title
OSU CHGCG at SemEval-2016 Task 9: Chinese Semantic Dependency Parsing with Generalized Categorial Grammar

abstract
This paper introduces our Chinese semantic dependency parsing system for Task 9 of Se-mEval 2016. Our system has two components: a parser trained using the Berkeley Grammar Trainer on the Penn Chinese Treebank reannotated in a Generalized Categorial Grammar, and a multinomial logistic regression classifier. We first parse the data with the automatic parser to obtain predicate-argument dependencies and then we use the classifier to predict the semantic dependency labels for the predicate-argument dependency relations extracted. Although our parser is not trained directly on the task training data, our system yields the best performance for the non-local dependency recovery for the news data and comparable overall results.

Introduction Semantic dependency parsing is an important language processing task which is useful in information extraction and question answering. In this paper, we introduce a Chinese semantic dependency parsing system which is built upon a categorial analysis of the Chinese language. Categorial grammar annotations are attractive because they have a transparent syntactic-semantic interface and provide a natural account of longdistance dependencies in a language. For this system, we adopt a Generalized Categorial Grammar framework, GCG,  (Bach, 1981) , for our language analysis. GCG annotations, compared with other Categorial Grammars, have a larger set of languagespecific rules and a smaller set of lexical categories, which on the one hand retains the desirable features of a categorial grammar, such as straightforward compositionality of its syntactic derivations and elegant analysis of filler-gap phenomenon, and on the other hand, mitigates the sparse data problem faced by any heavily lexicalized annotations. Parsers trained with English GCG annotations have been shown to have state-of-the-art parsing performance and better long-distance dependency recovery  (Rimell et al., 2009; Nguyen et al., 2012) . Parsers trained with Chinese GCG annotations have been shown to achieve better parsing accuracy than the parser trained with Chinese Combinatory Categorial Grammar, CCG,  (Steedman, 2000; Steedman, 2012)  annotations  (Tse and Curran, 2010; Tse and Curran, 2012)  for those trees which both grammar annotations assign the same tree structures  (Duan and Schuler, 2015) . The current experiment is our first experiment with dependency relations generated from the Chinese GCG annotations. We evaluate them against the manually annotated semantic dependencies in the current SemEval task. Since the purpose of the system is to verify the semantic dependencies generated by the Chinese GCG parser are reasonable, we adopt a minimalist machine learning scheme for this system to accomplish the evaluation. We first train the Berkeley parser  (Petrov and Klein, 2007)  with GCG annotations converted from the currently reannotated protion of around 71% of the Chinese Treebank  (Xue et al., 2005)  sentences. With this parser, we parse the sentences from training sets of the SemEval task and extract dependencies from the parses. Since the dependency labels are more finegrained in the SemEval task, we train a multinomial logistic regression classifier to predict the dependency labels for the extracted dependencies, using lexical, POS and other position features. Even though the parser is not directly trained on the gold GCG annotations of the training sentences, this system still yields respectable results compared with other more task dependent systems. Also the official evaluation of the task shows that the current system yields the best non-local dependency parsing accuracy for the newspaper corpus, which supports the findings in English that GCG annotations yield superior performance in long-distance dependency recovery  (Nguyen et al., 2012) . 

 Chinese GCG Parser This experiment used the Berkeley parser trained on Chinese GCG reannotated trees. 

 Chinese GCG framework A generalized categorial grammar  (Bach, 1981; Nguyen et al., 2012)  1 is a tuple P, O, R, W, M  (Oehrle, 1994)  consisting of a set P of primitive category types, a set O of type-constructing operators, a set R of inference rules, a set W of vocabulary items, and a mapping M from vocabulary items to syntactic categories. A set of complex syntactic categories C may then be defined as: P ? C; C ? O ? C ? C; nothing else is in C. The reannotation of Chinese Treebank into GCG annotations is still an on-going project. So far, we have identified the following set of primitive syntactic categories P for Mandarin Chinese: 1 Nguyen et al (2012) notate the '//' and '\\' operators of  Bach (1981)  as -g and -h, mnemonic for 'gap' and 'heavy shift'. V: verb-headed clause N: noun-headed phrase or clause D: de-clause headed by ? C: cardinal number Q: quantificational phrase A: adjectival phrase or nominal modifier R: adverbial phrase or verbal modifier B: verbal complement of in ba-construction E: verbal complement of in passive voice The set of type-constructing operators O for Mandarin Chinese includes -a and -b operators for unsatisfied requirements of preceding or succeeding arguments, -c and -d operators for unsatisfied requirements of preceding or succeeding conjuncts, and a -g operator for unsatisfied requirements of gap categories.  2  A GCG category consists of a primitive category followed by one or more unsatisfied dependencies, each consisting of an operator followed by another category. For example the category for a transitive verb is 'V-aN-bN' , since it is headed by a verb and has unsatisfied dependencies for noun phrases preceding and following it, i.e., the subject and direct object respectively. As in other categorial grammars, inference rules for local argument attachment apply functors of category ? 1...n-1 -ac or p? 1..n-1 -bc to initial or final arguments of category c, where c ? C, p ? P and each ? ? {-a, -b} ? C: c:g p? 1..n-1 -ac:h ? p? 1..n-1 :? x g (f n x) ? (h x) (Aa) p? 1..n-1 -bc:g c:h ? p? 1..n-1 :? x (g x) ? h (f n x) (Ab) These two inference rules stipulate the argument of category c is the n-th argument of the head. Inference rules for modifier composition apply preceding or succeeding modifiers of category p-bd to modificands of category c, where p ? {A, R}, d ? {N, V}: p-bd:g c:h ? c:? x ? y (g y) ? (h x) ? (f 1 y)=x (Ma) c:g p-bd:h ? c:? x ? y (g x) ? (h y) ? (f 1 y)=x (Mb) Separate modifier composition rules makes it possible to assign the same syntactic category to the modifier regardless of its occurring position. The modifier composition rules Ma and Mb establish a '1'labeled dependency from the modifier to the modificand. For example, for the sentence '? ? The little cat ate the fish', we have the derivation and the dependencies extracted from the derivation as follows. ? little A-bN ? cat N Ma N ? ate V-aN-bN ? ASP R-bV Ma V-aN-bN ? fish N Ab V-aN Aa V ?'little' 1 ?'cat' ?'ate' 1 2 ?ASP 1 ?'fish' Inference rules for gap composition are: p? 1..n-1 oc ? p? 1..n-1 -gc:? vx (g x) ? (f n x)=v (Ga) c:g ? c-gd:? vx (g x) ? (f 1 v)=x (Gb) N:g ? N-gN:? vx (g x) ? ? e (de-asso e x v) (Gc) where p ? P , o ? {-a, -b}, c ? C, d ? {A-bN, R-bV} and ? ? {-a, -b} ? C. Rule Ga hypothesizes a gap as a preceding or succeeding argument, rule Gb hypothesizes an adjectival or adverbial modifier gap and rule Gc hypothesizes a gap which is associated with the subject in the topicalization construction which does not involve movement. Non-local arguments, each consisting of a nonlocal operator and argument category ? ? {-g} ? C, are then propagated to consequents from all possible combinations of antecedents. For d:g e:h ? c:(f g h) ? {Aa-b, Ma-b}: d? 1..m :g e? m+1..n :h ? c? 1..n :? v1..n f (g v 1..m ) (h v m+1..n ) (Ac-d, Mc-d) Rules Ac-d and Mc-d stipulate non-local propagation through argument and modifier composition. Inference rules for filler attachment apply gapped clauses to topicalized phrases as fillers. For c ? C, and p ? P : p:g c-gp:h ? c:? x ? y (g y) ? (h y x) (Fa) For example, for a topicalized sentence such as "? ? ? ? ? ? ?The fish, the little cat ate.", we can extract the dependencies as follows. ?'fish' ?'little' 1 ?'cat' ?'ate' 1 2 ?ASP 1 In Mandarin relative clauses, the particle ? 'de' takes a preceding clause containing a gap to form a relative clause modifying a succeeding noun. The modified noun is the filler of the gap in the relative clause. The inference rules for relative clauses apply the gapped de-clause to the modificand as a filler. For c ? C: D-gc:g N:h ? N:? x (h x) ? ? y (g x y) (R) For a noun phrase such as "? the fish that the little cat ate", we can extract the following dependencies. ?'little' 1 ?'cat' ?'ate' 1 2 ? DE 1 ?'fish' Ba constructions in Mandarin Chinese require the affected patients of certain verbs to occur before the verb. In our analysis, we propose that the particle ba takes a ba-verb as its complement. Ba-verbs can be derived from transitive verbs with the type conversion rule, or some verbs, such as some resultative verbs, have Ba-verb categories. The particle ? ba is assigned the category V-aNb(B-aN), with coindexation between the referent of its subject (f 1 x) and the referent of the subject of its complement (f 1 (f 2 x)). ? 'ba' ?V-aN-b(B-aN): ? x (f 0 x)=ba ? (f 1 x)=(f 1 (f 2 x)) The lexical entry of ba gives the following dependencies for the sentence '? The cat ate the fish. ?'cat' ? BA 1 2 ?'fish' ?'ate' 2 1 O O ?ASP 1 Mandarin Chinese uses the particle ? bei to construct passive sentences. In bei constructions, the patient argument of a verb, usually the second argument of a transitive verb or a ba-verb, is moved to the subject position of the clause. We propose the particle ? bei takes a bei-verb as its complement, which is converted from a transitive verb with a missing object. Here is the lexical entry we propose for the bei particle. ? 'bei' ?V-aN-b(E-aN-gN)-bN: ? x (f 0 x)=bei ? (f 3 x)=(f 1 (f 2 x)) For example, the sentence '? The fish was eaten by the cat gives us the following dependencies. ?'fish' ? BEI 1 2 ?'cat' ?'ate' 1 2 O O ?ASP 1 2. 

 Training Chinese GCG Parser The syntactic parser we used for the current semantic dependency parsing is trained by the latent variable PCFG trainer  (Petrov and Klein, 2007)  on Chinese GCG annotations. Converting Penn Chinese Treebank 5 and 6 into GCG annotations is still an on-going project. We use a set of reannotation rules similar to those described by  Nguyen et al. (2012)  to reannotate the Penn Chinese Treebank into GCG trees. We currently have fully annotated 71% of sentences (18,505 out of 26,062 sentences) from the Penn Chinese Treebank 5 and 6. 3 With these 18,505, we have trained the Chinese GCG parser which is used for the current semantic dependency parsing task. From the parses, we extracted the raw dependences as the input for the multinomial classifier in the next stage. 

 Multinomial Dependency Label Classifier As shown in the examples above, the predicateargument dependencies extracted from GCG derivations do not have fine-grained labels as those dependencies annotated for the task. Also the dependencies identified by the parser sometimes have different directions than those annotated in the task. Therefore, in order to increase the coverage, for each dependency identified by the parser, we also add a dependency which has the reverse direction. For example, if the parser predicts that a dependency such as 1(eat, cat), in which the head is eat, the dependent is cat, the dependency label is '1', we would add another dependency with inversed direction: 1-inv(cat, eat). By doing so, we can increase the coverage of the annotated dependencies to around 83%. However, it also doubles the dependencies predicted by the parser and potentially hurts the recall of the accuracy later on. There are totally 157 semantic dependency labels used in the task. Since the classifier also needs to decide whether a dependency relation exists between each pair of words, we add a "NoRel" label for those pairs of words which, according to the gold annotation, do not hold any dependency relation between them. We train a one-vs-all multiclass classifier from the Vowpal Wabbit machine learning package.  4  We use the following features to predict the dependency labels: Lexical features: the 300-dimensional word embeddings of the head and dependent words trained with word2vec  (Mikolov et al., 2013)  on the full Chinese Wikipedia, the Chinese Gigaword as well as the training and test datasets in this task; POS features: the 50-dimensional vector representations of the POS tags of the head and dependent trained with the POS tag sequences from training and test datasets in this task; Linear distance: the linear distance of the head and the dependent in the sentence; Path distance: the distance of the nodes of the head and the dependent in the syntactic tree; Syntactic categories: the GCG syntactic categories of the head and the dependent; Pred-arg dependency labels: the dependency labels predicted by the parser, such as '1' or '2'; Repetition penalty: the reciprocal of the number of heads that the dependent word has, to penalize proposing too many heads for one word; Joint features: two-way combinational features between GCG syntactic categories of the two words where GCG is the current system and TOP is the system with the best labeled F1 score. and the dependency label, such "V-aN 1" or "N 1"; 

 Results and Discussion This Chinese semantic dependency parsing task comes in two domains, the newspaper articles (News) and texts selected from Chinese textbooks (Text). In our experiment, we found the combining the two training sets yields better accuracy for the textbook corpus and a slightly worse performance for the newspaper corpus. Therefore the News results reported in Table  1  and 2 are obtained by a classifier only trained on the newspaper corpus, and the Text results are obtained by a classifier trained on the combined training set of the newspaper corpus and the textbook corpus. The results in Table  1  show that newspaper text is more difficult to parse, even though the GCG parser is trained on a newspaper corpus. However, it also shows that the parser trained on the newspaper corpus can generalize nicely to another domain such as the textbook corpus, where more diverse syntactic constructions are found. Table  2  shows the results on the test set compared with the system yielding the highest labeled F1 score. We can see that the current system is around 3 percentage lower than the top system in terms of the labeled F1 score. Considering the fact that the parser is not directly trained on the task-specific dependency annotations and gold POS tags, these results look reasonably good with the rather simplistic machine learning architecture. Table  2  also shows that the current system achieves the best performance on non-local dependencies according to the official evaluation, which supports the corresponding findings in English where parsers trained on GCG English annotations achieve the state-ofthe-art performance in long distance dependency recovery  (Nguyen et al., 2012) . 

 Error Analysis We randomly inspected around 20 sentences from each domain where the predictions of the current system are different from the gold annotations to examine the reason, and we identified the following sources of errors. Parsing errors: Parsing errors caused around half of the wrong predictions we inspected. One type of mistake that we notice the parser often makes is wrong predictions about the internal structure of complex noun phrases. For example, for the noun phrase '? ? ? ? ? ? ? ? International Monetary Fund Organization', the parser proposes all first three nouns to be modifiers of the head noun '? organization', while '? monetary' actually modifies '? fund' in gold annotations. The parser also often makes mistakes when parsing questions, since there are not many questions in the Treebank. Uncovered linguistic phenomena: the gold dependency annotations issued by the task contain dependencies involving co-reference. ( In (1), '? I' is annotated to have a eEqu relation with '? myself '. In (2), '? Lusu' has a eEqu relation with '? me'. Dependencies like these, especially the one in (2), cannot be resolved easily by a syntactic parser, which means we might need an extra layer of post-processing to do co-reference inference based on discourse information. Ambiguous constructions: In some cases, a sentence can be analyzed in more than one way. All of them are reasonable analyses but each gives different dependencies. The current parser parses both (3) and (4) as object control sentences. In (3) '? he' is the object of '? love' and the subject of '? have aspiration'. In the gold annotation of (3), '? love' takes a sentential complement 'he has aspiration'. Therefore, for (3), our system proposes a dependency between '? love' and '? he', while in the gold annotations, the dependency is between '? love' and '? have'. In (4), our parser parses '? person' as the object of '? have' and the subject of '? came'. '? have'?therefore, is the root of the sentence. In gold annotations, '? come' is the root of the sentence. Inconsistent annotations: There are some cases where our predictions are systematically different from the gold annotations. For example, the current system is consistently different from the gold annotations on the identification of root where some adverbial clauses are involved. ( We think both (  5 ) and (  6 ) contain a conditional subordinate clause, and the root of the sentence should be '? postpone' in (5) and  '? buy' in (6) . In gold annotations, '? rain' is annotated to be the root of (5) and '? dislike' the root of (6). Our assumption is that those clauses are handled as conjunctions in gold annotations. Our predictions also do not agree with the gold annotations in some relative clauses. For (7), we think there is a dependency between '? do' and '? thing', rather than '? like' and '? thing'. 

 Conclusion This paper introduces the Chinese semantic dependency parsing system based on the predicateargument dependencies predicted by a Berkeley parser trained on Chinese GCG trees reannotated from the Penn Chinese Treebank. This system achieves comparable performance for the overall labeled dependency prediction and superior performance for the non-local dependency recovery. Our error analysis shows that many dependency parsing errors can be attributed to the syntactic parsing errors. In the future, we will expand the training set of the parser to cover more diverse syntactic constructions such as questions. We will also consider including corpora from different domains to make the parser more adaptable to data from new domains. have come here before' 
