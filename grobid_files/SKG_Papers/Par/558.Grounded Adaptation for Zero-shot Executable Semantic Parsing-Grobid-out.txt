title
Grounded Adaptation for Zero-shot Executable Semantic Parsing

abstract
We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycleconsistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose inputoutput consistency are verified. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms dataaugmentation in the training environment, performance increases with the amount of GAZPsynthesized data, and cycle-consistency is central to successful adaptation.

Introduction Semantic parsers  (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011)  build executable meaning representations for a range of tasks such as question-answering  (Yih et al., 2014) , robotic control  (Matuszek et al., 2013) , and intelligent tutoring systems  (Graesser et al., 2005) . However, they are usually engineered for each application environment. For example, a languageto-SQL parser trained on an university management database struggles when deployed to a sales database. How do we adapt a semantic parser to new environments where no training data exists? We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing, which adapts existing semantic parsers to new environments by synthesizing new, cycle-consistent data. In the previous example, GAZP synthesizes high-quality sales questions and SQL queries using the new sales database, then adapts the parser using the synthesized data. This procedure is shown in Figure  1 . GAZP is complementary to prior modeling work in that it can be applied to any model architecture, in any domain where one can enforce cycleconsistency by evaluating equivalence between logical forms. Compared to data-augmentation, which typically synthesizes unverified data in the training environment, GAZP instead synthesizes consistency-verified data in the new environment. GAZP synthesizes data for consistency-verified adaptation using a forward semantic parser and a backward utterance generator. Given a new environment (e.g. new database), we first sample logical forms with respect to a grammar (e.g. SQL grammar conditioned on new database schema). Next, we generate utterances corresponding to these logical forms using the generator. Then, we parse the generated utterances using the parser, keeping those whose parses are equivalent to the original sampled logical form (more in Section 2.4). Finally, we adapt the parser to the new environment by training on the combination of the original data and the synthesized cycle-consistent data. We evaluate GAZP on the Spider, Sparc, and CoSQL  (Yu et al., 2018b (Yu et al., , 2019a  language-to-SQL zero-shot semantic parsing tasks which test on unseen databases. GAZP improves logical form and execution accuracy of the baseline parser on all tasks, successfully adapting the existing parser to new environments. In further analyses, we show that GAZP outperforms data augmentation in the training environment. Moreover, adaptation performance increases with the amount of GAZPsynthesized data. Finally, we show that cycleconsistency is critical to synthesizing high-quality examples in the new environment, which in turn allows for successful adaptation and performance Output is shown in red. First, we train a parser and a utterance generator using training data. We then sample logical forms in the inference environment and generate corresponding utterances. We parse the generated utterances and check for cycle-consistency between the parse and the sampled logical form (see Section 2.4). Consistent pairs of utterance and logical form are used to adapt the parser to the inference environment. improvement. 1 2 Grounded Adaptation for Zero-shot Executable Semantic Parsing Semantic parsing involves producing a logical form q that corresponds to an input utterance u, such that executing q in the environment e produces the desired denotation EXE(q, e). In the context of language-to-SQL parsing, q and e correspond to SQL queries and databases. We propose GAZP for zero-shot semantic parsing, where inference environments have not been observed during training (e.g. producing SQL queries in new databases). GAZP consists of a forward semantic parser F (u, e) ! q, which produces a logical form q given an utterance u in environment e, and a backward utterance generator G(q, e) ! u. The models F and G condition on the environment by reading an environment description w, which consists of a set of documents d. In the context of SQL parsing, the description is the database schema, which consists of a set of table schemas (i.e. documents). We assume that the logical form consists of three types of tokens: syntax candidates c s from a fixed syntax vocabulary (e.g. SQL syntax), environment candidates c e from the environment description (e.g. table names from database schema), and  1  We will open-source our code. utterance candidates c u from the utterance (e.g. values in SQL query). Finally, c e tokens have corresponding spans in the description d. For example, a SQL query q consists of columns c e that directly map to related column schema (e.g. table, name, type) in the database schema w. In GAZP , we first train the forward semantic parser F and a backward utterance generator G in the training environment e. Given a new inference environment e 0 , we sample logical forms q from e 0 using a grammar. For each q, we generate a corresponding utterance u 0 = G(q, e 0 ). We then parse the generated utterance into a logical form q 0 = F (u 0 , e 0 ). We combine cycle-consistent examples from the new environment, for which q 0 is equivalent to q, with the original labeled data to retrain and adapt the parser. Figure  1  illustrates the components of GAZP. We now detail the sampling procedure, forward parser, backward generator, and cycle-consistency. 

 Query sampling To synthesize data for adaptation, we first sample logical forms q with respect to a grammar. We begin by building an empirical distribution over q using the training data. For language-to-SQL parsing, we preprocess queries similar to  and further replace mentions of columns and values with typed slots to form coarse Algorithm 1 Query sampling procedure.  that we remove JOINs which are later filled back deterministically after sampling the columns. Next, we build an empirical distribution P Z over these coarse templates by counting occurrences in the training data. The sampling procedure is shown in Algorithm 1 for the language-to-SQL example. Invalid queries and those that execute to the empty set are discarded. Given some coarse template z = SELECT key1, text1 WHERE text2 = val, the function d.CANFILL(z) returns whether the database d contains sufficient numbers of columns. In this case, at the minimum, d should have a key column and two text columns. The function d.RANDASSIGNCOLSTOSLOTS() returns a database copy d 0 such that each of its columns is mapped to some identifier text1, key1 etc. Appendix A.1 quantifies query coverage of the sampling procedure on the Spider task, and shows how to extend Algorithm 1 to multi-turn queries. 

 Forward semantic parser The forward semantic parser F produces a logical form q = F (u, e) for an utterance u in the environment e. We begin by cross-encoding u with the environment description w to model coreferences. Since w may be very long (e.g. entire database schema), we instead cross-encode u with each document d i in the description (e.g. each table schema) similar to . We then combine each environment candidate c e,i across documents (e.g. table columns) using RNNs, such that the final representations capture dependencies between c e from different documents. To produce the logical form q, we first generate a logical form template q whose utterance candidates c u (e.g. SQL values) are replaced by slots. We generate q with a pointerdecoder that selects among syntax candidates c s (e.g. SQL keywords) and environment candidate c e (e.g. table  columns ). Then, we fill in slots in q with a separate decoder that selects among c u in the utterance to form q. Note that logical form template q is distinct from coarse templates z described in sampling (Section 2.1). Figure  2  describes the forward semantic parser. Let u denote words in the utterance, and d i denote words in the ith document in the environment description. Let [a; b] denote the concatenation of a and b. First, we cross-encode the utterance and the document using BERT  (Devlin et al., 2019) , which has led to improvements on a number of NLP tasks. ! B i = BERT ! ([u; d i ]) (1) Next, we extract environment candidates in document i using self-attention. Let s, e denote the start and end positions of the jth environment candidate in the ith document. We compute an intermediate representation x ij for each environment candidate: a = softmax(W [ ! B is ; ... ! B ie ] + b) (2) x ij = e X k=s a k ! B ik (3) For ease of exposition, we abbreviate the above self-attention function as x ij = selfattn( ! B i [s : e]) Because x ij do not model dependencies between different documents, we further process x with bidirectional LSTMs  (Hochreiter and Schmidhuber, 1997 ). We use one LSTM followed by selfattention to summarize each ith document: ! h enc,i = selfattn(BiLSTM([x i1 ; x i2 ; ...])) (4) We use another LSTM to build representations for each environment candidate c e,i c e = BiLSTM([x 11 ; x 12 ; ...x 21 ; x 22 ...]) (5) We do not share weights between different LSTMs and between different self-attentions. Next, we use a pointer-decoder  (Vinyals et al., 2015)  to produce the output logical form template  User utterance u < l a t e x i t s h a 1 _ b a s e 6 4 = " A d v w c f P B g Z Q s W p O 1 z A c a C v + K G P o = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c I c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j i D w 0 f / 1 9 F V 5 U X C 6 6 0 b X 9 Z m Y X F p e W V 7 G p u b X 1 j c y u / v V N T U S I Z V l k k I t n w q E L B Q 6 x q r g U 2 Y o k 0 8 A T W v f 7 l K K / f o V Q 8 C m / 0 I E Y 3 o N 2 Q + 5 x R b a x K 0 s 4 X 7 K I 9 F p k H Z w q F i 4 / 7 7 6 v 3 v b T c z n + 2 O h F L A g w 1 E 1 S p p m P H 2 k 2 p 1 J w J H O Z a i c K Y s j 7 t Y t N g S A N U b j o e d E g O j d M h f i T N C z U Z u 7 8 7 U h o o N Q g 8 U x l Q 3 V O z 2 c j 8 L 2 s m 2 j 9 3 U x 7 G i c a Q T T 7 y E 0 F 0 R E Z b k w 6 X y L Q Y G K B M c j M r Y T 0 q K d P m N j l z B G d 2 5 X m o H R e d k + J p x S 6 U b J g o C / t w A E f g w B m U 4 B r K U A U G C A / w B M / W r f V o v V i v k 9 K M N e 3 Z h T + y 3 n 4 A A s u Q v Q = = < / l a t e x i t > u < l a t e x i t s h a 1 _ b a s e 6 4 = " A d v w c f P B g Z Q s W p O 1 z A c a C v + K G P o = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c I c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j i D w 0 f / 1 9 F V 5 U X C 6 6 0 b X 9 Z m Y X F p e W V 7 G p u b X 1 j c y u / v V N T U S I Z V l k k I t n w q E L B Q 6 x q r g U 2 Y o k 0 8 A T W v f 7 l K K / f o V Q 8 C m / 0 I E Y 3 o N 2 Q + 5 x R b a x K 0 s 4 X 7 K I 9 F p k H Z w q F i 4 / 7 7 6 v 3 v b T c z n + 2 O h F L A g w 1 E 1 S p p m P H 2 k 2 p 1 J w J H O Z a i c K Y s j 7 t Y t N g S A N U b j o e d E g O j d M h f i T N C z U Z u 7 8 7 U h o o N Q g 8 U x l Q 3 V O z 2 c j 8 L 2 s m 2 j 9 3 U x 7 G i c a Q T T 7 y E 0 F 0 R E Z b k w 6 X y L Q Y G K B M c j M r Y T 0 q K d P m N j l z B G d 2 5 X m o H R e d k + J p x S 6 U b J g o C / t w A E f g w B m U 4 B r K U A U G C A / w B M / W r f V o v V i v k 9 K M N e 3 Z h T + y 3 n 4 A A s u Q v Q = = < / l a t i b + p Q O F g W + 4 R o v 2 r L A E I m o l t P v U = " > A A A C I n i c b V B N S w M x F M z 6 W e t X 1 a O X Y B E 8 S N m V F v V W 8 O K x g l W h W 0 o 2 + 9 o G s 5 s l e a s t y / 4 W L / 4 V L x 4 U 9 S T 4 Y 0 x r D 9 o 6 E B h m 3 m P y J k i k M O i 6 n 8 7 c / M L i 0 n J h p b i 6 t r 6 x W d r a v j I q 1 R y a X E m l b w J m Q I o Y m i h Q w k 2 i g U W B h O v g 9 m z k X 9 + B N k L F l z h M o B 2 x X i y 6 g j O 0 U q d 0 6 i M M E D E z m I Y Q o 6 m I M P f 7 J m E c s l o y y H 1 l 1 7 X o 9 Z F p r e 6 z Q d 7 J v E P q 5 Z 1 S 2 a 2 4 Y 9 B Z 4 k 1 I m U z Q 6 J T e / V D x N L I p X D J j W p 6 b Y D t j G g W X k B f 9 1 I C N v W U 9 a F k a s w h M O x u f m N N 9 q 4 S 0 q 7 R 9 M d K x + n s j Y 5 E x w y i w k x H D v p n 2 R u J / X i v F 7 k k 7 E 3 G S I s T 8 J 6 i b S o q K j v q i o d D A U Q 4 t Y V w L + 1 f K + 0 w z j r b V o i 3 B m z 5 5 l l w d V b x q p X Z R L d f d S R 0 F s k v 2 y A H x y D G p k 3 P S I E 3 C y Q N 5 I i / k 1 X l 0 n p 0 3 5 + N n d M 6 Z 7 O y Q P 3 C + v g G O d a Y M < / l a t e x i t > students.id ! x 1,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " i b + p Q O F g W + 4 R o v 2 r L A E I m o l t P v U = " > A A A C I n i c b V B N S w M x F M z 6 W e t X 1 a O X Y B E 8 S N m V F v V W 8 O K x g l W h W 0 o 2 + 9 o G s 5 s l e a s t y / 4 W L / 4 V L x 4 U 9 S T 4 Y 0 x r D 9 o 6 E B h m 3 m P y J k i k M O i 6 n 8 7 c / M L i 0 n J h p b i 6 t r 6 x W d r a v j I q 1 R y a X E m l b w J m Q I o Y m i h Q w k 2 i g U W B h O v g 9 m z k X 9 + B N k L F l z h M o B 2 x X i y 6 g j O 0 U q d 0 6 i M M E D E z m I Y Q o 6 m I M P f 7 J m E c s l o y y H 1 l 1 7 X o 9 Z F p r e 6 z Q d 7 J v E P q 5 Z 1 S 2 a 2 4 Y 9 B Z 4 k 1 I m U z Q 6 J T e / V D x N L I p X D J j W p 6 b Y D t j G g W X k B f 9 1 I C N v W U 9 a F k a s w h M O x u f m N N 9 q 4 S 0 q 7 R 9 M d K x + n s j Y 5 E x w y i w k x H D v p n 2 R u J / X i v F 7 k k 7 E 3 G S I s T 8 J 6 i b S o q K j v q i o d D A U Q 4 t Y V w L + 1 f K + 0 w z j r b V o i 3 B m z 5 5 l l w d V b x q p X Z R L d f d S R 0 F s k v 2 y A H x y D G p k 3 P S I E 3 C y Q N 5 I i / k 1 X l 0 n p 0 3 5 + N n d M 6 Z 7 O y Q P 3 C + v g G O d a Y M < / l a t e x i t > students.school ! x 1,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " W a m n h u j n W 8 7 a + T s k w 5 D w 7 / 7 I 1 h E = " > A A A C J n i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J I U R S 9 C w Y v H C l a F p p T N d t o s 3 W T D 7 k R b Q n 6 N F / + K F w 8 V E W / + F L e 1 B 7 8 G F h 7 v z c z b e W E q h U H P e 3 f m 5 h c W l 5 Z L K + X V t f W N T X d r + 9 q o T H N o c i W V v g 2 Z A S k S a K J A C b e p B h a H E m 7 C w f l E v 7 k D b Y R K r n C U Q j t m / U T 0 B G d o q Y 5 7 F i A M E T E 3 m H U h Q V M 1 P F J K F k F k U s Y h P 0 6 H R a D s C i 3 6 E T K t 1 X 0 + L D q 5 f 0 h r R c e t e F V v W v Q v 8 G e g Q m b V 6 L j j o K t 4 F l s n L p k x L d 9 L s Z 0 z j Y J L K M p B Z s D a D l g f W h Y m L A b T z q d n F n T f M l 3 a U 9 q + B O m U / T 6 R s 9 i Y U R z a z p h h Z H 5 r E / I / r Z V h 7 7 S d i y T N E B L + Z d T L J E V F J 5 n R r t D A U Y 4 s Y F w L + 1 f K I 6 Y Z R 5 t s 2 Y b g / z 7 5 L 7 i u V f 2 j 6 v H l U a X u z e I o k V 2 y R w 6 I T 0 5 I n V y Q B m k S T h 7 I E x m T F + f R e X Z e n b e v 1 j l n N r N D f p T z 8 Q k p 0 6 f w < / l a t e x i t > students.school ! x 1,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " W a m n h u j n W 8 7 a + T s k w 5 D w 7 / 7 I 1 h E = " > A A A C J n i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J I U R S 9 C w Y v H C l a F p p T N d t o s 3 W T D 7 k R b Q n 6 N F / + K F w 8 V E W / + F L e 1 B 7 8 G F h 7 v z c z b e W E q h U H P e 3 f m 5 h c W l 5 Z L K + X V t f W N T X d r + 9 q o T H N o c i W V v g 2 Z A S k S a K J A C b e p B h a H E m 7 C w f l E v 7 k D b Y R K r n C U Q j t m / U T 0 B G d o q Y 5 7 F i A M E T E 3 m H U h Q V M 1 P F J K F k F k U s Y h P 0 6 H R a D s C i 3 6 E T K t 1 X 0 + L D q 5 f 0 h r R c e t e F V v W v Q v 8 G e g Q m b V 6 L j j o K t 4 F l s n L p k x L d 9 L s Z 0 z j Y J L K M p B Z s D a D l g f W h Y m L A b T z q d n F n T f M l 3 a U 9 q + B O m U / T 6 R s 9 i Y U R z a z p h h Z H 5 r E / I / r Z V h 7 7 S d i y T N E B L + Z d T L J E V F J 5 n R r t D A U Y 4 s Y F w L + 1 f K I 6 Y Z R 5 t s 2 Y b g / z 7 5 L 7 i u V f 2 j 6 v H l U a X u z e I o k V 2 y R w 6 I T 0 5 I n V y Q B m k S T h 7 I E x m T F + f R e X Z e n b e v 1 j l n N r N D f p T z 8 Q k p 0 6 f w < / l a t e x i t > ? schools.id ! x 2,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " U V i Y e r 9 k Y s K + u P H s W p H 9 I v x y 2 L o = " > A A A C I X i c b V D L S s N A F J 3 4 r P U V d e l m s A g u p C S l o s u C G 5 c V r A p N K Z P p b T N 0 k g k z N 9 o S 8 i t u / B U 3 L h T p T v w Z p 7 U L X w c G D u f c w 5 1 7 w l Q K g 5 7 3 7 i w s L i 2 v r J b W y u s b m 1 v b 7 s 7 u t V G Z 5 t D i S i p 9 G z I D U i T Q Q o E S b l M N L A 4 l 3 I T D 8 6 l / c w f a C J V c 4 T i F T s w G i e g L z t B K X f c s Q B g h Y m 5 4 p J Q 0 V d E r g s i k j E N + k o 6 K Q N m 0 F o M I m d b q P h 8 V 3 b x 2 T P 2 i 6 1 a 8 q j c D / U v 8 O a m Q O Z p d d x L 0 F M 9 i S J B L Z k z b 9 1 L s 5 E y j 4 B K K c p A Z s G u H b A B t S x M W g + n k s w s L e m i V H u 0 r b V + C d K Z + T + Q s N m Y c h 3 Y y Z h i Z 3 9 5 U / M 9 r Z 9 g / 6 + Q i S T O E h H 8 t 6 m e S o q L T u m h P a O A o x 5 Y w r o X 9 K + U R 0 4 y j L b V s S / B / n / y X X N e q f r 1 6 c l m v N L x 5 H S W y T w 7 I E f H J K W m Q C 9 I k L c L J A 3 k i L + T V e X S e n T d n 8 j W 6 4 M w z e + Q H n I 9 P j s m l h A = = < / l a t e x i t > schools.id ! x 2,1 < l a t e x i t s h a 1 _ b a s e 6 4 = " U V i Y e r 9 k Y s K + u P H s W p H 9 I v x y 2 L o = " > A A A C I X i c b V D L S s N A F J 3 4 r P U V d e l m s A g u p C S l o s u C G 5 c V r A p N K Z P p b T N 0 k g k z N 9 o S 8 i t u / B U 3 L h T p T v w Z p 7 U L X w c G D u f c w 5 1 7 w l Q K g 5 7 3 7 i w s L i 2 v r J b W y u s b m 1 v b 7 s 7 u t V G Z 5 t D i S i p 9 G z I D U i T Q Q o E S b l M N L A 4 l 3 I T D 8 6 l / c w f a C J V c 4 T i F T s w G i e g L z t B K X f c s Q B g h Y m 5 4 p J Q 0 V d E r g s i k j E N + k o 6 K Q N m 0 F o M I m d b q P h 8 V 3 b x 2 T P 2 i 6 1 a 8 q j c D / U v 8 O a m Q O Z p d d x L 0 F M 9 i S J B L Z k z b 9 1 L s 5 E y j 4 B K K c p A Z s G u H b A B t S x M W g + n k s w s L e m i V H u 0 r b V + C d K Z + T + Q s N m Y c h 3 Y y Z h i Z 3 9 5 U / M 9 r Z 9 g / 6 + Q i S T O E h H 8 t 6 m e S o q L T u m h P a O A o x 5 Y w r o X 9 K + U R 0 4 y j L b V s S / B / n / y X X N e q f r 1 6 c l m v N L x 5 H S W y T w 7 I E f H J K W m Q C 9 I k L c L J A 3 k i L + T V e X S e n T d n 8 j W 6 4 M w z e + Q H n I 9 P j s m l h A = = < / l a t e x i t > schools.name ! x 2,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " n c o u b k P Y X u p Y 0 R 0 + q 9 x k S E P K X A o = " > A A A C I 3 i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J K U i u J J 8 O K x g t V C U 8 p m O 2 0 W N 9 m w O 9 G W k P / i x b / i x Y M i X j z 4 X 9 z W H t T 6 Y O D x 3 g w z 8 8 J U C o O e 9 + H M z S 8 s L i 2 X V s q r a + s b m + 7 W 9 r V R m e b Q 5 E o q 3 Q q Z A S k S a K J A C a 1 U A 4 t D C T f h 7 f n Y v 7 k D b Y R K r n C U Q i d m g 0 T 0 B W d o p a 5 7 G i A M E T E 3 P F J K m m r C Y i i C y K S M Q 3 6 U D o t A 2 X k t B h E y r d V 9 P i y 6 e e 2 Q 1 o q u W / G q 3 g R 0 l v h T U i F T N L r u W 9 B T P I s h Q S 6 Z M W 3 f S 7 G T M 4 2 C S y j K Q W b A r r 1 l A 2 h b O r 7 E d P L J j w X d t 0 q P 9 p W 2 l S C d q D 8 n c h Y b M 4 p D 2 x k z j M x f b y z + 5 7 U z 7 J 9 0 c p G k G U L C v x f 1 M 0 l R 0 X F g t C c 0 c J Q j S x j X w t 5 K e c Q 0 4 2 h j L d s Q / L 8 v z 5 L r W t W v V 4 8 u 6 5 U z b x p H i e y S P X J A f H J M z s g F a Z A m 4 e S B P J E X 8 u o 8 O s / O m / P + 3 T r n T G d 2 y C 8 4 n 1 9 L g q Z t < / l a t e x i t > schools.name ! x 2,2 < l a t e x i t s h a 1 _ b a s e 6 4 = " n c o u b k P Y X u p Y 0 R 0 + q 9 x k S E P K X A o = " > A A A C I 3 i c b V B N S 8 N A E N 3 4 W e t X 1 K O X x S J 4 k J K U i u J J 8 O K x g t V C U 8 p m O 2 0 W N 9 m w O 9 G W k P / i x b / i x Y M i X j z 4 X 9 z W H t T 6 Y O D x 3 g w z 8 8 J U C o O e 9 + H M z S 8 s L i 2 X V s q r a + s b m + 7 W 9 r V R m e b Q 5 E o q 3 Q q Z A S k S a K J A C a 1 U A 4 t D C T f h 7 f n Y v 7 k D b Y R K r n C U Q i d m g 0 T 0 B W d o p a 5 7 G i A M E T E 3 P F J K m m r C Y i i C y K S M Q 3 6 U D o t A 2 X k t B h E y r d V 9 P i y 6 e e 2 Q 1 o q u W / G q 3 g R 0 l v h T U i F T N L r u W 9 B T P I s h Q S 6 Z M W 3 f S 7 G T M 4 2 C S y j K Q W b A r r 1 l A 2 h b O r 7 E d P L J j w X d t 0 q P 9 p W 2 l S C d q D 8 n c h Y b M 4 p D 2 x k z j M x f b y z + 5 7 U z 7 J 9 0 c p G k G U L C v x f 1 M 0 l R 0 X F g t C c 0 c J Q j S x j X w t 5 K e c Q 0 4 2 h j L d s Q / L 8 v z 5 L r W t W v V 4 8 u 6 5 U z b x p H i e y S P X J A f H J M z s g F a Z A m 4 e S B P J E X 8 u o 8 O s / O m / P + 3 T r n T G d 2 y C 8 4 n 1 9 L g q Z t < / l a t e x i t > ? ? Env desc BiLSTM + SelfAttn 

 Template pointer decoder 

 Candidate phrase BiLSTM Fixed syntax vocabulary SELECT, FROM, WHERE, >, < ? Output logical form Environment description w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > ? Table: students id school year ? Document d 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > d 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > Table: schools id name city ? Document d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > Value pointer decoder Value BERT c e < l a t e x i t s h a 1 _ b a s e 6 4 = " 1 C 6 L y d S t v n S S 7 V m R C p a h 6 Q Z A 8 O g = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 s V 0 o u i V 3 A r J I v B k p l r M f 3 2 / 7 X 1 h p F 9 5 b n Z i l E U r D B N W 6 6 b m J 8 Y d U G c 4 E j v K t V G N C W Z 9 2 s W m p p B F q f z g 5 d U S O r N I h Y a x s S U M m 6 u + J I Y 2 0 H k S B 7 Y y o 6 e l 5 b y z + 5 z V T E 1 7 4 Q y 6 T 1 K B k 0 0 V h K o i J y f h v 0 u E K m R E D S y h T 3 N 5 K W I 8 q y o x N J 2 9 D 8 O Z f X i S 1 k 5 J 3 W j q 7 t m m 4 M E U O D u A Q j s G D c y j D F V S g C g y 6 c A + P 8 O Q I 5 8 F 5 d l 6 m r R l n N r M H f + C 8 / g D a n Z H j < / l a t e x i t > ! h enc < l a t e x i t s h a 1 _ b a s e 6 4 = " 2 g h C i z P h 3 G 9 U 3 g e a C x X F m z V e 5 / 4 = " > A A A C B X i c b V D L S s N A F J 1 Y H 7 W + o u J K F 4 N F c F U S U X R Z c O O y g n 1 A E 8 J k O m m G T j J h Z q K U 0 I 0 b f 8 W N C 0 X c i r / g Q n D l p + g k 7 U J b D w w c z r m X O + f 4 C a N S W d a n M V e a X 1 h c K i 9 X V l b X 1 j f M z a 2 W 5 K n A p I k 5 4 6 L j I 0 k Y j U l T U c V I J x E E R T 4 j b X 9 w n v v t a y I k 5 f G V G i b E j V A / p g H F S G n J M / c c r m 1 B + 6 F C Q v C b L B x 5 m S M i S G I 8 8 s y q V b M K w F l i T 0 i 1 X v r 4 f t v 5 I g 3 P f H d 6 H K c R i R V m S M q u b S X K z Z B Q F D M y q j i p J A n C A 9 Q n X U 1 j F B H p Z k W K E T z Q S g 8 G X O g X K 1 i o v z c y F E k 5 j H w 9 G S E V y m k v F / / z u q k K z t y M x k m q 8 l T F o S B l U H G Y V w J 7 V B C s 2 F A T h A X V f 4 U 4 R A J h p Y u r 6 B L s 6 c i z p H V U s 4 9 r J 5 e 6 D Q u M U Q a 7 Y B 8 c A h u c g j q 4 A A 3 Q B B j c g n v w C J 6 M O + P B e D Z e x q N z x m R n G / y B 8 f o D f X a d k A = = < / l a t e x i t > c u < l a t e x i t s h a 1 _ b a s e 6 4 = " 4 3 t M W i v O v W x 3 C 8 X c c r + E i O c N H r Y = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 0 3 a h 6 J b c C c g i 8 W a k W M 5 + f L / t f 2 G l X X h v d W K W R i g N E 1 T r p u c m x h 9 S Z T g T O M q 3 U o 0 J Z X 3 a x a a l k k a o / e H k 1 B E 5 s k q H h L G y J Q 2 Z q L 8 n h j T S e h A F t j O i p q f n v b H 4 n 9 d M T X j h D 7 l M U o O S T R e F q S A m J u O / S Y c r Z E Y M L K F M c X s r Y T 2 q K D M 2 n b w N w Z t / e Z H U T k r e a e n s 2 q b h w h Q 5 O I B D O A Y P z q E M V 1 C B K j D o w j 0 8 w p M j n A f n 2 X m Z t m a c 2 c w e / I H z + g P y 3 Z H z < / l a t e x i t > c s < l a t e x i t s h a 1 _ b a s e 6 4 = " i b t E V 4 v O N 5 u x l Y X G S U 7 H 9 x B 5 + m Y = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 N B 8 B R 2 R d F j w I v H i O Y B y R J m J 7 3 J k N n Z Z W Z W C C G f 4 M W D I l 7 9 E X / B g + D J T 9 H J 4 6 C J B Q 1 F V T f d X U E i u D a u + + l k s k v L K 6 u 5 t f z 6 x u b W d m F n t 6 b j V D G s s l j E q h F Q j Y J L r B p u B D Y S h T Q K B N a D / u X Y r 9 + h 0 j y W t 2 a Q o B / R r u Q h Z 9 R Y 6 Y a 1 d b t Q d E v u B G S R e D N S L G c / v t / 2 v 7 D S L r y 3 O j F L I 5 S G C a p 1 0 3 M T 4 w + p M p w J H O V b q c a E s j 7 t Y t N S S S P U / n B y 6 o g c W a V D w l j Z k o Z M 1 N 8 T Q x p p P Y g C 2 x l R 0 9 P z 3 l j 8 z 2 u m J r z w h 1 w m q U H J p o v C V B A T k / H f p M M V M i M G l l C m u L 2 V s B 5 V l B m b T t 6 G 4 M 2 / v E h q J y X v t H R 2 b d N w Y Y o c H M A h H I M H 5 1 C G K 6 h A F R h 0 4 R 4 e 4 c k R z o P z 7 L x M W z P O b G Y P / s B 5 / Q H v 1 Z H x < / l a t e x i t > ! B 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " y H I q u Y i G + c 9 K s l k J 0 Q P e b Q u B 5 i 8 = " > A A A B / X i c b V C 7 S g N B F J 1 N f M T 4 W l + V z W A Q r M K u K F o G b S w j m A c k y z I 7 u U m G z O 4 s M 7 N K X I K / Y m O h i K 2 1 v 2 A h W P k p O n k U m n j g w u G c e 7 n 3 n i D m T G n H + b Q y 2 b n 5 h c X c U n 5 5 Z X V t 3 d 7 Y r C q R S A o V K r i Q 9 Y A o 4 C y C i m a a Q z 2 W Q M K A Q y 3 o n Q / 9 2 j V I x U R 0 p f s x e C H p R K z N K N F G 8 u 3 t p j C 2 Z J 2 u J l K K m / R s 4 L u + X X C K z g h 4 l r g T U i h l P 7 7 f d r 6 g 7 N v v z Z a g S Q i R p p w o 1 X C d W H s p k Z p R D o N 8 M 1 E Q E 9 o j H W g Y G p E Q l J e O r h / g f a O 0 c F t I U 5 H G I / X 3 R E p C p f p h Y D p D o r t q 2 h u K / 3 m N R L d P v Z R F c a I h o u N F 7 Y R j L f A w C t x i E q j m f U M I l c z c i m m X S E K 1 C S x v Q n C n X 5 4 l 1 c O i e 1 Q 8 v j R p O G i M H N p F e + g A u e g E l d A F K q M K o u g W 3 a N H 9 G T d W Q / W s / U y b s 1 Y k 5 k t 9 A f W 6 w + 5 D J n C < / l a t e x i t > ! B 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " O I N Y n f e L 4 I r 5 7 y k n 9 Y 8 5 Y i / k o V E = " > A A A B / X i c b V C 7 S g N B F J 0 1 P m J 8 r a / K Z j E I V m E 3 K F o G b S w j m A c k y z I 7 u U m G z M 4 s M 7 N K X I K / Y m O h i K 2 1 v 2 A h W P k p O n k U m n j g w u G c e 7 n 3 n j B m V G n X / b T m M v M L i 0 v Z 5 d z K 6 t r 6 h r 2 5 V V U i k Q Q q R D A h 6 y F W w C i H i q a a Q T 2 W g K O Q Q S 3 s n Q / 9 2 j V I R Q W / 0 v 0 Y / A h 3 O G 1 T g r W R A n u n K Y w t a a e r s Z T i J j 0 b B M X A z r s F d w R n l n g T k i 9 l P r 7 f d r + g H N j v z Z Y g S Q R c E 4 a V a n h u r P 0 U S 0 0 J g 0 G u m S i I M e n h D j Q M 5 T g C 5 a e j 6 w f O g V F a T l t I U 1 w 7 I / X 3 R I o j p f p R a D o j r L t q 2 h u K / 3 m N R L d P / Z T y O N H A y X h R O 2 G O F s 4 w C q d F J R D N + o Z g I q m 5 1 S F d L D H R J r C c C c G b f n m W V I s F 7 6 h w f G n S c N E Y W b S H 9 t E h 8 t A J K q E L V E Y V R N A t u k e P 6 M m 6 s x 6 s Z + t l 3 D p n T W a 2 0 R 9 Y r z + 6 k J n D < / l a t e x i t > Figure  2 : Forward semantic parser. Model components are shown in purple, inputs in blue, and outputs in red. First, we cross-encode each environment description text and the utterance using BERT. We then extract document-level phrase representations for candidate phrases in each text, which we subsequently encode using LSTMs to form input and environment-level candidate phrase representations. A pointer-decoder attends over the input and selects among candidates to produce the output logical form. q by selecting among a set of candidates that corresponds to the union of environment candidates c e and syntax candidates c s . Here, we represent a syntax token using its BERT word embedding. The representation for all candidate representations ! c is then obtained as ! c = [c e,1 ; c e,2 ; ...c s,1 ; c s,2 ; ...] At each step t of the decoder, we first update the states of the decoder LSTM: h dec,t = LSTM( ! c qt 1 , h dec,t 1 ) (7) Finally, we attend over the document representations given the current decoder state using dotproduct attention  (Bahdanau et al., 2015) : ?t = softmax(h dec,t ! h | enc ) (8) v t = X i ?t,i ! h enc,i (9) The score for the ith candidate ! c i is o t = ? [h dec,t ; v t ] + b (10) s t,i = o t ! c | i (11) qt = argmax(s t ) (12) Value-generation. The pervious template decoder produces logical form template q, which is not executable because it does not include utterance candidates c u . To generate full-specified executable logical forms q, we use a separate value pointer-decoder that selects among utterance tokens. The attention input for this decoder is identical to that of the template decoder. The pointer candidates c u are obtained by running a separate BERT encoder on the utterance u. The produced values are inserted into each slot in q to form q. Both template and value decoders are trained using cross-entropy loss with respect to the groundtruth sequence of candidates. 

 Backward utterance generator The utterance generator G produces an utterance u = G(q, e) for the logical form q in the environment e. The alignment problem between q and the environment description w is simpler than that between u and w because environment candidates c e (e.g. column names) in q are described by corresponding spans in w (e.g. column schemas in database schema). To leverage this deterministic alignment, we augment c e in q with relevant spans from w, and encode this augmented logical form q. The pointer-decoder selects among words c v from a fixed vocabulary (e.g. when, where, who) and words c q from q. Figure 3 illustrates the backward utterance generator. 

 Logical form q < l a t e x i t s h a 1 _ b a s e 6 4 = " e x x z + < l a t e x i t s h a 1 _ b a s e 6 4 = " p Z o w U P w i 5 z S r E i k K / e h g Q s J N h H o 3 D G L q V n M 1 c D Q v s z J s = " > A A A B 6 H i c b V A 9 S w N B E J 2 L X 0 n 8 i l r a H A b B Q s K d K F o G b C w T M B + Q h L C 3 N 5 e s 2 d s 7 d / e E c K S x s b C x U M T W 3 j 9 j 5 6 / R z U e h i Q 8 G H u / N M D P P i z l T 2 n G + r M z S 8 s r q W j a X X 9 / Y 3 N o u 7 O z W V Z R I i j U a 8 U g 2 P a K Q M 4 E 1 z T T H Z i y R h B 7 H h j e 4 H P u N O 5 S K R e J a D 2 P s h K Q n W M A o 0 U a q 3 n Y L R a f k T G A v E n d G i u X c g / / x f X 9 c 6 R Y + 2 3 5 E k x C F p p w o 1 X K d W H d S I j W j H E f 5 d q I w J n R A e t g y V J A Q V S e d H D q y D 4 3 i 2 0 E k T Q l t T 9 T f E y k J l R q G n u k M i e 6 r e W 8 s / u e 1 E h 1 c d F I m 4 k S j o N N F Q c J t H d n j r 2 2 f S a S a D w 0 h V D J z q 0 3 7 R B K q T T Z 5 E 4 I 7 / / I i q Z + U 3 N P S W d W k 4 c A U W d i H A z g C F 8 6 h D F d Q g R p Q Q H i E Z 3 i x b q w n 6 9 V 6 m 7 Z m r N n M H v y B 9 f 4 D n q y Q d Q = = < / l a t e x i t > q < l a t e x i t s h a 1 _ b a s e 6 4 = " e x x z + J N h H o 3 D G L q V n M 1 c D Q v s z J s = " > A A A B 6 H i c b V A 9 S w N B E J 2 L X 0 n 8 i l r a H A b B Q s K d K F o G b C w T M B + Q h L C 3 N 5 e s 2 d s 7 d / e E c K S x s b C x U M T W 3 j 9 j 5 6 / R z U e h i Q 8 G H u / N M D P P i z l T 2 n G + r M z S 8 s r q W j a X X 9 / Y 3 N o u 7 O z W V Z R I i j U a 8 U g 2 P a K Q M 4 E 1 z T T H Z i y R h B 7 H h j e 4 H P u N O 5 S K R e J a D 2 P s h K Q n W M A o 0 U a q 3 n Y L R a f k T G A v E n d G i u X c g / / x f X 9 c 6 R Y + 2 3 5 E k x C F p p w o 1 X K d W H d S I j W j H E f 5 d q I w J n R A e t g y V J A Q V S e d H D q y D 4 3 i 2 0 E k T Q l t T 9 T f E y k J l R q G n u k M i e 6 r e W 8 s / u e 1 E h 1 c d F I m 4 k S j o N N F Q c J t H d n j r 2 2 f S a S a D w 0 h V D J z q 0 3 7 R B K q T T Z 5 E 4 I 7 / / I i q Z + U 3 N P S W d W k 4 c A U W d i H A z g C F 8 6 h D F d Q g R p Q Q H i E Z 3 i x b q w n 6 9 V 6 m 7 Z m r N n M H v y B 9 f 4 D n q y Q d Q = = < / l a t h P B X g = " > A A A B 9 H i c b V A 9 S w N B E N 3 z M 8 a v G L G y W Q y C V b g T g 5 Y B G 8 s I 5 g O S I + z t 7 S V L 9 v Y u u 3 O B c F x r Z a + F h U F s / T F 2 / h s 3 H 4 U m P h h 4 v D f D z D w v F l y D b X 9 b a + s b m 1 v b u Z 3 8 7 t 7 + w W H h q N j Q U a I o q 9 N I R K r l E c 0 E l 6 w O H A R r x Y q R 0 B O s 6 Q 1 u p 3 5 z x J T m k X y A c c z c k P Q k D z g l Y C S X d t M O c O G z d J h l 3 U L J L t s z 4 F X i L E i p W p w 8 v l R O n m r d w l f H j 2 g S M g l U E K 3 b j h 2 D m x I F n A q W 5 T u J Z j G h A 9 J j b U M l C Z l 2 0 9 n R G T 4 3 i o + D S J m S g G f q 7 4 m U h F q P Q 8 9 0 h g T 6 e t m b i v 9 5 7 Q S C G z f l M k 6 A S T p f F C Q C Q 4 S n C W C f K 0 Z B j A 0 h V H F z K 6 Z 9 o g g F k 1 P e h O A s v 7 x K G p d l 5 6 p c u T d p 2 G i O H D p F Z + g C O e g a V d E d q q E 6 o m i I n t E b m l g j 6 9 V 6 t z 7 m r W v W Y u Y Y / Y H 1 + Q N f l p V m < / l a t e x i t > c v < l a t e x i t s h a 1 _ b a s e 6 4 = " Z / A 7 4 Z s C k x q l 5 4 E F h p S z r j J v O A I = " > A A A B 7 H i c b V B N S 8 N A E J 2 0 f t T 6 V R V P X o J F 8 F Q S U f R Y 8 O K x g m k L b S i b 7 a R d u t m E 3 U 2 h h P 4 G L x 4 U 8 e r / 8 C 9 4 E D z 5 U 3 T 7 c d D W B w O P 9 2 a Y m R c k n C n t O J 9 W L r + y u r Z e 2 C h u b m 3 v 7 J b 2 9 u s q T i V F j 8 Y 8 l s 2 A K O R M o K e Z 5 t h M J J I o 4 N g I B t c T v z F E q V g s 7 v Q o Q T 8 i P c F C R o k 2 k k c 7 2 X D c K Z W d i j O F v U z c O S l X 8 x / f b 4 d f W O u U 3 t v d m K Y R C k 0 5 U a r l O o n 2 M y I 1 o x z H x X a q M C F 0 Q H r Y M l S Q C J W f T Y 8 d 2 y d G 6 d p h L E 0 J b U / V 3 x M Z i Z Q a R Y H p j I j u q 0 V v I v 7 n t V I d X v k Z E 0 m q U d D Z o j D l t o 7 t y e d 2 l 0 m k m o 8 M I V Q y c 6 t N + 0 Q S q k 0 + R R O C u / j y M q m f V d z z y s W t S c O B G Q p w B M d w C i 5 c Q h V u o A Y e U G B w D 4 / w Z A n r w X q 2 X m a t O W s + c w B / Y L 3 + A L k h k w A = < / l a t e x i t > h enc < l a t e x i t s h a 1 _ b a s e 6 4 = " V w U g i Y e S E q 3 T H P W r X B 4 r C F X y r y s = " > A A A C B H i c b V C 7 S g N B F J 0 1 P m J 8 R c U q z W A Q r M K u K F o G b C w j m A c k S 5 i d 3 E 2 G z O 4 s M 7 N K W F L Y + C s 2 F o r Y C v 6 C h W D l p + j s J o U m H h g 4 n H M v d 8 7 x I s 6 U t u 1 P a y G 3 u L S 8 k l 8 t r K 1 v b G 4 V t 3 c a S s S S Q p 0 K L m T L I w o 4 C 6 G u m e b Q i i S Q w O P Q 9 I b n q d + 8 B q m Y C K / 0 K A I 3 I P 2 Q + Y w S b a R u s d Q R x u b g a y K l u E k G 4 2 7 S k Q G G k I 6 7 x b J d s T P g e e J M S b m a + / h + 2 / u C W r f 4 3 u k J G g c Q a s q J U m 3 H j r S b E K k Z 5 T A u d G I F E a F D 0 o e 2 o S E J Q L l J F m K M D 4 z S w 7 6 Q 5 o U a Z + r v j Y Q E S o 0 C z 0 w G R A / U r J e K / 3 n t W P t n b s L C K N Z p q u y Q H 3 O s B U 4 b w T 0 m g W o + M o R Q y c x f M R 0 Q S a g 2 v R V M C c 5 s 5 H n S O K o 4 x 5 W T S 9 O G j S b I o x L a R 4 f I Q a e o i i 5 Q D d U R R b f o H j 2 i J + v O e r C e r Z f J 6 I I 1 3 d l F f 2 C 9 / g C d 8 Z 0 T < / l a t e x i t > Environment description w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > w < l a t e x i t s h a 1 _ b a s e 6 4 = " C X I r a 8 o i c y x / t x z s H N 1 p c M q L 6 S A = " > A A A B 6 H i c b Z D J S g N B E I Z r 4 h b j F p e b l 8 Y g e A o z o u j N g A c 9 J m A W S I b Q 0 6 l J 2 v Q s d P c o c c g T e P G g i F c f w J N P 4 s 2 j b 2 J n O W j 0 h 4 a P / 6 + i q 8 q L B V f a t j + t z N z 8 w u J S d j m 3 s r q 2 v p H f 3 K q p K J E M q y w S k W First, we encode the input logical form along with environment description for each of its symbols. we subsequently encode using LSTMs to form the input and environment-level candidate token representations. A pointer-decoder attends over the input and selects among candidate representations to produce the output utterance. x 4 V K H g I V Y 1 1 w I b s U Q a e A L r X v 9 8 l N d v U C o e h V d 6 E K M b 0 G 7 I f c 6 o N l b l t p 0 v 2 E V 7 L P I X n C k U z t 7 v v i 7 e d t J y O / / R 6 k Q s C T D U T F C l m o 4 d a z e l U n M m c J h r J Q p j y v q 0 i 0 2 D I Q 1 Q u e l 4 0 C H Z N 0 6 H + J E 0 L 9 R k 7 P 7 s S G m g 1 C D w T G V A d U / N Z i P z v 6 y Z a P / U T X k Y J x p D N v n I T w T R E R l t T T p c I t N i Y I A y y c 2 s h P W o p E y b 2 + T M E Z z Z l f 9 C 7 b D o H B W P K 3 a h Z M N E W d i F P T g A B 0 6 g B J d Q h i o w Q L i H R 3 i y r q 0 H 6 9 l 6 m Z R m r G n P N v y S 9 f o N B d O Q v w = = < / l a t e x i t > ? Table: students id school year ? Document d < l a t e x i t s h a 1 _ b a s e 6 4 = " W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > d < l a t e x i t s h a 1 _ b a s e 6 4 = " W 2 r D k k j c a y G Z b l / 1 K h 7 E v H j D / 4 I = " > A A A B 6 n i c b V D L S g N B E O x N f M T 4 i o o n L 4 t B 8 B R 2 R d F j w I v H i O Y B y R J m Z 3 u T I b O z y 8 y s E J Z 8 g h c P i n j 1 R / w F D 4 I n P 0 U n j 4 M m F j Q U V d 1 0 d / k J Z 0 o 7 z q e V y y 8 t r 6 w W 1 o r r G 5 t b 2 6 W d 3 Y a K U 0 m x T m M e y 5 Z P F H I m s K 6 Z 5 t h K J J L I 5 9 j 0 B 5 d j v 3 m H U r F Y 3 O p h g l 5 E e o K F j B J t p J u g 6 3 Z L Z a f i T G A v E n d G y t X 8 x / f b / h f W u q X 3 T h D T N E K h K S d K t V 0 n 0 V 5 G p G a U 4 6 j Y S R U m h A 5 I D 9 u G C h K h 8 r L J q S P 7 y C i B H c b S l N D 2 R P 0 9 k Z F I q W H k m 8 6 I 6 L 6 a 9 8 b i f 1 4 7 1 e G F l z G R p B o F n S 4 K U 2 7 r 2 B 7 / b Q d M I t V 8 a A i h k p l b b d o n k l B t 0 i m a E N z 5 l x d J 4 6 T i n l b O r k 0 a D k x R g A M 4 h G N w 4 R y q c A U 1 q A O F H t z D I z x Z 3 H q w n q 2 X a W v O m s 3 s w R 9 Y r z + N U 5 G w < / l a t e x i t > Table: schools id name city ? Document d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > d 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " K 9 0 J B H K R 2 k h e j s r L Y Y y a d + Z C r F A = " > A A A B 6 n i c b V D J S g N B E K 1 J X G L c o u L J S 2 M Q P I W Z o O g x 4 M V j R L N A H E J P T 0 3 S p G e h u 0 c I Q z 7 B i w d F v P o j / o I H w Z O f o p 3 l o I k P C h 7 v V V F V z 0 s E V 9 q 2 P 6 1 c f m l 5 Z b W w V l z f 2 N z a L u 3 s N l W c S o Y N F o t Y t j 2 q U P A I G 5 p r g e 1 E I g 0 9 g S 1 v c D H 2 W 3 c o F Y + j G z 1 M 0 A 1 p L + I B Z 1 Q b 6 d r v V r u l s l 2 x J y C L x J m R c i 3 / 8 f 2 2 / 4 X 1 b u n 9 1 o 9 Z G m K k m a B K d R w 7 0 W 5 G p e Z M 4 K h 4 m y p M K B v Q H n Y M j W i I y s 0 m p 4 7 I k V F 8 E s T S V K T J R P 0 9 k d F Q q W H o m c 6 Q 6 r 6 a 9 8 b i f 1 4 n 1 c G 5 m / E o S T V G b L o o S A X R M R n / T X w u k W k x N I Q y y c 2 t h P W p p E y b d I o m B G f + 5 U X S r F a c k 8 r p l U n D h i k K c A C H c A w O n E E N L q E O D W D Q g 3 t 4 h C d L W A / W s / U y b c 1 Z s 5 k 9 + A P r 9 Q e O 1 5 G x < / l a t e x i t > B < l a t e x i t s h a 1 _ b a s e 6 4 = " V A k b 0 5 7 q l / c k 6 4 x w + B A 2 1 f I W r 4 A = " > A A A B + n i c b V D L S g N B E O z 1 G e N r o 9 6 8 D A b B U 9 g V R W 8 G P e g x g n l A s o T Z y W w y Z H Z n m Z k 1 x D W f 4 s W D I o K n f I k 3 j / 6 J k 8 d B E w s a i q p u u r v 8 m D O l H e f L W l h c W l 5 Z z a x l 1 z c 2 t 7 b t 3 E 5 F i U Q S W i a C C 1 n z s a K c R b S s m e a 0 F k u K Q 5 / T q t + 9 G v n V e y o V E 9 G d 7 s f U C 3 E 7 Y g E j W B u p a e c a w t i c B h p L K X r p 5 a B p 5 5 2 C M w a a J + 6 U 5 C + G D 9 / X H 3 t p q W l / N l q C J C G N N O F Y q b r r x N p L s d S M c D r I N h J F Y 0 y 6 u E 3 r h k Y 4 p M p L x 6 c P 0 K F R W i g Q 0 l S k 0 V j 9 P Z H i U K l + 6 J v O E O u O m v V G 4 n 9 e P d H B u Z e y K E 4 0 j c h k U Z B w p A U a 5 Y B a T F K i e d 8 Q T C Q z t y L S w R I T b d L K m h D c 2 Z f n S e W 4 4 J 4 U T m + d f N G B C T K w D w d w B C 6 c Q R F u o A R l I N C D J 3 i B V + v R e First, we encode the logical form using BERT. B = BERT (q) (13) Next, we apply a bidirectional LSTM to obtain the input encoding h enc and another bidirectional LSTM to obtain representations of tokens in the augmented logical form c q. h enc = BiLSTM( B ) (14) c q = BiLSTM( B ) (15) To represent c v , we use word embeddings from BERT . Finally, we apply a pointer-decoder that attends over h enc and selects among candidates c = [c q; c v ] to obtain the predicted utterance. 

 Synthesizing cycle-consistent examples Having trained a forward semantic parser F and a backward utterance generator G in environment e, we can synthesize new examples with which to adapt the parser in the new environment e 0 . First, we sample a logical form q using a grammar (Algorithm 1 in Section 2.1). Next, we predict an utterance u 0 = G(q, e ). Because G was trained only on e, many of its outputs are low-quality or do not correspond to its input q. On their own, these examples (u 0 , q) do not facilitate parser adaptation (see Section 3.1 for analyses). To filter out low-quality examples, we additionally predict a logical form q 0 = F (u 0 , e 0 ), and keep only examples that are cycle consistent -the synthesized logical form q 0 is equivalent to the originally sampled logical form q in e 0 . In the case of SQL parsing, the example is cycle-consistent if executing the synthesized query EXE(q 0 , e 0 ) results in the same denotation (i.e. same set of database records) as executing the original sampled query EXE(q, e 0 ). Finally, we combine cycle-consistent examples synthesized in e 0 with the original training data in e to retrain and adapt the parser. 

 Experiments We evaluate performance on the Spider  (Yu et al., 2018b) , Sparc  (Yu et al., 2019b) , and CoSQL  (Yu et al., 2019a)  zero-shot semantic parsing tasks. Table 1 shows dataset statistics. Figure  4  shows examples from each dataset. For all three datasets, we use preprocessing steps from  to preprocess SQL logical forms. Evaluation consists of exact match over logical form templates (EM) in which values are stripped out, as well as execution accuracy (EX). Official evaluations also recently incorporated fuzz-test accuracy (FX) as tighter variant of execution accuracy. In fuzztesting, the query is executed over randomized database content numerous times. Compared to an execution match, a fuzz-test execution match is less likely to be spurious (e.g. the predicted query coincidentally executes to the correct result). FX implementation is not public as of writing, hence we only report test FX. Spider. Spider is a collection of databaseutterance-SQL query triplets. The task involves producing the SQL query given the utterance and the database. Figure  2 and 3  show preprocessed input for the parser and generator. Sparc. In Sparc, the user repeatedly asks questions that must be converted to SQL queries  We do not show Sparc because its data format is similar to CoSQL, but without user dialogue act prediction and without response generation. For our experiments, we produce the output logical form given the data, utterance, and the previous logical form if applicable. During evaluation, the previous logical form is the output of the model during the previous turn (i.e. no teacher forcing on ground-truth previous output). by the system. Compared to Spider, Sparc additionally contains prior interactions from the same user session (e.g. database-utterance-queryprevious query quadruplets). For Sparc evaluation, we concatenate the previous system-produced query (if present) to each utterance. For example, suppose the system was previously asked "where is Tesla born?" and is now asked "how many people are born there?", we produce the utterance CoSQL. CoSQL is combines task-oriented dialogue and semantic parsing. It consists of a number of tasks, such as response generation, user act prediction, and state-tracking. We focus on statetracking, in which the user intent is mapped to a SQL query. Similar to , we restrict the context to be the previous query and the current utterance. Hence, the input utterance and environment description are obtained in the same way as that used for Sparc. 

 Spider 

 Results We primarily compare GAZP with the baseline forward semantic parser, because prior systems produce queries without values which are not executable. We include one such non-executable model, EditSQL , one of the top parsers on Spider at the time of writing, for reference. However, EditSQL EM is not directly comparable because of different outputs. Due to high variance from small datasets, we tune the forward parser and backward generator using cross-validation. We then retrain the model with early stopping on the development set using hyperparameters found via cross-validation. For each task, we synthesize 100k examples, of which ?40k are kept after checking for cycle-consistency. The adapted parser is trained using the same hyperparameters as the baseline. Please see appendix A.2 for hyperparameter settings. Table  2  shows that adaptation by GAZP results in consistent performance improvement across Spider, Sparc, and CoSQL in terms of EM, EX, and FX. We also examine the performance breakdown across query classes and turns (details in appendix A.4). First, we divide queries into difficulty classes based on the number of SQL components, selections, and conditions  (Yu et al., 2018b) . For example, queries that contain more components such as  nested subqueries, column selections, and aggregators, etc are considered to be harder. Second, we divide multi-turn queries into how many turns into the interaction they occur for Sparc and CoSQL  (Yu et al., 2019b,a) . We observe that the gains in GAZP are generally more pronounced in more difficult queries and in turns later in the interaction. Finally, we answer the following questions regarding the effectiveness of cycle-consistency and grounded adaptation. Does adaptation on inference environment outperform data-augmentation on training environment? For this experiment, we synthesize data on training environments instead of inference environments. The resulting data is similar to data augmentation with verification. As shown in the "syntrain" row of Table  3 , retraining the model on the combination of this data and the supervised data leads to overfitting in the training environments. A method related to data-augmentation is jointly supervising the model using the training data in the reverse direction, for example by generating utterance from query  (Fried et al., 2018; Cao et al., 2019) . For Spider, we find that this dual objective (57.2 EM) underperforms GAZP adaptation (59.1 EM). Our results indicate that adaptation to the new environment significantly outperforms augmentation in the training environment. How important is cycle-consistency? For this experiment, we do not check for cycle-consistency and instead keep all synthesized queries in the inference environments. As shown in the "nocycle" row of Table  3 , the inclusion of cycle-consistency effectively prunes ?60% of synthesized examples, which otherwise significantly degrade performance. This shows that enforcing cycle-consistency is crucial to successful adaptation. In another experiment, we keep examples that have consistent logical forms, as deemed by string match (e.g. q == q 0 ), instead of consistent denotation from execution. The "EM consistency" row of Table  3  shows that this variant of cycleconsistency also improves performance. In particular, EM consistency performs similarly to execution consistency, albeit typically with lower execution accuracy. How much GAZP synthesized data should one use for grounded adaptation? For this experiment, we vary the amount of cycle-consistent syn- thesized data used for adaptation. Figure  5  shows that that adaptation performance generally increases with the amount of synthesized data in the inference environment, with diminishing return after 30-40k examples. 

 Related work Semantic parsing. Semantic parsers parse natural language utterances into executable logical forms with respect to an environment  (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011) . In zero-shot semantic parsing, the model is required to generalize to environments (e.g. new domains, new database schemas) not seen during training  (Pasupat and Liang, 2015; Zhong et al., 2017; Yu et al., 2018b) . For languageto-SQL zero-shot semantic parsing, a variety of methods have been proposed to generalize to new databases by selecting from table schemas in the new database  Guo et al., 2019) . Our method is complementary to these work -the synthesis, cycle-consistency, and adaptation steps in GAZP can be applied to any parser, so long as we can learn a backward utterance generator and evaluate logical-form equivalence. Data augmentation. Data augmentation transforms original training data to synthesize artificial training data.  Krizhevsky et al. (2017)  crop and rotate input images to improve object recognition.  Dong et al. (2017)  and  Yu et al. (2018a)  respectively paraphrase and back-translate  (Sennrich et al., 2016; Edunov et al., 2018)  questions and documents to improve question-answering.  Jia and Liang (2016)  perform data-recombination in the training domain to improve semantic parsing.  Hannun et al. (2014)  superimpose noisy background tracks with input tracks to improve speech recognition. Our method is distinct from dataaugmentation in the following ways. First, we synthesize data on logical forms sampled from the new environment instead of the original environment, which allows for adaptation to the new environments. Second, we propose cycle-consistency to prune low-quality data and keep high-quality data for adaptation. Our analyses show that these core differences from data-augmentation are central to improving parsing performance. Cycle-consistent generative adversarial models (cycle-GANs). In cycle-GAN  (Zhu et al., 2017; Hoffman et al., 2018) , a generator forms images that fools a discriminator while the discriminator tries distinguish generated images from naturally occurring images. The the adversarial objectives of the generator and the discriminator are optimized jointly. Our method is different from cycle-GANs in that we do not use adversarial objectives and instead rely on matching denotations from executing synthesized queries. This provides an exact signal compared to potentially incorrect outputs by the discriminator. Morevoer, cycle-GANs only synthesize the input and verify whether the input is synthesized (e.g. the utterance looks like a user request). In contrast, GAZP synthesizes both the input and the output, and verifies consistency between the input and the output (e.g. the utterance matches the query). 

 Conclusion and Future work We proposed GAZP to adapt an existing semantic parser to new environments by synthesizing cycle-consistent data. GAZP improved parsing performance on three zero-shot parsing tasks. Our analyses showed that GAZP outperforms data augmentation, performance improvement scales with the amount of GAZP-synthesized data, and cycleconsistency is central to successful adaptation. In principle, GAZP applies to any problems that lack annotated data and differ between training and inference environments. One such area is robotics, where one trains in simulation because it is prohibitively expensive to collect annotated trajectories in the real world. In future work, we will consider how to interpret environment specifications to facilitate grounded adaptation in these other areas. 
