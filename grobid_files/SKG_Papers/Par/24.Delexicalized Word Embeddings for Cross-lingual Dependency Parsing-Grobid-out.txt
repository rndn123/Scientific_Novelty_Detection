title
Delexicalized Word Embeddings for Cross-lingual Dependency Parsing

abstract
This paper presents a new approach to the problem of cross-lingual dependency parsing, aiming at leveraging training data from different source languages to learn a parser in a target language. Specifically, this approach first constructs word vector representations that exploit structural (i.e., dependency-based) contexts but only considering the morpho-syntactic information associated with each word and its contexts. These delexicalized word embeddings, which can be trained on any set of languages and capture features shared across languages, are then used in combination with standard language-specific features to train a lexicalized parser in the target language. We evaluate our approach through experiments on a set of eight different languages that are part the Universal Dependencies Project. Our main results show that using such delexicalized embeddings, either trained in a monolingual or multilingual fashion, achieves significant improvements over monolingual baselines.

Introduction Over the recent years, distributional and distributed representations of words have become a critical component of many NLP systems  (Turian et al., 2010; Collobert et al., 2011) . The reason for this success is that these low-dimensional, dense word vectors address two major problems that appear in many NLP applications, namely data sparsity and the inherent lack of expressivity of onehot representations, and they can also be trained on large unannotated corpora which are cheap to produce and easily available. While they have proven useful in a number of tasks, and especially in dependency parsing  (Koo et al., 2008) , these word vectors are often learned in a generic manner, only using linear bag-of-word contexts (F.  Brown et al., 1992; Mikolov et al., 2013) , without paying much attention to the specifics of the task to be solved. Only very recently, people have tried to learn dependency-based embeddings  (Bansal et al., 2014; Levy and Goldberg, 2014; Madhyastha et al., 2014; Bansal, 2015) , and these new structure-aware representations have been shown to improve parsing performance in a monolingual setting. We would like to generalize this idea to a multilingual setting in a way that allows the transfer of structural information associated with words from one (or several) languages to others. While previous work have attempted to learn multilingual word clusters or embeddings  (Guo et al., 2015)  and use these for cross-lingual transfer, this paper explores a different research direction. Specifically, we investigate the use of vectorial representations in which lemma information have been abstracted away from both words and contexts, hence reduced to their morpho-syntactic attributes. The appeal of these de facto delexicalized word representations is that they further increase the coverage over the available training data, potentially allowing for better generalization. Furthermore, while words tend to be hard to align in a cross-lingual setting due to homonymy and polysemy, morpho-syntactic information tends to be much more robust to language barrier (depending on typological closeness), which make them particularly relevant for cross-lingual transfer. In contrast with delexicalized parsing approaches  (Mc-Donald et al., 2011) , the proposed method uses delexicalization during word embedding learning, not during parsing. Once induced over different source language datasets, these language-shared representations are used as additional features, in combination with standard language-specific features, in a standard lexicalized monolingual graphbased dependency parser for the target language. As far as we know, this is the first attempt at constructing delexicalized word embeddings for cross-lingual dependency parsing. Through the use of these delexicalized word embeddings, we wish to explore two main hypotheses. First and foremost, we want to assess to what extent a parser for a particular language can benefit from using morpho-syntactic regularities extracted from other languages. By comparing the performance of embeddings learned on different sets of source languages in parsing a specific target language, we also hope to assess whether and which typological similarities impact the learning of "good" embeddings. The second hypothesis looks at the choice of context types (sequential vs structural) used for learning these embeddings. That is, we wish to see if the use of syntactic structure delivers better parsing improvements, again in relation to typological similarities or differences. These hypotheses will be tested on treebanks from the recent Universal Dependencies Project  (Nivre et al., 2016) , which provides us with homogeneous syntactic dependency annotations in many languages. In section 2, we provide some background and review previous work on graph-based dependency parsing for mono-and cross-lingual settings and on word embeddings. Section 3 details our approach for learning delexicalized word embeddings and using them in dependency parsing. In section 4, we present some experimental results that show the importance of grammatical embeddings for the task at hand. And finally in section 5, we draw some conclusions and present future perspectives. 

 Preliminaries and Related Work The approach proposed in this paper draws on three different lines of work in dependency parsing. 

 Graph-based Dependency Parsing A dependency tree is a graphical representation of the syntactic structure of a sentence. The task of dependency parsing is to predict the dependency tree of a given sentence x, T x being the set of all its possible trees. Assuming we have access to a scoring function Score(?, ?) that tells how well a dependency tree fits the syntactic structure of a sentence, the goal of dependency parsing is to find the tree ? such that: ? = argmax t?Tx Score(x, t). The size of T x grows exponentially with the length of x, |T x | = |x| |x|?2 , making an exhaustive search for the best tree impractical in most cases. Thus in practice, some simplifying assumptions are made. Here we use the graph-based, edgefactored approach based on the assumption that the score of a tree can be computed as the sum of its edges scores  (McDonald et al., 2005a) . Let score(?, ?) be a scoring function for edges. Score(x, t) = e?t score(x, e). In this case, finding the best parse tree for x boils down to finding the maximum spanning tree in the complete graph whose vertices are the words of x. The score of an edge e is here defined as the dot product between a model w (a weight vector) and the feature vector ?(x, e) of this edge. 

 score(x, e) = w ? ?(x, e). In this paper, we learn the model w in an online manner with the Passive-Aggressive (PA) algorithm described in  (Crammer et al., 2006) . Specifically, we use the PA-II that uses a squared hinge loss in its predicted-loss cost-sensitive version, in which the cost is computed in terms of the symmetric difference on the edges with respect to the target tree. 

 Word Vectors for Dependency Parsing Distributional and distributed word representations are dense vectorial representations of words that live in a multi-dimensional integer or real space whose size is much smaller than the size of the original language vocabulary. There are now a large variety of spectral and neural approaches for learning these representations, including several variants of Principal Component Analysis  (Jolliffe, 2002)  and several deep neural net approaches. Most of these approaches have in common that they solely exploit linear, bag-ofword co-occurrence between words to derive these low-dimensional representations  (Mikolov et al., 2013; Lebret and Collobert, 2014) . Starting with the work of  Koo (2008) , the inclusion of this type of low-dimensional word representations as features has been shown to be a simple yet very effective way of improving dependency parsing performance. The main appeal of these low-dimensional dense representations is that they mitigate major shortcomings of standard one-hot encoding representations which are very sparse and live in very high dimensional spaces, thus lacking in expressivity and hindering generalization. While it is still unclear whether pretrained embeddings  (Andreas and Klein, 2014)  indeed capture interesting syntactic information, more recent work have concentrated on learning dependency-based word embeddings  (Bansal et al., 2014; Levy and Goldberg, 2014; Madhyastha et al., 2014; Bansal, 2015) . In these approaches, word co-occurrences are defined in terms of dependency contexts (x is the governor of word w), instead of linear contexts (x appears within a range of s around word w). Embedding techniques have also started to be applied to objects other than words, namely on dependency relations  (Bansal, 2015; Kiperwasser and Goldberg, 2015) . In this paper, we depart from these approaches by learning a low-dimensional word vector representation that is based only on the morphosyntactic information associated with that word, and learning is performed with simple PCA. Furthermore, we do not use any auto-parsed data in order to avoid errors from spreading into the embedding. Another point is that even if we use a first order parsing model, we use higher-order contexts for learning the embeddings. Bansal (2015) also uses higher-order contexts but combines them with a second-order dependency model. 

 Cross-lingual Dependency Parsing Cross-lingual dependency parsing encompasses several problems ranging from learning a parser for a target language relying solely on annotated data from a source language  (Lynn et al., 2014)  to learning a unique parser that can handle various languages  (Ammar et al., 2016) . Delexicalized parsers  (McDonald et al., 2011)  have been used to avoid the problems the arise from lexical translation. More recently, cross-lingual parsers have been trained using cross-lingual word clusters as well as multilingual word embeddings  (Guo et al., 2015)  to alleviate the lack of lexical information. Our work differs from previous studies in that it assumes the availability of annotated data from the target language for training the parser, but uses multilingual embeddings to benefit from annotated data in other languages. Another important difference is that while multilingual word embeddings are usually used to replace lexical items, we use morpho-syntactic embeddings that are less language dependent. 

 Dependency Parsing with Delexicalized Word Embeddings Standard word embeddings have two major drawbacks for our purposes: they represent word forms which are not easy to transfer from one language to another, and they rely on sequential contexts which are not grammatically motivated for languages with free word order. To circumvent these problems, we propose to create embeddings for morpho-syntactic attribute sets using structural information from dependency trees. As we abstract away the lexical form of words we call our embeddings delexicalized word embeddings. The advantage of embedding sets of morpho-syntactic attributes over word forms is that morpho-syntactic attributes are shared across languages much more frequently than lexical features, and they also tend to be more stable through translation. This allows a more reliable transfer of linguistic knowledge from one language to another. This also increases the vocabulary coverage as the number of morpho-syntactic attributes is far smaller than the number of word forms. Here, we choose to learn representations for full attribute sets (i.e., the set containing all the morphosyntactic attributes associated with a word form) instead of learning representations for single attributes and then composing those for each word. This is in line with standard work embedding approaches which implicitly do the same in learning a different representation for each distinct word form of a lemma (e.g., be, am, is, were) without any further analysis. We discuss this issue in more detail in the experiment section. 

 Delexicalized Words Let us briefly illustrate the kinds of morphosyntactic attributes we want to embed with some examples. For these examples, we are using the notation of the Universal Dependencies project. The English word a is a determiner (its partof-speech or POS is DET), its number is singular and its definiteness is indefinite. As a determiner, it does not have tense or mood, and as most English words, it does not have gen-der. We would thus embed the feature set DET:Definite=Ind|Number=Sing. Looking at an example from a morphologically richer language, we have Finnish verb form oli (meaning was) which we encode as VERB:Mood=Ind|Number=Sing|Person=3|Tense-=Past|VerbForm=Fin|Voice=Act. This means that oli is a finite verb form (not a participle) in the indicative past, its voice is active and its agreement is third person, singular. This gives vocabulary sizes ranging from a hundred or less for analytic languages (English has about 120 such combinations) to several thousands for synthetic ones (the Finnish part of the UD Project has about 4000 such combinations). 

 Structural Contexts Having decided to embed morpho-syntactic attribute sets rather than words, we need to map these new objects to dense vectors in R d . To this end, we apply principal component analysis (PCA) to a co-occurrence matrix (possibly reweighted) whose lines represent our new attribute sets (i.e., our delexicalized words) and whose columns are their contexts, which are also expressed in terms of morpho-syntactic attributes. We describe those contexts later on, but it is worth noting that as we allow them to diverge from the morpho-syntactic features sets, not including every features for example, the number of context can potentially reach a few tens of thousands. As we want to learn embeddings specifically tailored to dependency parsing, we use not only sequential (i.e. linear) contexts but also structural contexts based on dependency trees. Sequential contexts are of the kind: "word x appears in a window of size l centered on word y". Structural contexts are instead defined on the dependency tree: "word x is the governor of word y", or "x is a dependent of y"or again "x is a sibling of y". The new structural contexts can be seen as following a certain path in the dependency tree linking two words. Let up(x, t) be the function that maps a word x to its governor (following the upgoing edge) in tree t. As the root of a tree has no governor we add a dummy token called nil for that purpose. Then down(x, t) is the function that maps x to the set of its dependents in t. 

 down(x, t) = {y ? t | up(y, t) = x} Then we can define our new contexts as combinations of up and down, for example the governor of x is up(x, t), its dependents are down(x, t) and its siblings are down(up(x, t), t) \ {x}. We can also define similar functions over sequences. Let right(x, s) (respectively lef t(x, s)) be the word in sequence s standing just at the right (respectively at the left) of x, then we can also express the sequential contexts in the same framework. We also add two new dummy tokens begin and end to avoid ill definition at the borders of s. Using the notation f n (?) for f ? f ? ? ? ? f (?) where f is applied n times, we have that the window of size l centered on x is {right i (x, s) | i ? [i..l]} ? {lef t i (x, s) | i ? [i. .l]}. We can also define new contexts such as left or right siblings. Let us now turn to an example to make our approach more concrete. Figure  1  shows a dependency tree for a Gothic sentence 1 from the Universal Dependencies Project. Each word is accompanied with its part-of-speech and the corresponding morpho-syntactic attributes. Colored links represent examples of contexts, orange links standing for contexts of length 1 and blue links standing for contexts of length 2. 

 Embedding Delexicalized Words With Structural Contexts Given the above definition of structural contexts, there are still several design parameters to set in order to construct embeddings. First, we distinguish different types of contexts, depending on whether the contexts are sequential (with a distinction between left and right), governor, dependents and siblings (with a distinction between first left sibling, first right sibling and others). Second, there are different context spans, where the span is the maximum length (in term of function applications) of a context. It is equivalent to the window size for sequential context. For example, the sibling context has a fixed span of 2, but the governor of span 2 means the governor of the governor (if it exists, nil otherwise). Third, we distinguish different granularity levels of contexts, corresponding to the maximum number of morpho-syntactic attributes used to model contexts. Like words, contexts are also defined in terms of morpho-syntactic attributes, but we do not require complete sets for them, hence allowing for different granularity Figure  1 : Dependency tree of sentence jah all manageins iddjedun du imma (and all of the crowd went to him) from Ulfila's Bible, from the Gothic part of the Universal Dependencies Project. Under the words are their morpho-syntactic analysis and the colored links represent some possible structural contexts. levels. Taking an example from the sentence of Figure  1 , with a granularity of 0, the word manageins triggers the context NOUN only (i.e., the POS tag alone). With a granularity of 1, it triggers NOUN:Case=Gen, NOUN:Gender=Fem and NOUN:Number=Sing (i.e., the word POS tag is crossed with each of the other attributes). And with full granularity, the union over all subsets of attributes (of size 0 to 3) is combined with the POS tag. This gives 2 a possible contexts for a morphosyntactic attributes set with a attributes. Finally, other parameters are the embedding algorithm (here we use PCA), the matrix normalization method (he we use a simple L2-norm row normalization), the size of the embedding space and the number of contexts used. We can keep all the contexts as their numbers range from 36 (each part-of-speech counted twice for before and after a word and two extra context representing the beginning and the end of the sentence) to a few tens of thousands. 

 From Word Embeddings to Edge Embeddings to Parsing Features As the dependency model factors on edges, we need to turn the word embeddings into edge embeddings. We want an aggregating function that preserves edge orientation and the dependency between the edge endpoints. So we chose to use the outer product of the two original embeddings because it is not commutative and each output dimension depends on the two inputs. Let ? denote the outer product and let u and v be two vectors of R d , then: u ? v = uv This operation yields a matrix in R d?d but we need a vector, so we take the vector vec(uv ). In the following, whenever we use a matrix where a vector is expected, we implicitly assume the presence of a vec(?) 2 . There is a slight scalability problem as the output size grows quadratically with the size of the inputs. But in the case of dependency parsing, where feature vectors are commonly a few millions dimensions long, for typical embeddings size (between 100 and 500) an increase of a few tens of thousands dimensions is acceptable. We would like to use more context than just the two nodes of the edge to represent it. In order to define higher-order contexts, we use triplets of delexicalized words centered on each side of the edge. Specifically, we concatenate the representations associated with the triplets to keep a tractable model of size 9d 2 . Note that applying an outer product across each word of the triplet would be prohibitive, leading to vectors of the order of 10 12 dimensions which would not even fit in memory. More formally, let ? denote the concatenation operator, Dep(e) (respectively Gov(e)) be the dependent (respectively the governor) of an edge e and let emb(?) be the embedding function. ? emb (?, ?) being the embedding part of the feature vector. Using the notation of section 2.1, we have: ? emb (x, e) = i?{?1,0,+1} emb(Gov(e) i ) ? i?{?1,0,+1} emb(Dep(e) i ). score(x, e) = w?(?(x, e) ? ? emb (x, e)). Where ? is a scalar allowing to tune the relative importance of each part of the feature vector, and ?(?, ?) is the traditional dependency feature vector. This follows the same approach as  Kiperwasser and Goldberg (2015)  and  Chen et al.(2014) . As mentioned previously, we have special tokens such as begin and end to represent the word before the beginning and the end of a sentence. We also have a root token that stands for the extra root node added by the graphical dependency model. And we also have a back-off embedding of raw part-of-speech to handle unseen delexicalized words in the test set. 

 Experiments 

 Data set We have tested our parsing models based on delexicalized word embeddings on eight languages using the data of the Universal Dependencies (UD) v1.3  (Nivre et al., 2016) . We have chosen to work on English (en), Basque (eu), Finnish (fi), French (fr), Gothic (got), Hebrew (he), Hungarian (hu) and Romanian (ro). These languages belong to four different families, which are Indo-European (en, fr, got, ro), Finno-Ugric (fi, hu), Semitic (he), and Basque which forms a separate group. They also display various levels of morphological complexity not correlated with the families (en, fr and he do not have case marking while the other five do to various degrees) as well as different grammatical typologies (eu is an ergative language, while the other seven are accusative ones). When several corpora are available for a language, we picked the standard one. Table  1  provides some basic statistics on the language datasets. Also note that our experiments follow the train/dev/test split as pro-vided by the UD Project. 

 Features Dependency Features For parsing, we use standard graphical dependency parsing features that include word forms and POS-tags of edge nodes and surrounding words, edge length and direction and conjunction of those basic features. The main difference with the original MSTparser features of  McDonald et al.(2005b)  is that instead of using truncated words of length 5 as back-off features, we use the lemmas that are provided in the UD Project. 

 Embedding Contexts For the embedding contexts, we consider four parameters, namely the type and span of contexts, the granularity of the morpho-syntactic attributes used in those contexts and the dimension of the embedding space. Regarding the type of contexts we have experiments with three settings: (i) strictly sequential contexts (Seq), (ii) strictly structural contexts that use governor, dependents and siblings information (Struct) and (iii) mixed contexts using both dependency-based and sequential contexts (Mix). Regarding the span, we have tried 1 and 2. Siblings are only used in structural and mixed contexts of span 2 because that is the length of the path between a vertex and its siblings in a tree. We have tried granularity of 0 and full granularity. For the embedding space dimension we have tried 50, 150 and 500 dimensions, or the maximum possible size 3 if smaller than 500. For better readability, we will use shortcuts to refer to the different parameter settings: 1 = (span 1,granularity 0), 2 = (span 2, granularity 0) and 3 = (span 2, full granularity for contexts span 1, granularity 0 for context span 2). 

 Experimental Settings We have carried out two sets of experiments: monolingual and cross-lingual. In the first set, embeddings are learned on a single language training set and then used to parse that same language. In the second set, we have defined several clusters of languages based on their phylogenetic relationship and typological similarities. For a given cluster, embeddings are learned on the training sets of each language in that cluster, and in turn used to parse each language in that cluster. It is possible not to use any data from the target language when learning the embeddings, but in this study we stick to using target language data. Besides embeddings, there are three additional hyper-parameters that need to be tuned: the C aggressiveness parameter of the PA-II algorithm, the scaling factor ? that controls the relative weight of the embedding features in the edge scores, and the number i of training iterations of the PA-II algorithm. We have tuned these hyper-parameters through a grid search on the development sets and picked the values that were behaving best on average, giving C = 0.001, ? = 0.001, i = 5. All the scores reported below are Unlabeled Attachment Scores (UAS) measured on the test sets ignoring the punctuation marks. As a baseline comparison we use our implementation of the MSTparser without morpho-syntactic attributes representation of any kind. We computed the significance of the scores using the McNemar's test. 

 Monolingual Experiments Table  2  displays UAS scores for the monolingual setting. Except for French and Romanian that do not show real improvement, the six other languages show substantial performance increases with the embeddings. These improvements are statistically significant for all languages, except for Basque and Hebrew. One of our hypotheses was that structure is important when learning an embedding for dependency parsing and indeed our results support it. The largest improvements appear with structural or mixed embeddings which rely on syntactic structures. The results for English are significant and close to each other for all types of embeddings, this tends to show that in English, sentence structure and word order are very correlated and both contribute information. Indeed that is what one expects for English which has a rigid syntax and a poor morphology. On the other side of the picture, Basque and Gothic display the largest improvements with structural morpho-syntactic embeddings. This is also expected as those are both morphologically rich languages with more flexible word order. Even though the argument is less clear for Hungarian and Finnish, they both show that structure is important for learning informative dependency embeddings. 

 Cross-lingual Experiments Table  3  summarizes the UAS scores achieved using delexicalized embeddings learned on several languages. Parsing accuracy improve for four languages (en, eu, hu, ro) in the cross-lingual setting compared to the best monolingual setting. While the multilingual embeddings do not outperform the monolingual ones for the other four languages, they still deliver parsing performance that are better than with the baseline MST parser for all languages (but Gothic). That shows that indeed using data from other languages is beneficial for learning good embeddings for dependency parsing, which was the second hypothesis we wanted to evaluate. We also notice that the largest gains are achieved with structural (or mixed) embeddings, giving more evidence to the importance of structure for learning embeddings for dependency parsing. Table  3 : Best UAS scores in cross-lingual setting. Under Best All are the results using the embeddings learned on the set of all languages, while under Best Multilingual are given the best results for each language using only a subset of the languages for learning the embedding. The subscript represents the context types and the number of dimensions of the embedding. The baselines and best monolingual scores are also reported. Significance of scores uses the same conventions as in Table  2 . Let us now look more closely at which groups of source languages are most helpful for specific target languages. First, note in general the best performing embeddings are never those obtained by using the full set of languages (this is only the case for Basque). This is expected since we have picked languages with very different grammars thus the full embeddings can be very noisy with regard to a single language. In fact, the Basque results are rather surprising since this language differs the most from the others in terms of morphology, but also one for which we had rather small training data. The best parsing performance for English are achieved when using additional data from Gothic. As both are Germanic languages, this tends to show that data from genetically related languages can help in learning a better representation. Even though they do not achieve the best results, similar patterns occur for French (French and Romanian are Romance languages and English has been heavily influenced by Romance languages) and for Gothic (Gothic and Romanian are both Indo-European languages). Similarly, Hungarian and Romanian reach their best scores when parsed with typologically close languages that have case marking. And again, Basque, Finnish and Gothic display similar patterns. Hebrew performs reasonably well with French and English which are two languages with fairly restricted word orders. As to why some languages have better monolingual parsing results than multilingual results, we think this is at least partly due to the lack of flexibility of our model. That is, morpho-syntactic attributes sets are treated independently from one another making some of them hard to use in the cross-lingual setting. For example, Hebrew verbs display 'binyanim' (internal flection classes) that do not appear in any other language, similarly Finnish has a lot of cases that are not found in other languages. Those are indeed two languages that do not perform well with other languages. We thus believe that introducing compositionality in our embedding model should help in solving those problems and enhance the results further. 

 Conclusion In this paper, we have described a new way to induce multilingual embeddings, namely delexicalized word embeddings, that solely rely on the morpho-syntactic attributes of words which can easily be transferred across languages. This new approach to multilingual embeddings allows one to use annotated data from other languages to further improve the resulting embeddings and parsers, avoiding the problems that arise from lexicon alignment or cross-lingual word clustering. In line with previous recent work, we have shown that the syntactic structure is crucial when it comes to learning embeddings for dependency parsing. In addition, we have seen that the impact of the structure on the quality of an embedding depends on language typology. In future work, we should see how those morpho-syntactic embeddings can help in labeled dependency parsing, as edge types and word morpho-syntactic attributes are related. We would like to investigate the impact of the embedding algorithms (here we use PCA) on the final embeddings. We would also like to try other ways to turn word embeddings into edge embeddings in order to benefit more from the local neighborhoods. Finally, we would like to work on the embedding of clusters of morpho-syntactic attributes to induce higher-order embeddings for noun-phrases or verb-phrases and to deal with agreement and morpho-syntactic attributes hierarchy. 6 Acknowledgment Table 1 : 1 Number of sentences and words in the training and test sets, number of delexicalized word and of POS-tags for each language. The total number or embedded tokens is |morpho-syntactic feature set| + |P OS| + 3 because of the POS back-offs and the special begin, end and root tokens. Train Test sentences words sentences words morpho-syntactic tokens POS English 12 543 204 586 2 077 25 096 118 17 Basque 5 396 72 974 1 799 24 374 845 16 Finnish 12 217 162 721 648 9 140 1 592 15 French 14 557 356 216 298 7 018 195 17 Gothic 4 360 44 722 485 5 158 662 13 Hebrew 5 142 15 558 491 12 125 480 16 Hungarian 1 433 23 020 188 4 235 651 16 Romanian 4 759 108 618 794 18 375 412 17 
