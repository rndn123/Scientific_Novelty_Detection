title
Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation

abstract
Maintaining a consistent personality in conversations is quite natural for human beings, but is still a non-trivial task for machines. The persona-based dialogue generation task is thus introduced to tackle the personalityinconsistent problem by incorporating explicit persona text into dialogue generation models. Despite the success of existing personabased models on generating human-like responses, their one-stage decoding framework can hardly avoid the generation of inconsistent persona words. In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance.

Introduction In an open-domain conversation scenario, two speakers conduct open-ended chit-chat from the initial greetings and usually come to focus on their characteristics, such as hobbies, pets, and occupations, etc., in the course of the conversation. For humans, they can easily carry out conversations according to their personalities , but fulfilling this task is still a challenge for recent neural dialogue models  (Welleck et al., 2019) . One main issue is that these models are typically trained over millions of dialogues from different speakers, and the neural dialogue models have a propensity to mimic the response with the maximum likelihood in the training corpus  (Li et al., 2016b) , which results in the frequent inconsistency in responses . Another issue Figure  1 : A common problem for persona-based dialogue models is that they can hardly avoid the generation of inconsistent persona words. Although the model generates a response which looks good, it is an inconsistent one. With further rewriting, the model can focus more on improving persona consistency. is the user-sparsity problem  (Qian et al., 2017)  in conventional dialogue corpora  (Serban et al., 2015) . Some users have very few dialogue data, which makes it difficult for neural models to learn meaningful user representations  (Li et al., 2016b) . To alleviate the above issues,  introduced the Persona-Chat dataset to build more consistent dialogue models. Different from conventional dialogue corpora, this dataset endows dialogue models with predefined personas, which is in the form of textually described profile (as shown in the first line of Figure  1 ). The persona-based dialogue models also adopt an encoder-decoder architecture and are enhanced with persona encoding components, such as memory network  (Sukhbaatar et al., 2015)  and latent variable  (Kingma and Welling, 2013) . These models turn out to produce more consistent responses than the persona-free ones . Despite the successful application of the encoderdecoder framework in persona-based dialogue models, one concern is that they lack extra attention to the key persona information. The model will learn to minimize the overall loss of every decoded word, but this may lead to the neglect of the key personas: change of one persona-related word may not significantly affect the overall loss, but could turn a good response into a totally inconsistent one. As shown in Stage 1 of Figure  1 , only one improper word "Colorado" leads the response to be inconsistent. A desirable solution should be able to capture personas and automatically learn to avoid and refine inconsistent words before the response. In this paper, we present a Generate-Delete-Rewrite framework, GDR, to mitigate the generation of inconsistent personas. We design three stages specifically for the goal of generating persona consistent dialogues: The first Generate stage adopts a transformer-based generator to produce a personabased response prototype. The second Delete stage employs a consistency matching model to identify inconsistencies and delete (by masking) the inconsistent words from the prototype. Finally, in the Rewrite stage, a rewriter polishes the masked prototype to be more persona consistent. To examine the effectiveness of our GDR model, we carried out experiments on the public available Persona-Chat dataset . We summarize the main contributions as follows: ? A three-stage end-to-end generative framework, GDR, was proposed for the generation of persona consistent dialogues. ? A matching model was integrated into the generation framework to detect and delete inconsistent words in response prototype. ? Experimental results show the proposed approach outperforms competitive baselines on both human and automatic metrics. 

 Related Work End-to-end dialogue generation approaches are a class of models for building open-domain dialogue systems, which have seen growing interests in recent years  (Vinyals and Le, 2015; Shang et al., 2015; Serban et al., 2016; Li et al., 2016c; Li et al., 2017) . These dialogue models adopted recurrent units in a sequence to sequence (seq2seq) fashion  (Sutskever et al., 2014) . Since the transformer has been shown to be on par with or superior to the recurrent units  (Vaswani et al., 2017) , some dialogue models began to take advantage of this architecture for better dialogue modeling  Su et al., 2019) . Besides the advancements in dialogue models, the emergence of new dialogue corpus has also contributed to the research field.  introduced the Persona-Chat dataset, with explicit persona texts to each dialogue. Based on seq2seq model and memory network, they further proposed a model named Generative Profile Memory Network for this dataset. Following this line,  Yavuz et al. (2019)  designed the DeepCopy model, which leverages copy mechanism to incorporate persona texts.  integrated persona texts into the Per-CVAE model for generating diverse responses. However, the persona-based models still face the inconsistency issue  (Welleck et al., 2019) . To model the persona consistency,  Welleck et al. (2019)  annotated the Persona-Chat dataset and introduced the Dialogue Natural Language Inference (DNLI) dataset. This dataset converts the detection of dialogue consistency into a natural language inference task  (Bowman et al., 2015) . Personalized dialogue generation is an active research field  (Li et al., 2016b; Qian et al., 2017; Zheng et al., 2019a,b; . In parallel with this work,  Song et al. (2019b)  leveraged adversarial training to enhance the quality of personalized responses.  incorporated mutual persona perception to build a more explainable  dialogue agent. Other relevant work lies in the area of multi-stage dialogue models  (Lei et al., 2020) . Some retrieval-guided dialogue models  Wu et al., 2019; Cai et al., 2019a,b; Su et al., 2020 ) also adopted a multi-stage framework, but the difference from our work is obvious: we generate the prototype rather than retrieve one. A high-quality retrieved response is not always available, especially under the persona-based setting. 

 Model 

 Overview In this work, we consider learning a generative dialogue model to ground the response with explicit persona. We focus on the persona consistency of single-turn responses, and we leave the modeling of multi-turn persona consistency as future work. Formally, we use uppercase letters to represent sentences and lowercase letters to represent words. Let Q = q 1 , q 2 , ..., q n denotes the input query with n words, and let P = {P (1) , P (2) , ..., P (k) } (3) Rewrite be the k different persona texts, where P (i) = p (i) 1 , p (i) 2 , ..., p (i) m i is the i-th persona text with m i words. Our goal is to learn a dialogue model M to generate a response ? = y 1 , y 2 , ..., y k , which is consistent with the persona, based on both query Q and persona P . In abbreviation, ? = M(Q, P ). More concretely, as shown in Figure  2 , the proposed model M consists of three parts: 1) Prototype generator G. This component takes persona texts and query as input and generates a response prototype for further editing. It adopts an encoder-decoder architecture  (Sutskever et al., 2014) , with the transformer  (Vaswani et al., 2017)  applied in both the encoder and the decoder. 2) Consistency matching model D. This model is designed to detect and delete those words in the prototype that could lead to inconsistency. We train this model in a natural language inference fashion on the DNLI  (Welleck et al., 2019)  dataset. 3) Masked prototype rewriter R. The rewriter learns to rewrite the response prototype to a more consistent one. It is also a transformer decoder, which adopts a similar architecture as the decoder of G. The difference lies in that it takes the masked prototype, rather than the query, as input. 

 Generate: Prototype Generator We apply the encoder-decoder structure to build our prototype generator G. For the encoder, we use the self-attentive encoder in the transformer. For the decoder, built upon the transformer decoder, we propose a tuple-interaction mechanism to model the relations among persona, query, and response. 

 Self-Attentive Encoder As the persona P is composed of several sentences, we unfold all words in P into a sequence p (1) 1 , p (1) 2 , ..., p (i) m j , ..., p (k) m k . Then we use the self-attentive encoder  (Vaswani et al., 2017)  to compute the representations of the persona texts and query separately. The multi-head attention is defined as MultiHead(Q, K, V ), where Q,K,V are query, key, and value, respectively. The encoder is composed of a stack of N G identical layers. Take the first stack encoding of P for example: V  (1)  p = MultiHead(I(P ), I(P ), I(P )), (1) O (1) p = FFN(V (1) p ), (2) FFN(x) = max(0, xW 1 + b 1 )W 2 + b 2 , (3) where V  (1)  is the first layer result of the multi-head self-attention and I(?) is the embedding function of the input. The input embedding for word w i is the sum of its word embedding and position embedding. O  (1)  denotes the output of the first layer feed-forward network. For other layers: V (n) p = MultiHead(O (n?1) p ), O (n?1) p ), O (n?1) p ), (4) O (n) p = FFN(V (n) p ), (5) where n =2,...,N G . We applied layer normalization to each sublayer by LayerNorm(x + Sublayer(x)). Q is encoded in the same way. After N G identical layers, we can get the final representations O (N G ) p and O (N G ) q , where O (N G ) p and O (N G ) q are the encoded persona and encoded query, respectively. 

 Tuple-Interaction Decoder In the decoding phase, there are three types of information, persona P , query Q, and response Y , which make up a tuple (P ,Q,Y ). Accordingly, three inter-sentence relations need to be considered: (1) The alignment between Q and Y is beneficial to yield better results  (Bahdanau et al., 2014) . (  2 ) As the persona is composed of several sentences and describes different aspects, we need to find the most relevant persona information according to the relations between P and Y. (3) We also want to know whether the query needs to be answered with the given persona. Thus we should take the relations between P and Q into account. Considering the above factors, we design a twolayer tuple-interaction mechanism in the decoder, as shown in the first part of Figure  2 . There are three attentions in two layers: query attention (Q-Attn) and persona attention (P-Attn) in the first layer, and persona-query attention (PQ-Attn) in the second layer. N G such identical layers compose of the decoder. For the first layer: V (1) y = MultiHead(I(Y ), I(Y ), I(Y )), (6) E (1) = MultiHead(V (1) y , O (N G ) p , O (N G ) p ), (7) F (1) = MultiHead(V (1) y , O (N G ) q , O (N G ) q ), (8) T (1) = MultiHead(E (1) , F (1) , F (1) ), (9) O (1) dec = FNN(mean(E (1) , F (1) , T (1) )), (10) where E (1) and F  (1)  are the results of the first layer P-Attn and Q-Attn. T  (1)  is the result of the first layer PQ-Attn. O (1) dec denotes the first layer output. Note that the Y here is masked to ensure depending only on the known words  (Vaswani et al., 2017) . Repeatedly, for other layers: V (n) y = MultiHead(O (n?1) dec ), O (n?1) dec ), O (n?1) dec ), (11) O (n) dec = FNN(mean(E (n) , F (n) , T (n) )), (12) where n =2,...,N G . After N G layers, the decoder output O (N G ) dec is projected from hidden size to vocabulary size, then followed up by a softmax function to get the words' probabilities: Prob (1) = SoftMax(O (N G ) dec W 3 + b 3 ), ( 13 ) where W 3 is a hidden size?vocabulary size weight matrix and b 3 is the bias term with vocabulary size dimension. And Prob  (1)  denotes the output distribution of the first stage. Now we can get the response prototype ? (1) from the Prob  (1)  .  

 Delete: Consistency Matching Model The goal of the consistency matching model D is to reveal word-level consistency between the persona texts and the response prototype, thus the inappropriate words can be deleted from the prototype. This model is trained to estimate the sentencelevel entailment category  (Bowman et al., 2015)  of a response for the given persona texts, which includes entailment, neutral and contradiction. The key is that if the category is not entailment, we can delete the most contributing words by replacing them with a special mask token, thus giving the model a chance to rephrase. The attention weights can measure each word's contribution. The architecture of our consistency matching model is shown in Figure  3 . From bottom to top are the self-attentive encoding layer, cross attention layer, and consistency matching layer. As described in section 3.2, the self-attentive encoder (SAE(?)) performs self-attention over the input to get sentence representations. Because the task of consistency matching is quite different from dialogue generation, we did not share the encoders between the generator G and matching model D: ? = SAE D (P ), ( 14 ) B = SAE D ( ? (1) ), ( 15 ) where ? is a hidden size ? n matrix. ? = [? 1 , ?2 , ..., ?n ] and B = [ b1 , b2 , ..., bm ]. The n and m are the number of words in persona P and response prototype ? (1) . Here we applied average pooling stragety  (Liu et al., 2016; Chen et al., 2017)  to get the summary representations: ?0 = n i=1 ?i n , (16) and we can get the response attention weights and attentive response representations by: W b = ? 0 B, (17) B = W b B , (18) where W b is attention weights and B is response representations. Similarly, we can get W a and A. Once A and B are generated, three matching methods  (Chen et al., 2017)  are applied to extract relations: concatenation, element-wise product, element-wise difference. The results of these matching methods are concatenated to feed into a multi-layer perceptron, which has three layers and tanh activation in between. The output is followed up by a SoftMax function to produce probabilities. In the inference process, as shown in Figure  3 , the response attention weights W b is leveraged to illustrate the inconsistent words, which will be deleted 1 . In practice, we use a simple heuristic rule for deleting words: as long as the category is not entailment, we will delete 10% of the words (at least one word) 2 , with the highest attention weight, in the prototype ? (1) . In this way, we get the masked prototype ? (2) . 

 Rewrite: Masked Prototype Rewriter The rewriter R takes the masked prototype and persona as input and outputs the final response. R is also a transformer decoder, which is similar to the decoder of G in section 3.2, but with a minor difference: the masked prototype is close to the target response, thus the direct attention between the prototype and target response is needless. The architecture of R can be seen in the third part of Figure  2 , which can be formalized as:  is the encoded persona. After N R identical layers, the same generation process as in G is applied to the O O (N G ) mp = SAE G ( ? (2) ), (19) V (n) = MultiHead(O (n?1) rw ), O (n?1) rw ), O (n?1) rw ), (20) S (n) = MultiHead(V (n) , O (N G ) p , O (N G ) p ), (21) K (n) = MultiHead(S (n) , O (N G ) mp , O (N G ) mp ), (22) O (n) rw = FNN(mean(S (n) , K (n) )), (23) (N R ) rw , and we can get the final response ? (3) . 

 Training The consistency matching model D is trained separately from the prototype generator G and rewriter R. As forementioned, the matching model D is trained in a natural language inference fashion on the DNLI dataset  (Welleck et al., 2019) , which has been well defined by the previous studies  (Bowman et al., 2015; Chen et al., 2017; Gong et al., 2018) . We minimize the CrossEntropy loss between the outputs of D and the ground truth labels. The G and R share the same training targets. We trained them by the standard maximum likelihood estimate. Notice that there are two different deleting strategies in training: (1) In the warm-up phase, because the G can hardly generate high-quality prototypes at this period, we randomly delete each word, with a 10% probability, from the prototype. (2) After that, the trained consistency matching model D is leveraged to delete words. 

 Experiments 

 Datasets We carried out the persona-based dialogue generation experiments on the public available Persona-Chat dataset . Furthermore, we trained the consistency matching model on the recently released Dialogue Natural Language Inference (DNLI) dataset  (Welleck et al., 2019) . We show the statistics of the Persona-Chat dataset in Table  1 . The DNLI dataset  (Welleck et al., 2019)  is an enhancement to the Persona-Chat. It is composed of persona-utterance pairs from the Persona-Chat, and these pairs are further labeled as entailment, neutral, and contradiction. Some statistics of this dataset are given in Table  2 . 

 Compared Models To the best of our knowledge, this is an early work in modeling explicit persona consistency. To show the effectiveness of our models, we mainly compare it with the persona-based dialogue models: ? S2SA S2SA is an RNN-based attentive seq2seq model  (Bahdanau et al., 2014) . It only takes the query as input. ? Per-S2SA This is a seq2seq model that prepends all persona texts to the query as input . ? GPMN Generative Profile Memory Network is an RNN-based model that encodes persona texts as individual memory representations in a memory network . ? DeepCopy An RNN-based hierarchical pointer network, which leverages copy mechanism to integrate persona  (Yavuz et al., 2019) . ? Per-CVAE This is a memory augmented CVAE model to exploit persona texts for diverse response generation . ? Transformer Different from the RNN-based models, transformer is a self-attention based sequence transduction model  (Vaswani et al., 2017) . The persona texts are concatenated to the query to serve as its input. 

 Experimental Settings For all the RNN-based baseline models, they are implemented by two-layer LSTM networks with a hidden size 512. For the Transformer, the hidden size is also set to 512, and the layers of both encoder and decoder are 3. The number of heads in multi-head attention is 8, and the inner-layer size of the feedforward network is 2048. The word embeddings are randomly initialized, and the embedding dimension of all models is set to 512. Our model applies the same parameter settings as the transformer. The number of layers N G = N D = N R = 3. G and R share the word embeddings, but the matching model D uses independent embeddings. We use token-level batching with a size 4096. Adam is used for optimization, and the warm-up steps are set to 10,000. We implemented the model in OpenNMT-py  (Klein et al., 2017) . 

 Evaluation Metrics In the evaluation, there are two essential factors to consider: persona consistency and response quality. We apply both human evaluations and automatic metrics on these two aspects to compare different models. 

 Human Evaluation We recruit five professional annotators from a third-party company. These annotators have high-level language skills but know nothing about the models. We sampled 200 persona-query-response tuples per model for evaluation. Duplicated queries (such as greetings which appear more than once) will not be sampled twice. First, we evaluate the persona consistency of a response. The annotators are asked to decide whether the response is consistent with the given persona. 0 indicates irrelevant or contradictory and 1 indicates consistent (Const.). Second, we evaluate the quality of a response on three conventional criteria: fluency (Fluc.), relevance (Relv.), and informativeness (Info.). Each aspect is rated on five-scale, where 1, 3, and 5 indicate unacceptable, moderate, and excellent performance, respectively. 2 and 4 are used for unsure.  Dziri et al. (2019)  has shown that natural language inference based entailment ratio can be used as an indicator of dialogue consistency. Here we trained two well-performed NLI models, DIIN  (Gong et al., 2018)  and BERT  (Devlin et al., 2019) , to automatically predict the category of persona-response pairs, and we calculated the ratio of entailment as an additional reference to the persona consistency. In our experiments, DIIN and BERT achieved 88.78% and 89.19% accuracy on the DNLI test set, respectively, compared with previous best results 88.20%. The trained models are then leveraged for calculating entailment ratios. Two model-based entailment ratios are abbreviated as Ent diin and Ent bert . 

 Automatic Metrics For dialogue quality, we follow  to use perplexity (PPL) to measure the fluency of responses. Lower perplexity means better fluency. Besides, we also use Dist-1 / Dist-2  (Li et al., 2016a)     

 Main Results We report the main evaluation results in Table  3 . Compared with baseline methods, our GDR model obtains the highest consistency score of 49.2% in human evaluation, which is significantly better than other methods. The target responses in the sampled data are also annotated, and 65.4% of them expressed persona information. Moreover, the two model-based entailment ratios, which are calculated on the whole test set, also prove the effectiveness of our GDR model. Although the two NLI models differ in results, our GDR model ranks first under the evaluation of both DIIN and BERT. For dialogue quality, our proposed model has a remarkably lower perplexity of 16.7 than all other baseline methods. An analysis can be seen in Section 4.6. Besides, our distinct-2 metric is even significantly better than the Per-CVAE model, which is designed to generate diverse responses. Additionally, we carried out pairwise response comparison to see the dialogue quality gains. We report the results in Table  4 . While the GDR model significantly improves persona consistency, it can still generate high-quality responses like the transformer and GPMN. 

 More Analysis As the proposed model achieves better performance than baseline methods, we turn to ablation tests to further quantify the contributions made by different components. We ablated our model through several different approaches: ? GR It removes the matching model D, i.e., generates a prototype and rewrites it directly. ? GRdR This approach replaces the matching model D with 10% random deleting (Rd), thus to see if the masked prototype, extracted by our matching model D, is beneficial. ? G Our model's generator, without further consistency matching and rewriting. ? T It is a transformer generator but removes the tuple-interaction in section 3.2 and directly concatenates persona texts to the query. This model is equivalent to the vanilla transformer. We report the results in Table  5 . First, we look into which components contribute to the consistency. As seen, from T, G, GR to GDR, every step has an observable improvement in Const., indicating the effectiveness of our model's design. Both the tuple-interaction in G and the rewriting process in R contribute to the improvements of persona consistency. The GRdR approach, with nothing different from GDR but a random deleting strategy, serves as a foil to our GDR model, which indicates a well-learned consistency matching model is of great benefit to our three-stage generation framework to generate persona consistent dialogues. Second, we investigated the improvement of our perplexity. As we can see, the one-stage transformer approaches G and T have a perplexity higher than 26. In contrast, after we add the rewriter R, the perplexity of all approaches has a significant decline, no matter whether there is a matching model D. Lower perplexity means lower cross-entropy, which indicates the responses from the models have more ground truth words. To some extent, perplexity verifies the human evaluation results of the consistency. One reason for this improvement could be that the rewriter works like a denoising autoencoder  (Vincent et al., 2008) , and it can focus more on the reconstruction of the missing information of sequence itself, rather than learning to map a sequence to an entirely different one. We observed that the relevance scores of GR, GRdR, and G are a little inferior to the T. Even the GDR model is not significantly better than T on the relevance score. One plausible explanation is that all these models are specially designed for integrating persona information, although they obtain much better consistency score, it may come at the cost of relevance score. Moreover, we compared the GDR's response quality with three ablated models and reported it in Table  6 . As we can see, the deleting and rewriting, which are designed for improving consistency, also have a positive effect on the dialogue quality. At last, we presented some generated examples in Table  7 , together with the visualization of attention weights from match module D. In the first case, although the generated prototype is neutral regarding the persona, the word "nurse" is still masked according to our strategy. And after the rewriting stage, the final response expresses persona. In the second case, the prototype is potentially contradictory to the persona, and the keyword is successfully deleted by the matching model D. In the third case, the prototype is consistent with the persona, and no word is deleted. As a result, the final output response is the same as the output of no deletion model GR. In these cases, both consistency and quality are improved after the final rewriting. 

 Conclusion and Future Work In this paper, we presented a three-stage framework, Generate-Delete-Rewrite, for persona consistent dialogue generation. Our method adopts transformer architecture and integrates a matching model to delete the inconsistent words. Experiments are carried out on public-available datasets. Both human evaluations and automatic metrics show that our method achieves remarkably good performance. In the future, we plan to extend our approach to improve the consistency of multi-turn dialogues. Figure 2 : 2 Figure2: The overall architecture of our three-stage GDR model, including a prototype generator (Generate stage), a consistency matching model (Delete stage), and a masked prototype rewriter (Rewrite stage). The italics denote the inputs of each stage, and the boldfaces denote the outputs. All the attentions (attn) here refer to the multi-head attention. For the sake of brevity, we omitted some layers of the transformer in this figure. 
