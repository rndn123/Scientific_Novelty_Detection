title
RMM: A Recursive Mental Model for Dialogue Navigation

abstract
Language-guided robots must be able to both ask humans questions and understand answers. Much existing work focuses only on the latter. In this paper, we go beyond instruction following and introduce a two-agent task where one agent navigates and asks questions that a second, guiding agent answers. Inspired by theory of mind, we propose the Recursive Mental Model (RMM). The navigating agent models the guiding agent to simulate answers given candidate generated questions. The guiding agent in turn models the navigating agent to simulate navigation steps it would take to generate answers. We use the progress agents make towards the goal as a reinforcement learning reward signal to directly inform not only navigation actions, but also both question and answer generation. We demonstrate that RMM enables better generalization to novel environments. Interlocutor modelling may be a way forward for human-agent dialogue where robots need to both ask and answer questions.

Introduction A key challenge for embodied language is moving beyond instruction following to instruction generation, which can require understanding the listener. The turn-based dialogue paradigm raises a myriad of new research questions, from grounded versions of traditional problems like co-reference resolution  (Das et al., 2017a)  to explicitly modeling theory of mind in order to consider the listener's ability to understand generated instructions  (Bisk et al., 2020) . In this paper, we develop end-to-end dialogue agents to navigate photorealistic, indoor scenes to reach goal rooms. We train agents using the human-human Collaborative Vision-and-Dialogue Navigation (CVDN)  dataset. CVDN dialogues are turn-based, with a navigator following guide instructions and asking questions when needed. Modeling turn-based dialogues involves four core challenges: C1 A navigator deciding when to ask a question. C2 Generating navigator questions. C3 Generating guide question answers. C4 Generating navigator actions. Prior work has addressed individual components of turn-based dialogue modeling. This work is the first to train navigator and guide agents to perform end-to-end, collaborative dialogues with question generation (C2), question answering (C3), and navigation (C4) conditioned on dialogue history. Theory of mind  (Gopnik and Wellman, 1992 ) posits that efficient questions and answers build on a shared world of experiences and referents. To communicate efficiently, people model both a listener's mental state and the effects of their actions on the world. Modeling future worlds in navigation  (Anderson et al., 2019)  and control  (Paxton et al., 2019)  are open research questions, and we approximate solutions through a Recursive Mental Model (RMM) of a conversational partner. Our agent spawns instances of itself to simulate the ef-fects of dialogue acts before asking a question or generating an answer to estimate their effects on navigation. Viewed as a single system, the agents cooperatively search through the space of dialogues to efficiently perform embodied navigation. 

 Related Work and Background We build on research in multimodal navigation and the wider literature involving goal oriented dialogue. Table  1  summarizes how our work differs from existing work in vision-and-language navigation and task-oriented dialogue modelling. Instruction Following tasks an embodied agent with interpreting natural language instructions and visual observations to reach a goal  (Jayannavar et al., 2020; Wang et al., 2019; Ma et al., 2019; Anderson et al., 2018; Chen and Mooney, 2011) . These instructions describe step-by-step actions the agent needs to take, and can involve the creation of speaker models for data augmentation that provide additional instructions  (Fried et al., 2018) . This paradigm has been extended to longer trajectories and outdoor environments , as well as to agents in the real world  (Chai et al., 2018; Tellex et al., 2014) . In this work, we focus on the the simulated, photorealistic indoor environments of the MatterPort dataset  (Chang et al., 2017) , and go beyond instruction following alone to a twoagent dialogue setting. Navigation Dialogues task a navigator and a guide to cooperate to find a destination. Previous work includes substantial information asymmetry between the navigator and guide  (de Vries et al., 2018; Narayan-Chen et al., 2019) . Information asymmetry can take the form of the navigator seeing a bird's eye, abstract semantic map while the guide sees egocentric simulation frames  (de Vries et al., 2018) , affecting the kind of dialog possible when low-level visual cues cannot be grounded by the navigator. Other work only investigates the navigation portion of the dialogue without considering text question generation and answering . Going beyond models that perform navigation from dialogue history alone  (Wang et al., 2020; Zhu et al., 2020; , or decide when to ask navigator questions but do so as a simple "help" flag with oracle responses  (Chi et al., 2020; , in this work we train two agents: a navigator agent that asks questions, and a guide agent that answers those questions. 

 Representative Work C1 C2 C3 C4 ; by doing so, our work becomes the first to train two agents jointly on multi-turn dialogues where agents both produce and consume task-relevant language. We eschew only the challenge of deciding when to ask questions (C1), using a fixed heuristic instead. Multimodal Dialogue takes several forms. In Visual Dialogue  (Das et al., 2017a) , an agent answers a series of questions about an image that may require dialogue context. Reinforcement learning gives strong performance on this task  (Das et al., 2017b) , and such paradigms have been extended to producing multi-domain visual dialogue agents  (Ju et al., 2019) .  GuessWhat (de Vries et al., 2017)  presents a similar paradigm, where agents use visual properties of objects to reason about which referent meets various constraints. Identifying visual attributes can also lead to emergent communication between pairs of learning agents  (Cao et al., 2018) . Goal Oriented Dialogue systems can help a user achieve a predefined goal, from booking flights to learning kitchen tasks  Vlad Serban et al., 2015; Bordes and Weston, 2017; Chai et al., 2018) . Modeling goal-oriented dialogue requires skills that go beyond language modeling, such as asking questions to clearly define a user request, querying knowledge bases, and interpreting results from queries as options to complete a transaction. Many recent task oriented systems are data-driven and trained end-to-end using semisupervised or transfer learning methods  (Ham et al., 2020; Mrksic et al., 2017) . However, these datadriven approaches may lack grounding between the text and the environment state. Reinforcement learning-based dialogue modeling  (Su et al., 2016; Peng et al., 2017; Liu et al., 2017)  can improve completion rate and user experience by helping ground conversational data to environments. 

 Task and Data Our work creates a two-agent dialogue task, building on the CVDN dataset  of human-human dialogues. In that dataset, a human N avigator and Guide collaborate to find a goal room containing a target object. The N avigator moves through the environment, and the Guide views this navigation until the N avigator asks a question in natural language (C1, C2). Then, the Guide can see the next few steps a shortest path planner would take towards the goal, and produces a natural language response (C3). Dialogue continues until the N avigator arrives at the goal (C4). We model this dialogue between two agents: 1. Questioner (Q) & Navigator (N ) 2. Guide (G) We split the first agent into its two roles: question asking (C2) and navigation (C4). As input, the agents receive the same data as their human counterparts in CVDN. Specifically, both agents (and all three roles) have access to the entire dialogue and visual navigation histories, in addition to a textual description of the target object (e.g., a plant). The N avigator uses this information to execute on a sequence of actions composed of: forward, left, right, look up, look down, and stop. The Questioner asks for specific guidance from the Guide. The Guide is presented with the navigation and dialogue histories as well as the next five shortest path steps to the goal, given as a sequence of image observations those steps produce. Agents are trained on human-human dialogues of natural language questions and answers from CVDN. Individual question-answer exchanges in that dataset are underspecified and rarely provide simple step-by-step instructions like "straight, straight, right, ...". Instead, exchanges rely on assumptions of world knowledge and shared context  (Frank and Goodman, 2012; Grice et al., 1975) , which manifest as instructions rich with visuallinguistic co-references such as should I go back to the room I just passed or continue on? The CVDN release does not provide any baselines or evaluations for the interactive dialogue setting we present, and instead focuses solely on navigation (C4). We use the same metric as that work, "Goal Progress" in meters-the distance reduction between the N avigator's starting position and ending position with respect to the goal location. Dialogue navigation proceeds by iterating through the three roles until either the N avigator Algorithm 1: Dialogue Navigation loc = p0; hist = t0; a ? N (hist); loc, hist = update( a, loc, hist); while a = STOP and len(hist) < 20 do q ? Q(hist, loc) ; // Question s = path(loc, goal, horizon = 5) ; o ? O(hist, loc, q, s) ; // Answer hist ? hist + (q, o); for a ? N (hist) do loc ? loc + a ; // Move hist ? hist + a; end end return (goal ? t0) ? (loc ? t0) chooses to stop or a maximum number of turns are played (Algorithm 1). In addition to "Goal Progress", we report BLEU scores  (Papineni et al., 2002)  for evaluating the generation of questions and answers by comparing against human questions and answers. Note, in our dialogue setting, Goal Progress also implicitly measures the utility of generated language and is therefore complementary to BLEU when evaluating utility versus fluency. 

 Models We introduce the Recursive Mental Model (RMM) as an initial approach to our new full dialogue CVDN task formulation. Key to this approach is allowing component models (N avigator, Questioner, and Guide) to learn from each other and roll out possible dialogues and trajectories. We compare our model to a traditional sequence-to-sequence baseline, and we explore data augmentation using the Speaker-Follower method  (Fried et al., 2018) . 

 Sequence-to-Sequence Architecture The underlying architecture, shown in Figure  2 , is shared across all approaches. The core dialogue tasks are navigation action decoding and language generation for asking and answering questions. We present three sequence-to-sequence  (Bahdanau et al., 2015)  models to perform as N avigator, Questioner, and Guide. The models rely on an LSTM  (Hochreiter and Schmidhuber, 1997)  encoder for the dialogue history. To encode visual observations, our models take the penultimate ResNet  (He et al., 2015)  layer as the image observation. Future work may explore different and more nuanced encoding architectures.  V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t > I t < l a t e x i t s h a 1 _ b a s e 6 4 = " m C k A j n w p s H B N 5 G V Z j Z G o + A f i 3 t o = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 o r e K 9 g P a U D b b T b t 0 s w m 7 E 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G N 1 O / 9 c S 1 E b F 6 x H H C / Y g O l A g F o 2 i l h 7 s e 9 k p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i G n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 M r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 1 q x T u v V O 8 v y r X r P I 4 C H M M J n I E H l 1 C D W 6 h D A x g M 4 B l e 4 c 2 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E q 8 I 2 4 < / l a t e x i t > a t 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0  1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e O q L F S 6 6 m X 8 X N v 0 i u V 3 Y o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 5 S G C a p 1 x 3 M T 4 2 d U G c 4 E T o r d V G N C 2 Y g O s G O p p B F q P 5 u d O y G n V u m T M F a 2 p C E z 9 f d E R i O t x 1 F g O y N q h n r R m 4 r / e Z 3 U h F d + x m W S G p R s v i h M B T E x m f 5 O + l w h M 2 J s C W W K 2 1 s J G 1 J F m b E J F W 0 I 3 u L L y 6 R 5 U f G q l e v 7 a r l 2 k 8 d R g G M 4 g T P w 4 B J q c A d 1 a A C D E T z D K 7 w 5 i f P i v D s f 8 9 Y V J 5 8 5 g j 9 w P n 8 A B C W P Y Q = = < / l a t e x i t > Attend w i < l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4    = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B o 7 V V g u V O G d p F n 5 w r R U y K C o = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W t B / Q h r L Z b t q l m 0 3 Y n Q g l 9 C d 4 8 a C I V 3 + R N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V H m g f + + W K W 3 X n I K v E y 0 k F c j T 6 5 a / e I G Z p x B U y S Y 3 p e m 6 C f k Y 1 C i b 5 t N R L D U 8 o G 9 M h 7 1 q q a M S N n 8 1 P n Z I z q w x I G G t b C s l c / T 2 R 0 c i Y S R T Y z o j i y C x 7 M / E / r 5 t i e O V n Q i U p c s U W i 8 J U E o z J 7 G 8 y E J o z l B N L K N P C 3 k r Y i G r K 0 K Z T s i F 4 y y + v k t Z F 1 a t V r + 9 r l f p N H k c R T u A U z s G D S 6 j D H T S g C Q y G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w B S E o 3 Y < / l a t e x i t > a t 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " P j 7 + j l 4 a s d g R V m j T s R D U o 4 i T t y o = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S S l o N 6 K X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x y 8 S p Z r z J Y h n r T k A N l 0 L x J g q U v J N o T q N A 8 n Y w v p v 5 7 S e u j Y j V I 0 4 S 7 k d 0 q E Q o G E U r t W k / w 8 v q t F 8 q u x V 3 D r J K v J y U I U e j X / r q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 4 u 9 1 P C E s j E d 8 q 6 l i k b c +  j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U 3 9 1    q 5 e a h W q 7 d 5 n E U 4 B h O 4 A w 8 u I I a 3 E M d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / 2 E Y 9 Y < / l a t e x i t >   a t 4   < l a t e x i t s h a 1 _ b a s e 6 4 = " 9 8 M 7 2 Q 9 j 3    l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5    j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U 3 9 1    q 5 e a h W q 7 d 5 n E U 4 B h O 4 A w 8 u I I a 3 E M d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / 5 G 4 9   <TAR> Plant <NAV> forward? <ORA> Yes  j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1      < l a t e x i t s h a 1 _ b a s e 6 4 = " n D K n o e / J t r u K A y s t y a r Z R p 6 W A 5 o = " > A A A B 8 H i c b V B N S w M x E M 3 W r 1 q / q h 6 9 B I s g C m V X C u q t 6 E V v F e y H t G v J p t k 2 N M k u y a x Q l v 4 K L x 4 U 8 e r P 8 e a / M W 3 3 o K 0 P B h 7 v z T A z L 4 g F N + C 6 3 0 5 u a X l l d S 2 / X t j Y 3 N r e K e 7 u N U y U a M r q N n 8 3 C k 5 t 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h t d + J l S S I l d s s S h M J c G Y z H 4 n A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 1 C R R u C t / z y K m l V K 1 6 t c v N Q K 9 d v 8 z g K c A p n c A E e X E E d 7 q E B T W A w h m d 4 h T c n c V 6 c d + d j 0 b r m 5 D M n 8 A f O 5 w / 0 j I 9 X < / l a t e x i t > a t 3 < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 F w Y k 9 F 8 t T 8 g C L q e b q 7 j A b y s c M M = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R a U G 9 F L x 4 r 2 A 9 o Q 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t h P X R s T q E c c J 9 y M 6 U C I U j K K V W r S X 4 f n l p F c q u x V 3 B r J M v J y U I U e 9 V / r q 9 m O W R l w h k 9 S Y j u c m 6 G d U o 2 C S T 4 r d 1 P C E s h E d 8 I 6 l i k b c + N n s 3 A k 5 t U q f h L G 2 p Z D M 1 N 8 T G Y 2 M G U e B 7 Y w o D s 2 i N x X / 8 z o p h t d + J l S S I l d s v i h M J c G Y T H 8 n f a E 5 Q z m 2 h D I t 7 K 2 E D a m m D G 1 C R R u C t / j y M m l e V L x D d R P + x J V o b n 7 O D G a 2 o = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g n o r e v F Y w X 5 A G 8 p m u 2 m X b j Z h d y K U 0 B / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D f z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W a t N + h h e 1 a b 9 c c a v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6 r H q 1 6 s 1 D r V K / z e M o w g m c w j l 4 c A V 1 u I c G N I H B G J 7 h F d 6 c x H l x 3 p 2 P R W v B y W e O 4 Q + c z x / 3 l o 9 Z < / l a t e x i t > a t 5 < l a t e x i t s h a 1 _ b a s e 6 4 = " x o P 2 Q Z j v P Y 3 3 6 0 M B 4 r b u i k A M d M Q = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U W 9 F L x 4 r 2 A 9 o Q 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t h P X R s T q E c c J 9 y M 6 U C I U j K K V W r S X 4 f n l p F c q u x V 3 B r J M v J y U I U e 9 V / r q 9 m O W R l w h k 9 S Y j u c m 6 G d U o 2 C S T 4 r d 1 P C E s h E d 8 I 6 l i k b c + N n s 3 A k 5 t U q f h L G 2 p Z D M 1 N 8 T G Y 2 M G U e B 7 Y w o D s 2 i N x X / 8 z o p h t d + J l S S I l d s v i h M J c G Y T H 8 n f a E 5 Q z m 2 h D I t 7 K 2 E D a m m D G 1 C R R u C t / j y M m l e V L x Attend [! ! ? ! " ] Previous Action " # ResNet Encoder Decoder dt < l a t e x i t s h a 1 _ b a s e 6 4 = " p f 2 I q h h B V I 4 l W / U O 7 7 w v p j q 9 e R s = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W w 2 m 3 b p Z h N 2 J 0 I p / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E p h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m S T T j D d Z I h P d C a j h U i j e R I G S d 1 L N a R x I 3 g 5 G t z O / / c S 1 E Y l 6 x H H K / Z g O l I g E o 2 i l h 7 C P / X L F r b p z k F X i 5 a Q C O R r 9 8 l c v T F g W c 4 V M U m O 6 n p u i P 6 E a B Z N 8 W u p l h q e U j e i A d y 1 V N O b G n 8 x P n Z I z q 4 Q k S r Q t h W S u / p 6 Y 0 N i Y c R z Y z p j i 0 C x 7 M / E / r 5 t h d O 1 P h E o z 5 I o t F k W Z J J i Q 2 d 8 k F J o z l G N L K N P C 3 k r Y k G r K 0 K Z T s i F 4 y y + v k l a t 6 l 1 U a / e X l f p N H k c R T u A U z s G D K 6 j D H T S g C Q w G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w B U E o 3 T < / l a t e x i t > d0 = hN < l a t e x i t s h a 1 _ b a s e 6 4 = " d t r S u f l F J l p t I O t t g q n K D i F 9 F R c = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 m t g l 6 E o h d P U s F + S L s s 2 W z a h i b Z J c k K Z e m v 8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 e h m 6 r e f q N I s l g 9 m n F B f 4 I F k f U a w s d J j F L j o C g 2 D u 6 B c c a v u D G i Z e D m p Q I 5 G U P 7 q R T F J B Z W G c K x 1 1 3 M T 4 2 d Y G U Y 4 n Z R 6 q a Y J J i M 8 o F 1 L J R Z U + 9 n s 4 A k 6 s U q E + r G y J Q 2 a q b 8 n M i y 0 H o v Q d g p s h n r R m 4 r / e d 3 U 9 C / 9 j M k k N V S S + a J + y p G J 0 f R 7 F D F F i e F j S z B R z N 6 K y B A r T I z N q G R D 8 B Z f X i a t W t U 7 q 9 b u z y v 1 6 z y O I h z B M Z y C B x d Q h 1 t o Q B M I C H i G V 3 h z l P P i v D s f 8 9 a C k 8 8 c w h 8 4 n z 8 0 2 o 9 d < / l a t e x i t > hN < l a t e x i t s h a 1 _ b a s e 6 4 = " Y b t m B R l b o Z 8 I E 3 o 5 a J i e 7 3 V b Y Q Y = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 k k q 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t h P X R s T q E c c J 9 y M 6 U C I U j K K V H o a 9 u 1 6 p 7 F b c G c g y 8 X J S h h z 1 X u m r 2 4 9 Z G n G F T F J j O p 6 b o J 9 R j Y J J P i l 2 U 8 M T y k Z 0 w D u W K h p x 4 2 e z U y f k 1 C p 9 E s b a l k I y U 3 9 P Z D Q y Z h w F t j O i O D S L 3 l T 8 z + u k G F 7 5 m V B J i l y x + a I w l Q R j M v 2 b 9 I X m D O X Y E s q 0 s L c S N q S a M r T p F G 0 I 3 u L L y 6 R Z L G o k F U d C N n 2 e z 6 R B S q I m x T c = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 r F i v 6 A N Z b O Z t E s 3 m 7 C 7 E U r p T / D i Q R G v / i J v / h u 3 b Q 7 a + m D g 8 d 4 M M / O C V H B t X P f b W V v f 2 N z a L u w U d / f 2 D w 5 L R 8 c t n W S K Y Z M l I l G d g G o U X G L T c C O w k y q k c S C w H Y z u Z n 7 7 C Z X m i W y Y c Y p + T A e S R 5 x R Y 6 X H s N / o l 8 p u x Z 2 D r B I v J 2 X I U e + X v n p h w r I Y p W G C a t 3 1 3 N T 4 E 6 o M Z w K n x V 6 m M a V s R A f Y t V T S G L U / m Z 8 6 J e d W C U m U K F v S k L n 6 e 2 J C Y 6 3 H c W A 7 Y 2 q G e t m b i f 9 5 3 c x E N / 6 E y z Q z K N l i U Z Q J Y h I y + 5 u E X C E z Y m w J Z Y r b W w k b U k W Z s e k U b Q j e 8 s u r p F W t e J e V 6 s N V u X a b x 1 G A U z i D C / D g G m p w D 3 V o A o M B P M M r v D n C e X V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t > It < l a t e x i t s h a 1 _ b a s e 6 4 = " m C k A j n w p s H B N 5 G V Z j Z G o + A f i 3 t o = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 o r e K 9 g P a U D b b T b t 0 s w m 7 E 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G N 1 O / 9 c S 1 E b F 6 x H H C / Y g O l A g F o 2 i l h 7 s e 9 k p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i G n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 M r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 1 q x T u v V O 8 v y P O q L F S 6 6 m X 8 X N v 0 i u V 3 Y o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 5 S G C a p 1 x 3 M T 4 2 d U G c 4 E T o r d V G N C 2 Y g O s G O p p B F q P 5 u d O y G n V u m T M F a 2 p C E z 9 f d E R i O t x 1 F g O y N q h n r R m 4 r / e Z 3 U h F d + x m W S G p R s v i h M B T E x m f 5 O + l w h M 2 J s C W W K 2 1 s J G 1 J F m b E J F W 0 I 3 u L L y 6 R 5 U f G q l e v 7 a r l 2 k 8 d R g G M 4 g T P w 4 B J q c A d 1 a A C D E T z D K 7 w 5 i f P i v D s f 8 9 Y V J 5 8 5 g j 9 w P n 8 A B C W P Y Q = = < / l a t e x i t > Attend w i < l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > w i < l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B N B K R b g X E M M E V q w M H w V q x Z k Q G g j W D 4 f X E b z 4 x b X i k 7 m E U M 1 + S v u I h p w S s 9 H D 7 e N J N 4 d Q b d 4 s l t + x O g R e J l 5 E S y l D r F r 8 6 v Y g m k i m g g h j T 9 t w Y / J R o 4 F S w c a G T G B Y T O i R 9 1 r Z U E c m M n 0 4 P H u M j q / R w G G l b C v B U / T 2 R E m n M S A a 2 U x I Y m H l v I v 7 n t R M I L / y U q z g B p u h s U Z g I D B G e f I 9 7 X D M K Y m Q J o Z r b W z E d E E 0 o 2 I w K N g R v / u V F 0 j g r e 5 X y 5 V 2 l V L 3 K 4 s i j A 3 S I j p G H z l E V 3 a A a q i O K J H p G r + j N 0 c 6 L 8 + 5 8 z F p z T j a z j / 7 A + f w B 5 z y P 2 A = = < / l a t e x i t > I ?      Navigation Action Decoding (C4) Initially, the dialogue context is just a target object t O category, for example "plant." The goal room contains an instance of that category. As questions are asked and answered, the dialogue context grows. Following prior work  (Anderson et al., 2018; , dialogue history words w words are embedded as 256 dimensional vectors and passed through an LSTM to produce u context vectors and a final hidden state h N . The hidden state h N is used to initialize the LSTM decoder. At every timestep the decoder is updated with the previous action a t?1 and current image observation I t . The hidden state is used to attend over the language u and predict the next action a t (Figure  2a ). G B Y T O i R 9 1 r Z U E c m M n 0 4 P H u N j q / R w G G l b C v B U / T 2 R E m n M S A a 2 U x I Y m H l v I v 7 n t R M I L / y U q z g B p u h s U Z g I D B G e f I 9 7 X D M K Y m Q J o Z r b W z E d E E 0 o 2 I z y N g R v / u V F 0 i i X v E r p 8 q 5 S r F 5 l c e T Q I T p C J 8 h D 5 6 i K b l A N 1 R F F E j 2 j V / T m a O f F e X c + Z q 1 L T j Z z g P 7 A + f w B 6 M G P 2 Q = = < / l a t e x i t > I ? t+3 < l a t e x i t s h a 1 _ b a s e 6 4 = " k h m 1 W i 1 m q A N 4 B w S 1 L m A F u F 6 6 E u U = " > A A A B 8 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S K I Q t n V g n o r e t F b B f s h 7 V q y a b Y N T b J L k h X K 0 l / h x Y M i X v 0 5 3 v w 3 p u 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 7 O w u L S 8 s p p b y 6 9 v b G 5 t F 3 Z 2 6 z p K F K E 1 E v F I N Q O s K W e S 1 g w z n D Z j R b E I O G 0 E g + u x 3 3 i i S r N I 3 p t h T H 2 B e 5 K F j G B j p Y f b x + N O a k 7 O R p 1 C 0 S 2 5 E 6 B 5 4 m W k C B m q n c J X u x u R R F B p C M d a t z w 3 N n 6 K l W G E 0 1 G + n W g a Y z L A P d q y V G J B t Z 9 O D h 6 h Q 6 t 0 U R g p W 9 K g i f p 7 I s V C 6 6 E I b K f A p q 9 n v b H 4 n 9 d K T H j h p 0 z G i a G S T B e F C U c m Q u P v U Z c p S g w f W o K J Y v Z W R P p Y Y W J s R K F K E 1 E v F I N Q O s K W e S 1 g w z n D Z j R b E I O G 0 E g + u x 3 3 i i S r N I 3 p t h T H 2 B e 5 K F j G B j p Y f b x + N O a k 7 O R p 1 C 0 S 2 5 E 6 B 5 4 m W k C B m q n c J X u x u R R F B p C M d a t z w 3 N n 6 K l W G E 0 1 G + n W g a Y z L A P d q y V G J B t Z 9 O D h 6 h Q 6 t 0 U R g p W 9 K g i f p 7 I s V C 6 6 E I b K f A p q 9 n v b H 4 n 9 d K T H j h p 0 z G i a G S T B e F C U c m Q u P v U Z c p S g w f W o K J Y v Z W R P p Y Y W J s R N B K R b g X E M M E V q w M H w V q x Z k Q G g j W D 4 f X E b z 4 x b X i k 7 m E U M 1 + S v u V u n h M N K 2 F O C p + n s i J d K Y k Q x s p y Q w M P P e R P z P a y c Q X v g p V 3 E C T N H Z o j A R G C I 8 + R 7 3 u G Y U x M g S Q j W 3 t 2 I 6 I J p Q s B k V b A j e / M u L p H F W 9 i r l y 7 t K q X q V x Z F H B + g Q H S M P n a M q u k E 1 V E c U S f S M X t We pretrain the N avigator on the navigation task alone before fine-tuning in the full dialogue setting that we introduce. The next action is sampled from the model's predicted logits, and the episode ends when either a stop action is sampled or 80 actions are taken . 

 Speaker Models (C2 & C3) To generate questions and answers, we train sequence-to-sequence models (Figure  2b ) where an encoder takes in a sequence of images and a decoder produces a sequence of word tokens. At each decoding timestep, the decoder attends over the input images to predict the next word of the question or answer. This model is also initialized via training on CVDN dialogues. In particular, question asking (Questioner) encodes the images of the current viewpoint where a question is asked, and then decodes the question tokens produced by the human N avigator. Question answering (Guide) encodes images of the next five steps the shortest path planner would take towards the goal, then decodes the language tokens pro-duced by the human Guide. Pretraining initializes the lexical embeddings and attention alignments before fine-tuning in the collaborative, turn-taking setting we introduce in this paper. 

 Conditioning Context We define three levels of dialogue context given as input to our N avigator agents in order to evaluate how well they utilize the generated conversations. We compare agents' ability to navigate to the goal room given: t O the target object present in the goal room; QA i-1 additionally the previous question-andanswer exchange; QA 1:i-1 additionally the entire dialogue history. We constrain the Questioner and Guide speaker models to condition on fixed contexts. The Questioner model takes as input the current visual observation I t and the target object t O . The Guide model takes the visual observations I * t+1:t+5 of the next five steps of navigation according to a shortest path planner, the target object t O , and the last question Q i?1 generated by the Questioner. 1 

 Recursive Mental Model We introduce the Recursive Mental Model agent (RMM),  2  which is trained with reinforcement learning to propagate feedback from navigation error through all three component models: N avigator, Questioner, and Guide. In this way, the training signal for question generation includes the training How this looks like for Vision-Dialog Navigation 

 Start Recursive Mental Model Rollout Goal N < l a t e x i t s h a 1 _ b a s e 6 4 = " A i z T e X p l B v n 9 P W e W H A X H z W a q l V Y = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N 6 6 k g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u f D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o O s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d B p 1 7 6 L e e L i s N W + K O s p w A q d w D h 5 c Q R P u o A V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A I V d k W g = < / l a t e x i t > N < l a t e x i t s h a 1 _ b a s e 6 4 = " A i z T e X p l B v n 9 P W e W H A X H z W a q l V Y = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N 6 6 k g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u f D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o O s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d B p 1 7 6 L e e L i s N W + K O s p w A q d w D h 5 c Q R P u o A V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A I V d k W g = < / l a t e x i t > ? q 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " f b 1 O 4 i h h j 0 X w Z q j A Q X c J B s v G E + U = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m t g h 6 L X j x W s B / S X U o 2 z b a h S X Z N s k J Z + i u 8 e F D E q z / H m / / G t N 2 D V h 8 M P N 6 b Y W Z e m H C m j e t + O Y W l 5 Z X V t e J 6 a W N z a 3 u n v L v X 0 n G q C G 2 S m M e q E 2 J N O Z O 0 a Z j h t J M o i k X I a T s c X U / 9 9 i N V m s X y z o w T G g g 8 k C x i B B s r 3 f u a C f 8 Q P Z z 0 y h W 3 6 s 6 A / h I v J x X I 0 e i V P / 1 + T F J B p S E c a 9 3 1 3 M Q E G V a G E U 4 n J T / V N M F k h A e 0 a 6 n E g u o g m x 0 8 Q c d W 6 a M o V r a k Q T P 1 5 0 S G h d Z j E d p O g c 1 Q L 3 p T 8 T + v m 5 r o M s i Y T F J D J Z k v i l K O T I y m 3 6 M + U 5 Q Y P r Y E E 8 X s r Y g M s c L E 2 I x K N g R v 8 e W / p F W r e m f V 2 u 1 5 p X 6 V x 1 G E A z i C U / D g A u p w A w 1 o A g E B T / A C r 4 5 y n p 0 3 5 3 3 e W n D y m X 3 4 B e f j G 7 j S j 7 I = < / l a t e x i t > ? q 00 < l a t e x i t s h a 1 _ b a s e 6 4 = " L X Q z 5 S L + B w p t  I b A N C V D N N T K C a s U = " > A A A B 8 X i c b V B N T w I x E J 3 F L 8 Q v 1 K O X K j F 4 I r t o o k e i F 4 + Y y E d k N 6 R b C j S 0 3 b X t m p A N / 8 K L B 4 3 x 6 r / x 5 r + x w B 4 U f M k k L + / N Z G Z e G H O m j e t + O 7 m V 1 b X 1 j f x m Y W t 7 Z 3 e v u H / Q 1 F G i C G 2 Q i E e q H W J N O Z O 0 Y Z j h t B 0 r i k X I a S s c 3 U z 9 1 h N V m k X y 3 o x j G g g 8 k K z P C D Z W e v A 1 E / 4 x e i y X u 8 W S W 3 F n Q M v E y 0 g J M t S 7 x S + / F 5 F E U G k I x 1 p 3 P D c 2 Q Y q V Y Y T T S c F P N I 0 x G e E B 7 V g q s a A 6 S G c X T 9 C p V X q o H y l b 0 q C Z + n s i x U L r s Q h t p 8 B m q B e 9 q f i f 1 0 l M / y p I m Y w T Q y W Z L + o n H J k I T d 9 H P a Y o M X x s C S a K 2 V s R G W K F i b E h F W w I 3 u L L y 6 R Z r X j n l e r d R M G 4 = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m t g h 6 L X j x W s B / Q X U o 2 z b a h S X a b Z I W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Y c K Z N q 7 7 7 R T W 1 j c 2 t 4 r b p Z 3 d v f 2 D 8 u F R S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D f z 2 0 9 U a R b L R z N J a C D w Q L K I E W y s 1 P E 1 E / 4 p G v f K F b f q z o F W i Z e T C u R o 9 M p f f j 8 m q a D S E I 6 1 7 n p u Y o I M K 8 M I p 9 O S n 2 q a Y D L C A 9 q 1 V G J B d Z D N 7 5 2 i c 6 v 0 U R Q r W 9 K g u f p 7 I s N C 6 4 k I b a f A Z q i X v Z n 4 n 9 d N T X Q T Z E w m q a G S L B Z F K U c m R r P n U Z 8 p S g y f W I K J Y v Z W R I Z Y Y W J s R C U b g r f 8 8 i p p 1 a r e Z b X 2 c F W p 3 + Z x F O E E z u A C P L i G O t x D A 5 p A g M M z v M K b M 3 Z e n H f n Y 9 F a c P K Z Y / g D 5 / M H V h G P g Q = = < / l a t e x i t > } < l a t e x i t s h a 1 _ b a s e 6 4 = " z 9 I 0 3 u D a A 3 b S 8 q E r i C B / z L Q + 3 n M = " > A A A B 6 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 9 V 7 A e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q d e P C j i 1 X / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G t z O / / c S 1 E b F 6 x E n C / Y g O l Q g F o 2 i l h 9 6 0 X 6 6 4 V X c O s k q 8 n F Q g R 6 N f / u o N Y p Z G X C G T 1 J i u 5 y b o Z 1 S j Y J J P S 7 3 U 8 I S y M R 3 y r q W K R t z 4 2 f z S K T m z y o C E s b a l k M z V 3 x M Z j Y y Z R I H t j C i O z L I 3 E / / z u i m G 1 3 4 m V J I i V 2 y x K E w l w Z j M 3 i Y D o T l D O b G E M i 3 s r Y S N q K Y M b T g l G 4 K 3 / P I q a d W q 3 k W 1 d n 9 Z q d / k c R T h B E 7 h H D y 4 g j r c Q Q O a w C C E Z 3 i F N 2 f s v D j v z s e i t e D k M 8 f w B 8 7 n D 5 / a j W s = < / l a t e x i t > Q < l a t e x i t s h a 1 _ b a s e 6 4 = " 1 Z + a i 4 R 7 a Y 9 T O k p Y l + O c U g K E e J U = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N y 5 b s A + Y D i W T Z t r Q T D I k G a E M / Q w 3 L h R x 6 9 e 4 8 2 / M t L P Q 1 g O B w z n 3 k n N P m H C m j e t + O 6 W N z a 3 t n f J u Z W / / 4 P C o e n z S 1 T J V h H a I 5 F L 1 Q 6 w p Z 4 J 2 D D O c 9 h N F c R x y 2 g u n 9 7 n f e 6 J K M y k e z S y h Q Y z H g k W M Y G M l f x B j M y G Y Z + 3 5 s F p z 6 + 4 C a J 1 4 B a l B g d a w + j U Y S Z L G V B j C s d a + 5 y Y m y L A y j H A 6 r w x S T R N M p n h M f U s F j q k O s k X k O b q w y g h F U t k n D F q o v z c y H G s 9 i 0 M 7 m U f U q 1 4 u / u f 5 q Y l u g 4 y J J D V U k O V H U c q R k S i / H 4 2 Y o s T w m S W Y K G a z I j L B C h N j W 6 r Y E r z V k 9 d J t 1 H 3 r u q N 9 n W t e V f U U Y Y z O I d L 8 O A G m v A A L e g A A Q n P 8 A p v j n F e n H f n Y z l a c o q d U / g D 5 / M H i e y R a w = = < / l a t e x i t > G < l a t e x i t s h a 1 _ b a s e 6 4 = " A w s m y h s 2 O h 7 2 g e O 5 w z l q r u T I J j g = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x I Q d 0 V X e i y g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u b D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o K s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d C 7 q X q N + / d C o N W + K O s p w A q d w D h 5 c Q h P u o Q V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A H 1 M k W k = < / l a t e x i t > ? g 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t > ? g 00 < l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t > ? g < l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t > ? g 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t > ? g 00 < l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t > ? g < l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t > ? g 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t > ? g 00 < l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t > ? g < l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t > max q,g GP (?) < l a t e x i t s h a 1 _ b a s e 6 4 = " 3 x d x q r n r x B + X A W L C A e Y o T 8 k P k l E = " > A A A B / X i c b V D L S s N A F J 3 U V 6 2 v + N i 5 G S x C B S m J F N R d 0 Y U u K 9 g H N C F M J p N 2 6 C Q T Z y Z i D c V f c e N C E b f + h z v / x m m b h b Y e u H A 4 5 1 7 u v c d P G J X K s r 6 N w s L i 0 v J K c b W 0 t r 6 x u W V u 7 7 Q k T w U m T c w Z F x 0 f S c J o T J q K K k Y 6 i S A o 8 h l p + 4 P L s d + + J 0 J S H t + q Y U L c C P V i G l K M l J Y 8 c 8 + J 0 I O X 3 R 3 3 R v C q U X F w w N W R Z 5 a t q j U B n C d 2 T s o g R 8 M z v 5 y A 4 z Q i s c I M S d m 1 r U S 5 G R K K Y k Z G J S e V J E F 4 g H q k q 2 m M I i L d b H L 9 C B 5 q J Y A h F 7 p i B S f q 7 4 k M R V I O I 1 9 3 R k j 1 5 a w 3 F v / z u q k K z 9 y M x k m q S I y n i 8 K U Q c X h O A o Y U E G w Y k N N E B Z U 3 w p x H w m E l Q 6 s p E O w Z 1 + e J 6 2 T q l 2 r n t / U y v W L P I 4 i 2 A c H o A J s c A r q 4 B o 0 Q B N g 8 A i e w S t 4 M 5 6 M F + P d + J i 2 F o x 8 Z h f 8 g f H 5 A 1 5 t l I o = < / l a t e x i t > Figure  3 : The Recursive Mental Model allows for each sampled generation to spawn a new dialogue and corresponding trajectory to the goal. The dialogue that leads to the most goal progress is followed by the agent. signal for answer generation, which in turn is derived from the training signal from navigation error. The agent's progress towards the goal in the environment informs the dialogue itself; each model educates the others (Figure  3 ). Each model among the N avigator, Questioner, and Guide may sample N trajectories or generations of max length L. These samples in turn are considered recursively by the RMM agent, leading to N T possible dialogue trajectories, where T is at most the maximum trajectory length. To prevent unbounded exponential growth during training, each model is limited to a maximum number of total recursive calls per run. Search techniques, such as frontiers  (Ke et al., 2019) , could be employed in future work to guide the agent. Training In the dialogue task we introduce, the agents begin only knowing the name of the target object. The N avigator agent must move towards the goal room containing the target object, and can ask questions using the Questioner model. The Guide agent answers those questions given a privileged view of the next steps in the shortest path to the goal rendered as visual observations. We define two different loss functions to learn the parameters ? of the N avigator agent. We learn a policy ? ? (? |t O ) which maximizes the loglikelihood of the shortest path trajectory ? given target object t O present in the goal room (Eq. 1). The action decoder a t = f ? D (z t , I t ) takes language encoder z t = f ? E (w 1:t ) as input along with the image observations I t at time t. Dialogue context at time t, w 1:t is input to the language encoder. The cross entropy loss is defined as: J CE (?) = ? T t=1 log ? ? (a t |I t , t O , w 1:t ) (1) Our second N avigator RL agent loss is standard policy gradient based Advantage Actor Critic  (Sut-ton and Barto, 1998)  minimizing a k-step TD 3 error of the critic, J RL (?): = ? T t=1 A ? log ? ? (a t |I t , t O , w 1:t ) + 1 2 T t=1 (A ? ) 2 (2) A ? =r t+1 +V ? (I t+1 )-V ? (I t ) is the advantage function in Eq. 2, where r t+1 is the reward measured by the goal progress and the V ? denotes the statevalue (critic) model. The first term in Eq. 2 is the actor loss, while the second term is the critic (value) loss of the advantage actor critic loss function. The overall system is trained end-to-end using sum of the RL agent loss of the navigator agent J RL (?) and the cross entropy loss between the ground truth and the generated trajectories, J CE (?). The speaker model parameters are also updated via the sum of the standard question/answer generation cross entropy and the composite N avigator agent loss from the branch with the max goal progress. Inference During training, exact environmental feedback-the remaining distance to the goal-can be used to evaluate samples and trajectories. This information is not available during inference, so we instead rely on the navigator's confidence to determine which of several sampled paths should be explored. For every question-answer pair sampled, the agent rolls forward five navigation actions per sequence, and the trajectory sequence with the highest probability is used for the next timestep. This heuristic does not guarantee that the model is progressing towards the goal, but empirically confidence-based estimation enables progress. 

 Dialogue Gameplay As is common in dialogue settings, there are several moving pieces and a growing notion of state throughout training and evaluation. In addition to the N avigator, Questioner, and Guide, the N avigator agent also needs to determine when to invoke the Questioner model to get supervision from the Guide (C1). We leave this componentwhen to ask questions-for future work and set a fixed number of steps before asking a question. We invoke the Questioner model after every 4 navigation steps based on the human average of 4.5 steps between questions in CVDN. Setting a maximum trajectory length is required due to computational constraints as the the lan-guage context w 1:j grows. Following , we use a maximum navigation length of 80 steps, leading to a maximum of 80 4 = 20 question-answer exchanges per dialogue. We use a single model for question and answer generation, and indicate the role of spans of text by prepending <NAV> (Questioner navigation questions) or <ORA> (Guide answers based on oracle views) tags (Figure  2a ) to condition the generation task. During roll outs the model is reinitialized to prevent information sharing via the hidden units. 

 Training Details We initialize the N avigator, Questioner, and Guide agents as encoder-decoder LSTM models with 512 hidden dimensions. The N avigator encoder is a forward LSTM, while the Questioner and Guide speaker models use bi-LSTM encoders. We use the 512 dimensional penultimate ResNet layer for image observations I t , embed words w in 256 dimensions, and embed actions in 32 dimensions. The models observe a word history up to 160 tokens, and can decode up to 80 actions per episode. The value/critic module is a linear layer with relu and dropout on top of the hidden state. We optimize the N avigator models with the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.0001 with weight decay 0.0005. For the Questioner and Guide models, we use an RMSProp optimizer with learning rate 0.0001. Models are pretrained on CVDN data with batches of size 100 for 20, 000 iterations. During self-play, models are trained with batches of 10, for RMM with N = 3, or 100 else for 5, 000 iterations. A dropout rate of 0.5 is used during all training. All N avigator models are trained using student sampling  (Anderson et al., 2018) . In RMM N =3 , one action sequence is produced via argmax decoding, while the other two via sampling (no temperature). The same is true for language decoding but with a temperature of 0.6. Exploration of how sampler strategies effect performance is left for future work. Data Augmentation (DA) Navigation agents can benefit from generated language instructions  (Fried et al., 2018) . We augment the baseline model's navigation training data in a fashion similar to the rollouts of RMM N =3 to create a more direct comparison between the baseline and RMM. We choose a CVDN conversation and sample three action trajectory rollouts, two by sampling an action at each timestep, and one by taking the argmax Model Goal Progress (m) ? BLEU ? t O QAi-1 QA1:i-1 +Oracle Stopping QAi-1 QA1:i-1 Val Seen Seq2Seq 20.1 10.5 15.0 22.9 0.9 0.8 Seq2Seq + DA 20.1 10.5 10.0 14.  action at each timestep. We evaluate those trajectories' progress towards the conversation goal location and keep the best for augmentation. We give the visual observations of the chosen path to the pretrained Questioner model to produce a relevant instruction. This trajectory paired with a generated language instruction is added to the training data, and we downweight the contributions of these noisier pairs to the overall loss, so loss = ? * generations + (1 ? ?) * human. The choice of ? affects the fluency of the language generated; we use ? = 0.1. 

 Results In Table  2  we present dialogue results for our RMM agent and competitive baselines. We report two main results and four ablations for seen and unseen house evaluations; the former are novel dialogues in houses seen at training time, while the latter are novel dialogues in novel houses. 

 Full Evaluation The full evaluation paradigm conditions navigation on the entire dialogue history QA 1:i-1 in addition to the original target object t O . We present two conditions for RMM (N = 1 and N = 3). Recall that N indicates the number of trajectories (N avigator) or generations (Questioner, Guide) explored in our recursive calls. N = 1 corresponds to taking the single maximum prediction while N = 3 allows the agent to sample alternatives (Section 4.2). While low, the BLEU scores are better for RMM-based agents across settings. A challenge for navigation agents is knowing when to stop. Following previous work  (Anderson et al., 2018) , we additionally report Oracle Success Rates measuring the best goal progress the agents achieve along the trajectory. In unseen environments, the RMM-based agents make the most progress towards the goal and benefit from exploration at during inference (N = 3), and this result holds when considering Oracle Success. In seen environments, by contrast, the RMM-based agents perform slightly less well than the baseline sequence-to-sequence models on goal progress. This effect may be a consequence of environment bias in navigation simulations where houses are seen at both training and inference time with overlapping paths  (Zhang et al., 2020) . Ablations We also include two simpler results: t O , where the agent is only provided the target object and explores based on this simple goal, and QA i-1 where the agent is only provided the previous question-answer pair. Both of these settings simplify the learning and evaluation by focusing the agent on search and less ambiguous language, respectively. There are two results to note. First, given only t O the RMM trained model with sampling generalizes best to unseen environments. In this setting, during inference all models have the same limited information, so the RL loss and exploration have better equipped RMM to generalize. Second, several trends invert between the seen and unseen scenarios. Specifically, the simplest model with the least information performs best overall in seen houses. This high performance coupled with weak language appears to indicate the models are learning a different (perhaps search based) strategy rather than how to utilize dialogue. In the QA i-1 and QA 1:i-1 settings, the agent generates a question-answer pair before navigating, so the relative strength of the RMM model's communication becomes clear. We analyze the generated language and navigation behavior of our models. 

 Analysis We analyze the lexical diversity and effectiveness of generated questions by the RMM. 

 Lexical Diversity Both RMM and Data Augmentation introduce new language by exploring and the environment and generating dialogues. In the case of RMM, an RL loss is used to update the models based on the most  successful dialogue. Using Data Augmentation, the best generations are simply appended to the dataset for one epoch and weighted appropriately for standard, supervised training. The augmentation strategy leads to small boost in BLEU performance and goal progress in several settings (Table  2 ), but the language appears to collapse to repetitive and generic interactions. We see this manifest rather dramatically in Figure  4 , where the DA is limited to only 22 lexical types. In contrast, RMM continues to produce over 500 unique lexical types, much closer to the nearly 900 used by humans. Human Evaluation We collected human judgements comparing human dialogs with generated dialogs from the baseline and RMM agents on 254 randomly selected episodes from the unseen validation set. While RMM uses an RL objective to inform its language generation and achieves higher progress towards the goal in this setting (Table  2 ), it is rated as equally or more grammatical (57%) and as equally or more fluent (60%) than the baseline agent, suggesting that RMMs generated language has not devolved into a neuralese to achieve better task performance. Human dialogs were rated as equally or more grammatical and fluent than RMM (89%/83%) and the baseline (88%/80%). 

 Effective Questions The dialogue paradigm allows us to assess the efficacy of speech acts in accomplishing goals. In a sense, the best question elicits the answer that maximizes the progress towards the goal room. If agents are truly effective at modeling one other, we expect the number of dialogue acts to be minimal. Human conversations in CVDN always reach the goal location, and usually with only 3-4 questions, as shown in Figure  5a . We see that the relationship between questions and progress is roughly linear,    excusing the occasional lost and confused human teams. The final human-human question is often simply confirmation that navigation has arrived successfully to the goal room. In Figure  5b , we plot dialogues for the Baseline, Data Augmentation, and RMM agents against percent goal progress. The RMM consistently outperforms the other two agents in terms of goal progress for each dialogue act. We see an increase in progress for the first 10 to 15 questions before RMM levels off. By contrast, the Baseline and Data Augmentation agents exhibit shallower curves and fail to reach the same level of performance. 

 Example Dialogue While Figure  1  shows a cherry-picked RMM trajectory from an unseen validation house, Figure  6  gives a lemon-picked RMM trajectory. We discuss the successes and failures of a lemon-pickedshowcasing model failure-trajectory in Figure  6 . As with all CVDN instances, there are multiple target object candidates (here, "fire extinguisher") but only one valid goal room. Agents can become distracted by objects of the target instance in nongoal rooms. When the Guide is shown the next few shortest path steps to communicate, those steps are towards the goal room. As can be seen in Figure  6 , the learned agents have difficulty in deciding when to stop and begin retracing their steps, and in this case never arrived to the correct goal room. The learned models' generated language is of different levels of quality, with RMM language much more coherent and verbose than Data Augmentation language. Figure  7  shows generated conversations along with the Goal Progress (GP) at each point when a question was asked. Note that the generation procedure for all models use the same sam- pler, and they start training from the same checkpoint, so the relatively coherent nature of the RMM as compared to the simple repetitiveness of the Data Augmentation is entirely due to the recursive calls and RL loss. No model uses length penalties or other generation tricks to avoid degeneration. 

 Conclusions and Future Work We present a two-agent task paradigm for cooperative vision-and-dialogue navigation (CVDN). Existing work in vision-and-language navigation is largely limited to navigation only (C4), sometimes with limited additional instructions (C4,C3). By contrast, this work requires navigation (C4), question asking (C2), and question answering (C3) components for learned, end-to-end dialogue. We find that simple speaker models are insufficient for the dialogue setting, and demonstrate promising results from a recursive RL formulation with turn taking informed by theory of mind. Figure 1 : 1 Figure 1: The RMM agent recursively models conversations with instances of itself to choose the right questions to ask (and answers to give) to reach the goal. 

 t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b 

 R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t > Decoder Encoder w i 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " b l X 3 D 2 d a 4 r w r w T e L 2 n u q I 4 2 3 r n 4 = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U G 9 F L x 4 r 2 A 9 o Q 9 l s J + 3 S z S b s b p Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h U 8 e p Y t h g s Y h V O 6 A a B Z f Y M N w I b C c K a R Q I b A W j 2 6 n f e k S l e S w f z D h B P 6 I D y U P 

 r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s 

 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > w i < l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s 

 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > a t < l a t e x i t s h a 1 _ b a s e 6 4 = " A b Z P 0 

 a < / l a t e x i t > (a) Dialogue and action histories combined with the current observation are used to predict the next navigation action. 

 r X j n l e r 9 R b l 2 n c d R g G M 4 g T P w 4 B J q c A t 1 a A C D A T z D K 7 w 5 0 n l x 3 p 2 P e e u K k 8 8 c w R 8 4 n z 8 g k o 2 x < / l a t e x i t > dT < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 p f 0 

 H e n Y 9 F 6 5 q T z 5 z A H z i f P y O S j b M = < / l a t e x i t >at 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b 

 r X r P I 4 C H M M J n I E H l 1 C D W 6 h D A x g M 4 B l e 4 c 2 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E q 8 I 2 4 < / l a t e x i t > Decoder Encoder w i 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " b l X 3 D 2 d a 4 r w r w T e L 2 n u q I 4 2 3 r n 4 = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U G 9 F L x 4 r 2 A 9 o Q 9 l s J + 3 S z S b s b p Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h U 8 e p Y t h g s Y h V O 6 A a B Z f Y M N w I b C c K a R Q I b A W j 2 6 n f e k S l e S w f z D h B P 6 I D y U 

 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > I ? t+1 

 t+2 < l a t e x i t s h a 1 _ b a s e 6 4 = " d n c z f X o 6 3 L o d E i 2 I o 7 7 1 T v X T S J A = " > A A A B 8 H i c b V B N S w M x E M 3 6 W e t X 1 a O X Y B F E o e y W g n o r e t F b B f s h 7 V q y a b Y N T b J L M i u U p b / C i w d F v P p z v P l v T N s 9 a O u D g c d 7 M 8 z M C 2 L B D b j u t 7 O 0 v L K 6 t p 7 b y G 9 u b e / s F v b 2 G y Z K N G V 1 G o l I t w J i m O C K 1 Y G D Y K 1 Y M y I D w Z r B 8 H r i N 5 + Y N j x S 9 z C K m S 9 J X / G Q U w J W e r h 9 P O 2 m c F Y e d w t F t + R O g R e J l 5 E i y l D r F r 4 6 v Y g m k i m g g h j T 9 t w Y / J R o 4 F S w c b 6 T 

 n k b g j f 7 8 j y p n 5 a 8 c u n y r l y s X G V x 5 G A f D u A I P D i H C t x A F W p A Q M A z v M K b o 5 w X 5 9 3 5 m L Y u O N n M H v y B 8 / k D 6 k a P 2 g = = < / l a t e x i t > I ? t+5 < l a t e x i t s h a 1 _ b a s e 6 4 = " Y / Z d Z W f d 9 i C H g 6 j e H F 7 9 M g m l P c 4 = " > A A A B 8 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S K I Q t m V i n o r e t F b B f s h 7 V q y a b Y N T b J L k h X K 0 l / h x Y M i X v 0 5 3 v w 3 p u 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 7 O w u L S 8 s p p b y 6 9 v b G 5 t F 3 Z 2 6 z p 

 n k b g j f 7 8 j y p n 5 a 8 c u n y r l y s X G V x 5 G A f D u A I P D i H C t x A F W p A Q M A z v M K b o 5 w X 5 9 3 5 m L Y u O N n M H v y B 8 / k D 7 V C P 3 A = = < / l a t e x i t > I ? t+4 < l a t e x i t s h a 1 _ b a s e 6 4 = " i + 9 B 3 C H T d O C 5 m I 7 m W g 5 p E W u 7 E 1 s = " > A A A B 8 H i c b V B N S w Mx E M 3 W r 1 q / q h 6 9 B I s g C m V X C u q t 6 E V v F e y H t G v J p t k 2 N M k u y a x Q l v 4 K L x 4 U 8 e r P 8 e a / M W 3 3 o K 0 P B h 7 v z T A z L 4 g F N + C 6 3 0 5 u a X l l d S 2 / X t j Y 3 N r e K e 7 u N U y U a M r q 

 I h p w S s 9 H D 7 e N J N 4 b Q y 7 h Z L b t m d A i 8 S L y M l l K H W L X 5 1 e h F N J F N A B T G m 7 b k x + C n R w K l g 4 0 I n M S w m d E j 6 r G 2 p I p I Z P 5 0 e P M Z H 

 G b o 5 0 X 5 9 3 5 m L X m n G x m H / 2 B 8 / k D 6 8 u P 2 w = = < / l a t e x i t > (b) Guide Bi-LSTM over the path is attended to during decoding for answer generation. 

 Figure 2 : 2 Figure 2: Our backbone Seq2Seq architectures are provided visual observations and portions of the dialogue history when taking actions or asking/answering questions. 

 a l 2 n c W R h y M 4 g T P w 4 B J q c A t 1 a A A B C c / w C m + O d l 6 c d + d j 3 p p z s p l D + A P n 8 w c b y 4 / j < / l a t e x i t > ? q < l a t e x i t s h a 1 _ b a s e 6 4 = " J 2 z T x m e v O y e S D 2 l c 2 e l L M W y d 

 Figure 4 : 4 Figure 4: Log-frequency of words generated by human speakers as compared to the Data Augmentation (DA) and our Recursive Mental Model (RMM) models. 

 (a) Human goal progress as dialogues unfold. As humans ask questions and make goal guesses, they roughly linearly make progress towards the goal location. 

 Model goal progress against the number of questions. DA and RMM generated dialogues make slower but consistent progress (ending below 25% of total goal progress). 

 Figure 5 : 5 Figure 5: Effectiveness of human dialogues (left) versus our models (right) at reaching the goal location. The slopes indicate the effectiveness of each dialogue exchange in reaching the target. 

 Figure 6 : 6 Figure 6: Trajectories in an unseen environment attempting to find a target "fire extinguisher." The red stop-sign is the goal room, while the black stop-sign is a non-goal room containing fire extinguishers. The white trajectory is the human path from CVDN, black is the Baseline model, and green is our RMM N =3 . 

 Table 1 : 1 Previous work has addressed subsets of the four key challenges for turn-based navigation dialogues by training single-turn agents. No prior work has tackled generating navigator questions (C2) Anderson et al. (2018) Fried et al. (2018) Narayan-Chen et al. (2019) Nguyen and Daum? III (2019) Chi et al. (2020) Thomason et al. (2019) RMM 

 Table 2 : 2 Dialogue results on CVDN. Data Augmentation adds noisy training data for the model. Goal progress evaluates the quality of the inferred navigation trajectory, while BLEU scores estimate the quality of the generated questions and answers. Evaluations conditioning on the entire dialogue history are highlighted in gray with the best results in blue. 

			 This limits phenomena like co-reference, but dramatically reduces the model's input space. Handling arbitrarily long contexts with limited training data is left to future work.2 https://github.com/HomeroRR/rmm 

			 Temporal Difference
