title
BAKSA at SemEval-2020 Task 9: Bolstering CNN with Self-Attention for Sentiment Analysis of Code Mixed Text

abstract
Sentiment Analysis of code-mixed text has diversified applications in opinion mining ranging from tagging user reviews to identifying social or political sentiments of a sub-population. In this paper, we present an ensemble architecture of convolutional neural net (CNN) and self-attention based LSTM for sentiment analysis of code-mixed tweets. While the CNN component helps in the classification of positive and negative tweets, the self-attention based LSTM, helps in the classification of neutral tweets, because of its ability to identify correct sentiment among multiple sentiment bearing units. We achieved F1 scores of 0.707 (ranked 5 th ) and 0.725 (ranked 13 th ) on Hindi-English (Hinglish) and Spanish-English (Spanglish) datasets, respectively. The submissions for Hinglish and Spanglish tasks were made under the usernames ayushk and harsh 6 respectively.

Introduction The research problem of Sentiment Analysis of Code-Mixed Social Media Text appeared as part of the SemEval Shared Challenge 2020  (Patwa et al., 2020) . Mixing languages while writing text, also called code-mixing, is a typical pattern observed in almost all forms of communication, including social media text. We only focus on two popular bilingual code-mixing styles namely Hinglish and Spanglish. Sentiment Analysis is a term broadly used to classify states of human affection and emotion. Interpreting code-mixed languages is difficult not only because the sentences may not fit a particular language model, but also because mixed text on social-media usually contains tokens such as hashtags, and usernames. In this paper, we present an ensemble of CNN and self-attention based LSTM, utilizing the XLM-R embeddings  (Conneau et al., 2019) . While CNNs have been used for sentiment analysis before  (Wang et al., 2016; Yoon and Kim, 2017) , none of the previous works have used a self-attention based LSTM along with it. We found that while the CNN component worked well for positive and negative tweets, the self-attention component worked better for neutral tweets, necessitating an ensemble of the two. The implementation of our system is made available via Github 1 . 

 Related Work Performing standard NLP tasks on code-mixed data has presented significant challenges.  Vyas et al. (2014)  attempted to find methods for POS tagging of code-mixed social media text. Another work by  Joshi et al. (2016)  used CNNs to learn subword level embeddings and then utilized these embeddings in a BiLSTM network to learn subword level information from social media text. Subword level representations are particularly important while dealing with noisy texts containing misspellings and punctuations. However, this work doesn't capture information about word-level semantics. More recent work by Lal et al. (  2019 ) uses two parallel BiLSTMs, which they call the Collective and Specific Encoder and an additional feature network. This approach combines recurrent neural networks utilizing attention mechanisms, which helps in evaluating the overall sentiment using attention weights when presented with a mixture of local sentiments. 3 Proposed Approach  The tweets have been originally provided in the Latin script with their corresponding language tags. Before feeding the tweets to any training stage, they are preprocessed using the following procedure (Figure  1 ): 1. Back-Transliteration: All the words with "Hindi" language tags are converted into Devanagari words using phonetic transliteration. Google's Transliteration API 2 was used for this purpose. The words with "Spanish" language tags are not transliterated. 2. Noise removal: Usernames (annotated as @username), URLs, and emoticons present in the tweets are removed altogether, while hashtags (annotated as #hashtag) are left as it is. We also experimented with replacing emoticons by their corresponding textual meaning, but removing them led to better performance. 3. Tokenization: Tweets after noise removal are tokenized into subwords using the XLM-R  (Conneau et al., 2019)  vocabulary and later converted into their corresponding IDs. 

 Embedding layer Since our data comprised of code-mixed tweets, it was essential to use a multilingual model. For our proposed architecture, we used the XLM-R embeddings. XLM-R is a transformer-based masked language model trained on one hundred languages, using more than two terabytes of filtered CommonCrawl data  (Conneau et al., 2019) . The subword IDs from the pre-processing stage are fed to the XLM-R encoder. The final hidden state corresponding to each token is used for the classification task as inputs to the proceeding components (See figure  2 ). The XLM-R encoder is fine-tuned during training to generate better encodings for the code-mixed text. We also experimented with the Multilingual BERT (henceforth, M-BERT), released by  Devlin et al. (2018) . We found that XLM-R performed much better than M-BERT for our dataset. 

 Architecture We propose an ensemble model comprising of two main components.  1@150x1024 Sentence Matrix 2@2x1024 2@3x1024 2@4x1024 Convolution 2@149x1 2@148x1 Max Pooling 2@1x1 Concat FC Layer Softmax Prediction Probabilities Latent Repesentation 2@1x1 2@1x1 1@6x1 1@3x1 1@3x1 2@147x1 

 CNN Classifier The first component is a convolutional neural network  (Lecun, 1989) (henceforth, CNN) . CNNs, to some extent, take into account the ordering of the words and the context in which each word appears. We generate the required embedding by passing the subword embeddings of a sentence individually into 1-D CNN. We perform a convolution with 3 different filter sizes (2, 3 and 4), before adding a bias and applying a non-linear RELU activation. The idea behind using several filter sizes was to capture contexts of varying lengths. The convolution layer is used to extract local features around each word window, while the max-pooling layer is used to extract the essential features in the feature map. XLM-R embeddings are passed through this component and, ultimately, through a softmax function to obtain the predictions of the first component. We call these predictions p CN N . 

 Self-Attention Classifier The second component is a self-attention based classifier (See figure  4 ). It helps in choosing the overall sentiment when presented with a mixture of sentiments. We use soft-attention  (Xu et al., 2015) , a deterministic, differentiable attention mechanism, where a softmax gives the weights for each subword, and the output of the attention module is a weighted sum of hidden representations at each location. The self-attention component comprises a BiLSTM  (Hochreiter and Schmidhuber, 1997 ) layer, which takes as input the output of the XLM-R encoder. The hidden state obtained from the BiLSTM layer for each subword is used to calculate the attention scores. Suppose a sequence is given by the subwords (w 1 , w 2 , ..., w n ). Let the i th forward hidden state in the BiLSTM be represented by ? ? h i and i th backward hidden state by ? ? h i . The combined annotation k i is obtained by concatenating ? ? h i and ? ? h i . We first concatenate the forward and backward hidden states to obtain a combined annotation (k 1 , k 2 , ..., k n ). k i = [ ? ? h i ; ? ? h i ] (1) The attention mechanism gives a score e i to each subword i in the sentence S, as given by (  2 ). e i = k i T k n (2) Then the attention weight a i of each k i is computed by normalizing the attention score e i a i = exp(e i ) n j=1 exp(e j ) (3) We then calculate the sentence latent representation vector h using equation (  4 ) h = n i=1 a i ? k i (4) The representation is thus a weighted combination of all the hidden states. The representation vector h is then passed through a fully connected layer followed by a softmax to obtain predictions p att . The predictions from the first and second components are aggregated (See figure  5 ) using element wise product (denoted by ?) to obtain the final predictions (p f inal = p CN N ? p att ). We experimented with other aggregating techniques like linearly weighted average, but element-wise product worked out better.  

 Data Description We used the dataset provided by the organizers of Task-9 of SemEval 2020  (Patwa et al., 2020)  for training both Hinglish and Spanglish models. The data has been annotated semi-automatically. The statistics of the dataset are shown in Table  1 . The dataset for Hinglish is balanced while that of Spanglish is highly unbalanced. For hyperparameter tuning, we used the validation set provided by the organizers. 

 Experiments and Results We first trained a vanilla CNN model on the provided dataset using the XLM-R embeddings. The CNN model seemed to be confused on neutral data points but worked well on positive and negative tweets. The self-attention model outperforms the previous model on neutral data points though it performs worse on the positive and negative samples. The good performance on neutrals can be attributed to the fact that neutral tweets may contain multiple sentiment bearing units which the model is capable of handling. Combining the results of CNN with those of the Self-Attention model was the primary motivation for using an ensemble of the two. The ensemble outperforms all our previous models, achieving a recall of 0.705 with an F1-score of 0.707 on the Hinglish test dataset and a recall of 0.696 with an F1-score of 0.725 on the Spanglish test dataset (See table 2). The confusion matrices for the ensemble on both datasets are shown in figure  6  and 7 (o : neutral, + : positive, -: negative). Our team was ranked 5 th among 62 teams in Hinglish and 13 th among 29 teams in Spanglish. To visualize the sentence embeddings learned by the model for the Hinglish test dataset, we projected the sentence vectors obtained before the final fully connected layer onto a lower-dimensional subspace using the t-SNE algorithm (van der Maaten and Hinton, 2008) for the two components (See figure  8 ). For CNN, the positive and negative tweets seem to form two distinct clusters, while the neutral tweets are scattered among them. In contrast, for the self-attention component, neutrals seem to form a distinct cluster, while the positive and negative classes are partially dispersed in a wide region. Thus, the two components, in a way, complement each other for better predictions over all the three classes. 7 Conclusion For our system, we use an ensemble of CNN and Self Attention architectures with XLM-R multilingual embeddings. We analyze which models work better for different classes of tweets. Our self-attention system helps in better classification of neutral tweets, which are difficult to classify due to multiple sentiment bearing units. Creating an ensemble with CNN helps in better classification of all the three classes. We also visualize how our model performs on different classes of tweets using the t-SNE algorithm. Our results show an improvement over some of the previous works in this field. Figure 2 : 2 Figure 2: XLM-R Encoder 

 Figure Figure 3: CNN Classifier 

 Figure 6 : 6 Figure 6: Confusion matrix for Ensemble on Hinglish test data 

 Figure 8 : 8 Figure 8: Visualisation of CNN and Self-Attention Sentence Vectors 

 Table 1 : 1 Statistics of training and development data 1@13x1024 Dataset Positive Neutral Negative CNN Classi er Train Hinglish 5264 4634 4102 Aggregator Spanglish 6005 3974 2023 Function Validation Hinglish 982 1128 890 Sentence Matrix Self-Attention Classi er Output Logits Test Spanglish 1498 Hinglish 1000 994 1100 506 900 Figure 5: Ensemble Classifier 

 Table 2 : 2 Performance of Ensemble system on Hinglish and Spanglish test datasets F1 Macro Macro o + - Macro Precision Recall Hinglish 0.640 0.762 0.729 0.707 0.712 0.705 Spanglish 0.135 0.825 0.375 0.725 0.763 0.696 6 Analysis 6.1 Visualization of the individual components 

			 https://www.google.com/inputtools/services/features/transliteration.html 

			 Validation data was used for constructing the confusion matrix for spanglish as true labels for test data were not available
