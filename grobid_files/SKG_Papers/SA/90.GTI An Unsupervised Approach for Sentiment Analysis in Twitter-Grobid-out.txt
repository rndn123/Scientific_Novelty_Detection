title
GTI: An Unsupervised Approach for Sentiment Analysis in Twitter

abstract
This paper presents the approach of the GTI Research Group to SemEval-2015 task 10 on Sentiment Analysis in Twitter, or more specifically, subtasks A (Contextual Polarity Disambiguation) and B (Message Polarity Classification). We followed an unsupervised dependency parsing-based approach using a sentiment lexicon, created by means of an automatic polarity expansion algorithm and Natural Language Processing techniques. These techniques involve the use of linguistic peculiarities, such as the detection of polarity conflicts or adversative/concessive subordinate clauses. The results obtained confirm the competitive and robust performance of the system.

Introduction The domain of sentiment analysis has received increasing attention in recent years  (Liu, 2012) , particularly due to the growth of the Internet and content generated by users of social networks and other platforms. Some of these, such as Twitter, allow people to express their opinions using colloquial, compact language. The result is a new form of expression that may in the long term become a source of extremely valuable information. An increasing number of companies are now focusing their marketing campaigns on online comments, sentiments, and opinions of brands from clients or potential clients, and some are even trying to predict the acceptance and rejection of certain products using this information  (Jansen et al., 2009) . Even though the approaches used for this purpose are numerous and varied, they can be broadly divided into two categories: supervised machine-learning and unsupervised semantic-based approaches. The former are often classifiers built from features of a "bag of words" representation  (Hu and Liu, 2004; Pak et al., 2010) . In other words, they consist of automatically analyzing n-grams in search of recurrent combinations of opinion words. The latter aim at capturing and modeling linguistic knowledge through the use of dictionaries  (Taboada et al., 2011)  containing words that are tagged with their semantic orientation. These methods detect the words present in a text using different strategies involving lexics, syntax or semantics  (Quinn et al., 2010)  and then aggregate their values. Such methods usually combine two or more levels of analysis. In recent years, work on sentiment classification using different types of texts has shown that specialized methods are required. For example, emotions are not conveyed in the same manner in newspaper articles as in blogs, reviews, forums or other types of user-generated content  (Balahur, 2013) . Dealing with sentiment in Twitter, thus, requires an analysis of the characteristics of tweets and the design of adapted methods. This paper presents a method for sentiment analysis in English that uses dependency parsing to determine the polarity of tweets, using a previously created sentiment lexicon and considering the special structure and linguistic content of these postings. The remainder of this article is structured as follows: Section 2 provides a brief description of the task and some of its subtasks. Section 3 presents in detail the system proposed for the performance of these tasks, and Section 4 shows the results obtained and discusses them. Finally, Section 5 summarizes the main findings and conclusions. 

 Task Description This paper describes our contribution to the SemEval-2015 Task 10: Sentiment Analysis in Twitter. Of the five subtasks established, we participated in two: ? Contextual Polarity Disambiguation (A), on determining the polarity of a marked instance of a word or phrase in the context of a given message. ? Message Polarity Classification (B), on classifying the content of a whole message. This year there were two datasets for testing candidate systems for substasks A and B: The Official 2015 Test and a Progress Test. The first test consisted of a set of Twitter messages  (Rosenthal et al., 2015)  whilst the second test was a rerun of  SemEval-2014 Task 9 (Rosenthal et al., 2014 , which includes Twitter messages and other kinds of texts from different domains. Datasets formed by the datasets given in  SemEval-2013 Task 2 (Nakov et al., 2013  were also provided for training and development. In our case, the approach does not involve any training, and all the datasets were used to test the behavior of our system. 

 System Overview The main objective of the tasks was to detect whether a marked instance of word/phrase in a given context (A) or message (B) expresses positive, negative or neutral sentiment. Most learning-or lexiconbased systems do not usually take into account relations between words, although they try to simulate comprehension of some linguistic constructions, such as negation, but this does not always work correctly due to the complexity of human language. For this reason, in this paper, we propose an alternative system to exploit the information present in dependencies obtained from a parsing analysis, without the need for any kind of training. The research we describe in this section has several linguistic peculiarities that were used to improve sentiment detection performance. Our method, which was fully unsupervised, consisted of four stages, which are each explained in detail below. 

 Preprocessing Working with tweets presents several challenges for natural language processing. The language used on social media sites is quite different from that used in other forums because it often contains words that are not found in a dictionary. One reason is that tweets have particular orthographic and typographical characteristics, such as letter or word duplication. Hence, before applying our approach, it was necessary to start with a data preprocessing stage to normalize the language used, remove noisy elements and generalize the vocabulary used to express sentiment. The aim of the preprocessing module is to bring tweets as close as possible to natural language by eliminating expressions that are not considered part of current usage, in order to minimize the noise in later stages. There are four main steps involved: ? URL links (such as "http://url"), hashtags links (such as "#hashtag") and username links (such as "@username") are replaced with "URL", "HASHTAG" and "USERNAME" placeholders respectively. ? Replicated characters are removed to return the word to its normal form, such as sweeeeet ? sweet. ? ? Abbreviations 2 are replaced with their respective full written forms, such as h8 ? hate. 1 taken from the list available at http://www.datagenetics.com/blog/october52012/index.html 2 taken from the lists available at http://chatslang.com/terms/abbreviations. 

 Lexical and syntactic analysis In order to derive the syntactic context, each preprocessed social media message must first be broken into tokens and then into sentences. To then ensure that all inflected forms of a word are covered, lemmatization and part-of-speech (POS) tagging are performed using the Freeling Tagger  (Atserias et al., 2006; Padr? et al., 2012) , or more specifically, its tagger implementation based on HMM  (Brants, 2000) . Freeling is a library that provides multiple language analysis services, including probabilistic prediction of categories of unknown words. POS tagging allows the identification of lexical items that can contribute to the correct recognition of sentiment in message. These items are namely adjectives, adverbs, verbs and nouns. The resulting lemmatized and POS-annotated messages are fed to a parser that transforms the output of the tagger into a full parse tree. Finally, the tree is converted to dependencies, and the functions are annotated. The entire process is performed with Freeling Parser  (Padr? et al., 2012) . 

 Sentiment lexicons Sentiment lexicons, such as SOCAL  (Taboada et al., 2011) ,  AFINN (Nielsen et al., 2011)  and NRC Emotion and Hashtag Sentiment Lexicon  Mohammad et al., 2013b) , have been used in many systems for determining the semantic orientation of a phrase within a tweet or sentence. These lexicons contain English word lists sorted by lexical category, i.e. adjectives, verbs, nouns and adverbs. Each word is assigned a score of between -5 and 5. However, these lexical resources are intrinsically non-contextual, so it is necessary to improve their coverage. To do this, we need to acquire new polarities of subjective words that are not present in generic dictionaries and adapt the scores of the other words using the data available. Consequently, we apply an automatic polarity expansion algorithm based on graphs  (Cruz et al., 2011) . The graph is generated from the syntactic dependencies provided by the Freeling Parser, considering only those involving verbs, nouns and adjectives. The starting point of the algorithm is a subset of negative and positive words, that are fed into the system as seed words. In this regard, we chose the most negative and positive words in the SOCAL and AFINN lexicons, as they resulted to work quite well for the datasets provided, after carrying out different experiments through the training datasets. Then, we apply the iterative polarity expansion through the created graph, and the result is merged with the unique word list of SOCAL/AFINN lexicons, incorporating 5982 of new words. The next step is to include emoticon labels, together with their polarities, in the resulting sentiment lexicon. 

 Sentiment Detection Once the lexical and syntactic analyses are complete, it is possible to estimate the polarity resulting from a message. In other words, its sentiment can be expressed by a real number, which can be later interpreted as positive, negative or neutral. This value is computed by using the lexical polarities of the words included in the text (provided by the sentiment lexicon we have generated), and subjecting the special parsing structure and its content to linguistic processing which is described below. Once these have been applied, the resulting sentiment is a propagation of the values of linguistic elements within the dependencies, from the leaves to the upper levels until the root is achieved  (Caro, 2013) . Then, it is classified according to defined interval. 

 Intensification treatment Intensifiers and diminishers, such as "very" or "a little", are usually adverbs that emphasize or attenuate the semantic orientation of the words or expressions they precede. Intensification is achieved by associating a positive or negative percentage, which implies a graduation depending on its type  (Zhang et al., 2012) . For instance, in "very good", "very" enhances the positivity of "good". Our system detects these structures and uses the parsing to identify the exact scope of the intensification whose semantic orientation will be altered. Superlative adjectives are also taken into account by asuming that they behave like a word accompanied by an intensifier. An example is "greatest", where the superlative implies an intensification of the word "great". 

 Negation treatment Negation can be used to deny or reject statements. It is expressed grammatically through a variety of negator words, such as "no", "not", "never" or "neither"  (Zhang et al., 2012) . In our case, it is first necessary to identify the dependencies in which any of the above negator forms are present to estimate the negation scope. Later, the semantic polarities of the words involved in the affected dependencies are modified using a negative factor. 

 Polarity conflict treatment The mere application of polar lexicons, intensifiers, diminishers and negators on a syntactic structure is insufficient. That is, words cannot be considered individually  (Moilanen et al., 2007) . The meaning and polarity of "unpleasant dream" differs for example from those of "wonderful dream". The first statement has a negative connotation while the second has a positive one. In both cases, the word "dream" is involved, and we could expect that, regardless of its accompanying terms, it should behave in a specific way, with certain polarity effects or expectations. However, the meaning changes significantly with the addition of "unpleasant" or "wonderful". In these cases, our system is able to detect polarity conflicts, i.e., it recognizes when a positive adjective modifies a negative noun, or vice-versa, and subsequently reduces the polarity of the elements that cause the conflict. 

 Adversative/concessive clause treatment There is a point in common between adversative and concessive subordinate clauses. While the former express an objection in compliance with what is said in the main clause, the latter express a difficulty in fulfilling the main clause, although it is not impossible. In both cases, one part of the sentence is in contrast with the other part. For this reason, in a context of sentiment analysis, we can assume that both constructions will restrict, exclude, amplify or diminish the sentiment reflected in the clauses. In this regard, it is necessary to clearly distinguish them. In an adversative structure, the argument introduced by items such as "but" or "however" is usually more important  (Winterstein, 2012; Poria et al., 2014) , while in a concessive structure, that introduced by items such as "despite" or "in spite of" is the least important  (Rudolph, 1996) . Our approach is able to coherently estimate the sentiment of sentences that involve not only adver-sative clauses, such as "Bill Maher may be a little out there, but he does make some points" (where the speaker is backing the view of Bill in general), but also concessive clauses such as "Despite going off on Saturday, it looks like Ian Bennett could be fine for Wembley" (where what appears to be really important is that Ian could go to Wembley). 

 Experimental Results In this section we describe the experiments we conducted for both subtasks. These experiments were carried out using the datasets provided by the SemEval-2015 task organizers. These datasets are composed of texts extracted from Twitter (including sarcastic tweets), LiveJournal and phone text messages. The performance of each system is measured by means of the F-score, calculated as shown in Equation  1 , F-score = (F P + F N )/2 (1) where F P stands for the F-score estimated only for positive results. In this case, this value is computed as shown in Equation  2 , where P P represents the precision and R P the recall, both for positive results. The same is calculated for negative results, denominated F N . F P = (2 * P P * R P )/(P P + R P ) Table  1  presents the overall score for subtasks A and B, in Twitter2015 Test, as well as precision, recall and F-measure values for positive (P), negative (N) and neutral (NEU) results.  The approach previously described was applied on both datasets (A and B) in the same way using the  As can be seen, all our results are adjusted, so we can state that our system has no bias for one particular result, but performs quite well for all three types of answers. However, as can be seen in subtask A, the performance measures for neutral tweets are notably lower than those obtained for positive and negative tweets. This can be explained by the content of the dataset provided, which contained 1006 negative and 1896 positive tweets, but just 190 neutral tweets, which is an insufficient sample for producing reliable estimates on precision. The same problem happened for progress test A, where the proportions of tweets are similarly unbalanced. Detailed scores for progress tests of subtasks A and B are shown in Table  2 . In general, we can say that our system is quite stable, as it generates similar results for the different kinds of texts under evaluation. Also of note are the high percentages obtained for sarcastic tweets, which ranked in the first position in subtask A and in the tenth (test dataset) and sixth positions (progress dataset) in subtask B (as shown in Table  3 ). 

 Conclusions This paper describes the participation of the GTI Research Group, AtlantTIC Centre, University of Vigo, in SemEval-2015 task 10: Sentiment Analysis in Twitter. We achieved our results using a fully unsupervised approach for message-level and phrase-  level sentiment analysis of tweets. Table  3  shows our position in the ranking published for both subtasks A and B for all the different datasets evaluated. Our approach comprises different processing stages, including the generation of sentiment lexicons, test preprocessing and the application of different methods for determining contextual polarity based on syntactical structure. This makes our approach robust in diverse contexts without the need for previous manual tagging of datasets. To the best of our knowledge, it is the only system presented in this competition whose sentiment analysis method does not require any supervision. Emoticons 1 are replaced by one of nine labels: e laugh, e happy, e surprise, e positive state, e neutral state, e inexpressive, e negative state, e sad and e sick. For instance, :-( is replaced with e sad. 

 Table 1 : 1 Results of our approach for subtasks A and B. 

 Table 2 : 2 Performance of our approach on the progress test A and B. generated sentiment lexicon and applying the propa- gation of the sentiment values within the dependen- cies. After performing several tests on the training datasets provided by organizers, we set the neutral sentiment intervals to [?0.05, 0.05] for subtask A and [?1.0, 1.0] for subtask B. 

 Table 3 : 3 Position of our approach for each test and task, according to results provided on January 1, 2015.
