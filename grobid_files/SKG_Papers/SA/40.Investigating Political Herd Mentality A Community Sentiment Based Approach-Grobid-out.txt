title
Investigating Political Herd Mentality: A Community Sentiment Based Approach

abstract
Analyzing polarities and sentiments inherent in political speeches and debates poses an important problem today. This experiment aims to address this issue by analyzing publiclyavailable Hansard transcripts of the debates conducted in the UK Parliament. Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts currently surpasses the benchmark results on the same dataset. Such sentiment classification systems could prove to be of great use in today's politically turbulent times, for public knowledge of politicians stands on various relevant issues proves vital for good governance and citizenship. The experiments also demonstrate that continuous feature representations learned from graphs can improve performance on sentiment classification tasks significantly.

Introduction One of the key aspects of a functional, free society is being presented with comprehensive options in electing government representatives. The decision is aided by the positions politicians take on relevant issues like water, housing, etc. Hence, it becomes important to relay political standings to the general public in a comprehensible manner. The Hansard transcripts of speeches delivered in the UK Parliament are one such source of information. However, owing to the voluminous quantity, * Indicates equal contribution. esoteric language and opaque procedural jargon of Parliament, it is tougher for the non-expert citizen to assess the standings of their elected representative. Therefore, conducting stance classification studies on such data is a challenging task with potential benefits. However, the documents tend to be highly tedious and difficult to comprehend, and thus become a barrier to information about political issues and leanings. Sentiment analysis of data from various relevant sources (social media, newspapers, transcripts, etc.) has often given several insights about public opinion, issues of contention, general trends and so on  (Carvalho et al., 2011; Loukis et al., 2014) . Such techniques have even been used for purposes like predicting election outcomes and the reception of newly-launched products. Since these insights have wide-ranging consequences, it becomes imperative to develop rigorous standards and state-of-the-art techniques for them. One aspect that helps with analyzing such patterns and sentiments is studying about the interconnections and networks underlying such data. Homophily, or the tendency of people to associate with like-minded individuals, is the fundamental aspect of depicting relationships between users of a social network (for instance). Constructing graphs to map such complex relationships and attributes in data could help one arrive at ready insights and conclusions. This comes particularly useful when studying parliamentary debates and sessions; connecting speakers according to factors like party or position affiliations pro-vides information on how a speaker is likely to respond to an issue being presented. Attempts to analyze social media data based on such approaches have been made  (Deitrick and Hu, 2013) . 

 Related Work The analysis of political content and parliamentary debates have opened an exciting line of research in recent years and has shown promising results in tasks of stance classification  (Hasan and Ng, 2013)  and opinion mining  (Karami et al., 2018) . A large part of the work initially concentrated on legislative speeches, but the focus has shifted to social media content analysis in recent times. This shift in focus has been particularly rapid with the proliferation of social media data and research (?  Shah and Zimmermann, 2017; Shah et al., 2016b; Mahata et al., 2018; Shah et al., 2016c,a) . Lauderdale and Herzog (2016) presented their method of determining political positions from legislative speech. The datasets were sourced from Irish and US Senate debates.  Rheault et al. (2016)  examined the emotional polarity variations in speeches delivered in the British parliament over a hundred years. They observed a correlation between the variations in emotional states of a particular period of time and the national economic situation.  Thomas et al. (2006)  studied the relationships between segments of speeches delivered in the Congress and the overall tone: of opposition or support. A significant amount of research exists on the political temperament across social media websites like Facebook and Twitter.  Stieglitz and Dang-Xuan (2012)  studied the relationship between the inherent sentiment of politically relevant tweets and the retweet activity.  Ceron et al. (2014)  proposed methods for determining the political alignments of citizens and tested them on French and Italian-context datasets. Many new findings based on the contemporary political landscape continue to be developed and presented.  Wang and Liu (2018)  analyzed US President Donald Trump's speeches delivered during his 2016 election campaign.  Rudkowsky et al. (2018)  proposed the usage of word embeddings in the place of the traditional Bag-of-Words (BOW) approach for text analysis, and demonstrated experiments on Austrian parliamentary speeches. There have been some approaches to model interactions among members of a network to help in the task of sentiment analysis. Moreover, there have been applications that extract information about each user by representing them as a node in the social graph and creating low dimensional representation usually induced by neural architectures  (Grover and Leskovec, 2016) .  Mishra et al. (2018)  and  Qian et al. (2018)  use such social graph-based features to gain considerable improvement in the task of abuse detection in social media. However there has been no work done to model the interaction between the members of the Parliament for the task of stance classification. For studying transcripts of speeches delivered in the House of Commons in the UK Parliament, Abercrombie and Batista-Navarro (2018b) curated a dataset consisting of parliamentary motions and debates as provided in the Hansard transcripts, along with other information like party affiliations and polarities of the motions being discussed. This was followed by carrying out studies on the dataset and developing a sentiment analysis model which also demonstrated the results of motionindependent (one-step) and motion-dependent classification of polarities  Abercrombie and Batista-Navarro (2018a) . This dataset is used for further analysis in our experiments. 

 Dataset In the UK, transcripts of parliamentary debates are publicly available along with information related to division votes as well as manually annotated sentiment labels. To investigate the effectiveness of our pipeline, experiments were conducted using the HanDeSeT dataset as created by (Abercrombie and Batista-Navarro, 2018b). The dataset consists of 607 politicians and their speeches over various motions, with a total of 1251 samples. The speeches are divided into five utterances, and other features such as Debate ID, Debate title, Motion subject with polarities: manual annotation and ruling-opposing-based, Motion and Speaker party affiliations, Speech Polarities: manual and votebased, Rebellion percentage. Sentiment polarity is present in both speeches and motions. Hence labels are provided for motion polarities as well. Two label types are provided for motions: a manually-annotated one predicting positive or negative polarity, and a government/opposition one decided as follows: if the speaker who proposes the motion belongs to the ruling government, the polarity is positive; if the speaker belongs to the opposition then the polarity is negative. Two label types are provided for speeches as well: one manually-annotated, and the other a speaker-vote label extracted from the division related to the corresponding debate. 

 Methodology The models described in Abercrombie and Batista-Navarro (2018a) extracted n-gram features (uni-grams, bi-grams, tri-grams, and their combinations) from the utterances for sentiment classification. The stance-based relationships between the members are modeled, and their effectiveness is analyzed. This study aims to develop on the limitations of using only text-based features and by doing so present a sound, coherent model for sentiment classification for parliamentary speeches. The methodology consists of the following subsections: preprocessing, to describe the initial data preprocessing methods undertaken; feature extraction, which discusses feature sets used for our model, and model description and training, to elaborate on our model and training procedures. 

 Preprocessing The dataset was preprocessed for further analysis. This was required so unnecessary words; characters etc. could be removed and not add further noise to the dataset. The text was lower-cased, and all punctuation marks and other special characters were removed. Following this, stopword removal was done using NLTK. Finally, a few custom stopwords specific to the parliamentary procedure were removed. These were taken from Abercrombie and Batista-Navarro (2018b). Finally, the utterances were concatenated and prepared for feature extraction and model training. 

 Feature Extraction 

 Textual Features Various textual features were extracted for classification and normalized using the L2 norm. These are listed below. ? TF-IDF: Term Frequency-inverse Document Frequency (TF-IDF) features were extracted from n-grams (upto 3) in the text. N-gram features are immensely useful for factoring in contextual information surrounding the components of a text (whether characters or words) and are widely used for text analysis, language processing, etc. ? LDA-based topic modeling: Topic modeling is used to derive information related to the underlying "topics" contained in a text. In order to extract such topic-based features from the utterances, the Latent Dirichlet Allocation (LDA)  (Blei et al., 2003)  model was used. The probability distribution over the most commonly occurring 30 topics was used as features for each speech. ? NRC Emotion: The NRC Emotion Lexicon (Mohammad and Turney, 2013) is a publicly available lexicon that contains commonly occurring words along with their affect category (anger, fear, anticipation, trust, surprise, sadness, joy, or disgust) and two polarities (negative or positive). The score along these 10 features was computed for the utterances. 

 Graph-based features For our analysis, two graphs were constructed from the dataset. The graph consists of nodes that represent the members who participate in the proceedings of the Parliament. The edges among the members are conditioned upon their accord or discord on debates regarding policies. Two members of the same or varying political parties either agree on a policy or differ on it. Therefore, the two graphs are constructed. ? simGraph: In order to model the similarity on stances among members, G sim (v, e) is a weighted undirected graph induced on the dataset with vertices v corresponding to the members m of political parties where an edge e between two vertices v and u is defined as weight(e) =| f (v) ? f (u) | where f (v) is the set of stances taken by the member that is represented by node v. ? oppGraph: Similarly, to model the differences among the members, G opp (v, e) is induced on the dataset such that an edge e between two vertices v and u is defined as weight(e) =| (f (v) \ f (u)) ? (f (u) \ f (v)) | where f (v) is the set of stances taken by the member that is represented by node v. node2vec: To obtain community based embeddings, feature representations were generated using node2vec  (Grover and Leskovec, 2016) . node2vec is similar to word2vec  (Mikolov et al., 2013b)  and uses the same loss function to assign similar representations to nodes that are in the context of each other. To obtain the context of a node, node2vec samples a neighborhood for each of the nodes by constructing a fixed number of random walks of constant length. The traversal strategy for these random walks is determined by the hyper-parameters Return Parameter p and In-out Parameter q which have the ability to moderate the sampling between a depth-first strategy and a breadth-first strategy. The return parameter p controls the likelihood of immediately revisiting a node in the walk, while the in-out parameter q allows the search to differentiate between inward and outward nodes. Formally, given a graph G = (V, E) , we learn a function f : V ? IR d that maps nodes to feature representations where d is the dimension of the representation. In order to do so, for every node u ? V , we define a neighbourhood N S (u) ? V is generated using the sampling strategy S. The skip-gram model  (Mikolov et al., 2013a ) is then employed to maximize the following objective function: max f logP r(N s (u)|f (u)). (1) Combining Graph Embeddings: To combine embeddings generated for each member in the two graphs, a dense neural network was used. The embeddings were projected onto a linear layer and fine-tuned upon the classification task. The penultimate layer of the model was used as the graph embedding corresponding to each user. The network consisted of two input layers for the two embedding sets, followed by single dense layers with hidden layer size 16 and activation ReLU. These two layers were then combined, and the resultant combination passed through two dense layers (layer size 16, activation ReLU), before being passed through a final dense softmax layer. The network was optimized using Adam, and trained over 20 epochs with batch size 64. 

 Other features Of all the feature sets explored in  Abercrombie and Batista-Navarro (2018a) , the feature set all the meta-features had the best results consistently across all the three models. Hence, we used these in addition to our textual and community-based graph features. The meta-features consisted of speaker party affiliation, debate IDs and motion party affiliation. 

 Baseline models The original experiments consisted of 3 models for classification: a one-step model and two two-step models. We consider the two-step models as our baselines, which are described below. ? manAnnot: a two-step model in which motion polarity classification is first performed based on manually-annotated positive or negative sentiments, corresponding to model 2a in the original experiments; ? govAnnot: a two-step model in which motion polarity classification is first performed based on government or opposition labeling, corresponding to model 2b in the original experiments. In the case of the two two-step models, the dataset is divided into two parts based on the predicted polarities. These two divided datasets are then used for training and classification separately. Two classifiers were used in both the steps: Support Vector Machine (SVM) with the linear kernel and Multi-Layer Perceptron (MLP) with 1 hidden layer containing 100 neurons. 

 Proposed model In the original experiment, the best results were obtained from the two-step models with the MLP classifier. A similar two-step approach is followed here as well, with MLP as the chosen classifier. The network consists of 1 hidden layer with 100 neurons. 

 Experiments Experiments on two models are presented: 1. manAnnot: here, the dataset is divided into two parts based on predicted motion polarity from manually annotated labels. 2. govAnnot: Here, the dataset is separated into two parts based on the speaker's affiliation: if the speaker presenting the motion belongs to the ruling government, then the motion polarity is positive, or otherwise negative. The hyperparameters (for each of the feature sets and the classifier) were tuned using grid search. L-BFGS  (Liu and Nocedal, 1989)  was used for optimization in the neural network. Model training and evaluation was carried out using stratified 10fold cross-validation. Stratification was performed to account for the slight imbalance in the dataset. Two types of labels are presented in the dataset: vote-based and manually-annotated. We use the manually-annotated labels for our experiments. For the graph-based features, a grid search was performed which yielded the following parameters for generating embeddings: ? simGraph: p = 10, q = 1, walk length = 15, number of walks = 15, window size = 10. The feature vector obtained from these parameters yielded an accuracy of 79.51%. ? oppGraph: p = 0.1, q = 10, walk length = 5, number of walks = 10, window size = 10. The feature vector obtained from these parameters yielded an accuracy of 69.53%. 

 Results and Discussion Table  2  and Table  3  present the results on the two models respectively. The values of accuracy, pre-cision, recall, and F1-score are presented on feature sets with and without graph-based features. In the case of both models, the usage of graphbased features outperforms the results obtained without using them. The difference is large in the case of the feature set comprising of LDA, NRC, and meta-features in the model with manuallyannotated labels: the F1 scores obtained with and without graph features differ by 7.8%. It can be observed that by using graph-based features The baselines for both have been surpassed by using graph-based features along with the other textual and meta-features. Our best results for manAnnot are obtained by using the combination of LDA, NRC, and graph-based features along with meta-features. The best results for gov-Annot are obtained by using the combination of TF-IDF and meta-features along with graph-based features. 

 Conclusion We presented a method for sentiment analysis of parliamentary debate transcripts, which could go a long way in helping determine the position an elected representative might assume on issues of great importance to the general public. The experiments were carried out on the Hansard parliamentary debates dataset  (Abercrombie and Batista-Navarro, 2018b) . We performed experiments on a variety of textual analysis methods (e.g. topic modeling, emotion classification, n-grams), and combined them with community-based graph features obtained by representational learning on the dataset using node2vec. Our results surpass the state-of-the-art results using both govAnnot and manAnnot. Also, the F1 and accuracy values of the models using graph-based features are higher than those without graph-based features, the difference being considerable in some cases. This gives sufficient demonstration for the ability of representational learning to enhance performances on tasks like sentiment analysis. 
