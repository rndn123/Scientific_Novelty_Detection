title
Machine Translation of Spanish Personal and Possessive Pronouns Using Anaphora Probabilities

abstract
We implement a fully probabilistic model to combine the hypotheses of a Spanish anaphora resolution system with those of a Spanish-English machine translation system. The probabilities over antecedents are converted into probabilities for the features of translated pronouns, and are integrated with phrase-based MT using an additional translation model for pronouns. The system improves the translation of several Spanish personal and possessive pronouns into English, by solving translation divergencies such as ella ? she | it or su ? his | her | its | their. On a test set with 2,286 pronouns, a baseline system correctly translates 1,055 of them, while ours improves this by 41. Moreover, with oracle antecedents, possessives are translated with an accuracy of 83%.

Introduction The divergencies of pronoun systems across languages require in many cases the understanding of the antecedent of a source pronoun to decide its correct translation. For instance, Spanish 3rd person personal and possessive pronouns generally have more than one translation into English: ?l can be rendered by he or it depending on the humanness of the antecedent, while the possessive determiner su can be translated by his, her, its or their depending on the gender, number and humanness of the possessor. In this paper, we provide a fully probabilistic integration of a Spanish anaphora resolution system into a phrase-based machine translation (MT) one, building upon a coreference-aware decoding model that we proposed earlier  (Luong and Popescu-Belis, 2016) . We extend this model by using actual probabilities of antecedents instead of the best candidate only, and by applying the model to Spanish-English pronoun translation, which requires a larger range of antecedent features than English-French. In addition, the test set is considerably larger than in the previous study, and includes possessive determiners (also called adjectives or, as we do here, pronouns), which exhibit larger translation divergencies. The paper is organized as follows. After a review of related work (Section 2), we present in Section 3 the coreference-aware translation model, which is learned from texts with probabilistic anaphoric links hypothesized by a coreference resolution system. This model is combined with a classic phrase-based MT model, as explained in Section 4. The results, presented in Section 5, show an improvement in pronoun translation accuracy of 4% when measured automatically, and reach 83% correct translations with oracle antecedents of possessives. 

 Related Work Recent years have witnessed an increasing interest in improving machine translation of pronouns. Several studies have attempted to integrate anaphora resolution with statistical MT (Le Nagard and  Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012) , but have often been limited by the accuracy of anaphora resolutions systems, even on the best-resourced language, English. For instance, Le Nagard and  Koehn (2010)  trained an English-French translation model on an annotated corpus in which each occurrence of the English pronouns it and they was annotated with the gender of its antecedent on the target side, but failed to improve over the baseline due to anaphora resolution errors.  Hardmeier and Federico (2010)  in-tegrated a word dependency model into the SMT decoder as an additional feature, to keep track of pairs of source words acting respectively as antecedent and anaphor in a coreference link, and improved English-German MT over the baseline. The recent shared tasks on pronoun-focused translation  Guillou et al., 2016)  have promoted a pronoun correction task, which relies on information about the reference translation of the words surrounding the pronoun to be corrected, thus allowing automatic evaluation. Several systems developed for this task avoid direct use of anaphora resolution, but still reach competitive performance.  Callin et al. (2015)  designed a classifier based on a feed-forward neural network, which considered as features the preceding nouns and determiners along with their partsof-speech.  Stymne (2016)  combined the local context surrounding the source and target pronouns (lemmas and POS tags) together with source-side dependency heads. The winning systems of the WMT 2016 pronoun task used neural networks:  Luotolahti et al. (2016)  and  Dabre et al. (2016)  summarized the backward and forward local contexts and passed them to a deep Recurrent Neural Network to predict pronoun translation. In this paper, we exploit anaphora resolution as the main knowledge source, building upon the model we have proposed earlier  (Luong and Popescu-Belis, 2016) , in which coreference features are directly used during the decoding process through an additional translation table. However, we extend our previous model and use additional features, including the source word, and the gender, number and humanness of the antecedent candidates. In addition, instead of training and testing an SMT system on the gender-marked datasets (as did Le Nagard and Koehn (2010)), and use antecedents with absolute confidence, we model the probabilistic connection between a given pronoun and a given gender/number on the training set, and use the probabilistic scores of the antecedent within a coreference model, along with the translation and language models, when decoding. We do not deal, however, with null pronouns, which raise different challenges, addressed e.g. by  Wang et al. (2016)  for Chinese-to-English MT and by Rios Gonzales and  Tuggener (2017)  for Spanishto-English MT. 

 Learning the Coreference Model The coreference model is the essential component of the general framework we proposed earlier  (Luong and Popescu-Belis, 2016) . The goal of the coreference model is to learn the probabilities of translating a given source pronoun, represented by the features of its antecedent, into a target pronoun. Due to anaphora resolution errors and variability in translation, the coreference model is not deterministic, but contains probabilities of translations, which are later combined with those from the translation and language models. We build a fully probabilistic coreference model, unlike our previous attempt, which relied only on the best candidate antecedent. Building the model requires two stages, presented in 3.1 and 3.2 below. The Spanish 3rd-person pronouns that we consider are: (a) the two singular subject pronouns ?l and ella; (b) the two possessive determiners su and sus; (c) the two singular possessive pronouns suyo and suya. The possessive determiners agree in number with the possessed entity (which they determine) and refer to a possessor with unspecified gender and number, hence each of them can be translated by his, her, its or their. The possessive pronouns refer both to a possessed entity (with which they agree in gender and number) and a possessor of unspecified gender and number. Hence, they can be translated into English as his own (one), her own, its own or their own -but not with plural, e.g. not his own ones. 

 Antecedent Identification using CorZu The goal of the first stage is to identify candidate antecedents of each source pronoun in the training data with their probabilities. The Spanish data is processed as follows. More detailed descriptions of the annotations are given by  Rios (2016)  and Rios Gonzales and Tuggener (2017) who also make them public.  1  We use FreeLing 2  (Padro and Stanilovsky, 2012)  for morphological analysis and named entity recognition and classification, Wapiti 3  (Lavergne et al., 2010)  for PoS tagging, and the MaltParser 4  (Nivre et al., 2006)  for parsing. The models for tagging, parsing and co-reference resolution are all trained on the AnCora-ES Spanish treebank  (Taul? et al., 2008) .  5  The CorZu coreference resolution system  (Klenner and Tuggener, 2011; Tuggener, 2016)  annotates the dependency trees with referential entities. CorZu implements a variant of the entity-mention coreference model, and enforces morphological consistency in coreference chains. For selecting antecedents of pronouns, CorZu uses a mention ranking approach: all antecedent candidates are considered at once, and each of them is given a score based on its features (see  Tuggener (2016) , Section 5.3.3). The features include standard ones (distance, grammatical relations, etc.) along with novel ones (animacy, discourse status, morphology, etc.). Their weights are learned using a Naive Bayes classifier. Rather than selecting the candidate with the highest score as the antecedent, we retain a list of the most likely antecedents with their scores, namely all candidates with scores greater than 1% of the highest one, keeping at least two of them (if available). For each candidate antecedent, we extract the following features (obtained from FreeLing): gender (masculine, feminine, or neuter), number (singular or plural) and human (person vs. other). The newly used 'human' feature is intended to help with the English divergencies he/it, his/its, she/it and her/its. 

 Assignment of the Coreference Score To build the coreference model, for each of the anaphoric links found by CorZu, we append to each Spanish pronoun (noted P) the feature values of the respective antecedent (noted G, N, H). Moreover, we consider the English side of the parallel corpus (available with AnCora-ES), and using word-level alignments generated by GIZA++  (Och and Ney, 2003)  we identify the translation of the Spanish pronoun. This results in a set of weighted triples of the form (P-G-N-H, pron EN, probability) -e.g., (ella-femininesingular-person, she, 0.686453) -where probability results from the normalization of the current candidate score with respect to the total of the whole list. We gather all possible triples over the training data. If the candidates do not fully cover all possible P-G-N-H combinations, the remaining combinations will be generated, but with zero probability, and appended to the list in the coreference model. Improving significantly on our previous study, we now compute the co-occurrence probability between each English pronoun (p EN ) and a specific P-G-N-H combination by integrating probability scores from all triples in which they appear, with a normalization factor, as follows: P (p EN |PGNH) = score(PGNH, p EN ) score(PGNH) If coreference resolution and word alignment were perfect, the resulting list would contain only trivial pairs, such as (ella-feminine-singularperson, she, 1.0), but this is far from being the case. Indeed, even after filtering out triples with p < 10 ?5 , we are left with 13,584 triples in the coreference model. The excerpt from the coreference model in Figure  1  shows other translation options for ellafeminine-singular-person: although there are several wrong triples as a consequence of alignment errors, they have small scores compared to that of the likely correct translation.  

 Using the Coreference Model for SMT The Coreference Model (CM) is used within the Moses phrase-based SMT system  (Koehn et al., 2007)  as a second translation model, which will be called instead of the main model whenever the system encounters a Spanish pronoun that is marked as above with its G-N-H features (hence in the form P-G-N-H). We use the configuration declarations in the Moses environment  (Koehn et al., 2007) , as we previously described  (Luong and Popescu-Belis, 2016) , to integrate the CM into the decoder as an additional translation model. The weights of the CM are optimized on a held-out set, unlike our previous study  (Luong and Popescu-Belis, 2016)  in which they were manually set. Before decoding, we first perform anaphora resolution on the source document. Then, the G-N- H features extracted from the best candidate antecedent are appended to the pronoun.  6  For instance, on the following example: "Mi hermana va a la escuela. Su escuela est? detr?s de la catedral.", hermana (sister) is the antecedent of the possessive determiner su, and it is a singular, feminine and human noun. Therefore, su in the second sentence is changed to: "Su-singular-femiminehuman escuela est? detr?s de la catedral." and is given as an input to the MT system, which will use the CM to translate the first word. 

 Results and Analysis 

 Experimental Settings The MT training set for Moses is a part of the News Commentary (NC) 2011 set from WMT, combined with part of NC 2010, with a total of 250,000 ES-EN sentence pairs (see Section 3.1). The parameters are tuned using MERT  (Och, 2003)  on an NC 2011 development subset of 2,713 pairs. Another subset of NC 2011 with 13,000 sentences is used for testing. The language model is trained on an NC 2011 monolingual set with ca. 1.1M sentences. The test data contains 6,134 occurrences of the Spanish pronouns we study here, but CorZu found an antecedent only for 2,286 occurrences. For all other pronouns, our method will not translate them differently from the baseline system, therefore we do not count them below. We measure the Accuracy of Pronoun Translation (APT) by comparing the translated pronouns with those in the reference translation  (Miculicich Werlen and Popescu-Belis, 2016) . The metric first aligns the pronouns in the MT output against a reference translation, using GIZA++  (Och and Ney, 2003)  to align words and then a simple set of heuristics to refine the alignment of pronouns, based on position approximations and knowledge of expected tokens.  7  The APT software then com- putes several scores: the number of identical pronouns (noted C1) and of different ones (C3), the number of untranslated pronouns in the candidate (C4), in the reference (C5) or in both (C6).  8  The goal is to increase C1 and decrease all other scores. APT was found to correlate well with human evaluation, but is stricter than it. 

 Results with CorZu Antecedents The APT scores of the Moses baseline (BL) and our system (CM) are shown in Table  1 . Our system outperforms the baseline by 41 pronouns (net balance of improvements minus degradations), increasing the C1 score from 46% to 48%. Besides, it leaves fewer pronouns untranslated (C4). When examining the translation of the determiner su, the comparison of the first two confusion matrices in Table  2  shows that CM translates su more poorly than BL. In particular, it misses many occurrences of su that should have been translated as its, rendering them generally by his. This is likely due to the wrong labeling of the humanness feature on antecedents found by CorZu, in addition to anaphora resolution errors. In contrast, the occurrences of su that should have been translated with human pronouns (his, her) are better translated by the CM. Notably, despite its ambiguity, Example 1 SRC: no podr? sentirse en su-masc-sg-pers casa en ese pa?s CM: will not be able to be in his house in the country REF: he will scarcely be able to feel at home there Example 2 SRC: y si posible de la UE en su-masc-sg-other conjunto CM: if possible , and of the EU in its set REF: if not the EU as a whole su was often correctly linked by CorZu to a plural noun phrase, leading to a large improvement over the baseline for translations by their (220 vs. 148). One limitation of the CM system is exemplified in Figure  2 . Both mistakes (in red) are due to the CM not considering the context surrounding the pronoun su, i.e. the idiomatic expressions. Indeed, "su casa" and "su conjunto" mean respectively "to feel at home" and "as a whole" as idiomatic expressions, yet they are wrongly translated into "to be in his house" and "in its set" by the coreference model, which simply uses the features assigned to su after the substitution. Although the translations of su are correct in terms of features, the expressions should have been translated by the default translation model. A different strategy to pass antecedent information to the decoder while still using the standard translation model should be found in the future. 

 Results Using Oracle Antecedents To confirm the relevance of our model, and analyze the impact of coreference resolution errors, we selected a subset of 168 sentences with 64 occurrences of su. A native Spanish speaker annotated the correct antecedents and the correspond- 

 C1 C3 C4 C5 C6 CM 31 (48%) 16 8 6 3 OR 53 (83%) 5 0 6 0 Table  3 : APT scores of CM and oracle systems. C1 is the number of su identical to the reference. Using oracle antecedents rather than CorZu ones significantly increases C1. ing gender-number-humanness features for each pronoun. We then translated this data with our CM system, and compared it with the output of CM using CorZu antecedents, in Table  3 . The accuracy when using oracle antecedents is 83%, and among the 11 errors (translations differing from the reference), 8 are in fact considered as correct by a human judge. Oracle antecedents thus lead to nearly perfect translations, as confirmed by the confusion matrix, shown in the lower part of Table  2 . 

 Conclusion and Perspectives We presented a method that uses the morphological and semantic features of antecedents to improve the translation of Spanish personal and possessive pronouns into English. The method brings measurable improvements, and an oracle experiment indicates that better anaphora resolution should be even more beneficial to pronoun translation. Future work should integrate coreference into the MT decoder as an additional feature function, so that the surrounding contexts of pronouns are properly considered. In addition, we will attempt to improve the quality of the labels predicted by our resolver, we will use multiple hypotheses on antecedents when decoding, and finally consider the translation of null pronouns as well. Figure 1 : 1 Figure 1: Inside the coreference model: examples of (P-G-N-H, pron EN, probability) triples for the Spanish pronoun ella. 
