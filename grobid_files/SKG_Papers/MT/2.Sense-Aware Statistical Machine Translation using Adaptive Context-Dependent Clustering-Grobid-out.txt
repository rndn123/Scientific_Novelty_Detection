title
Sense-Aware Statistical Machine Translation using Adaptive Context-Dependent Clustering

abstract
Statistical machine translation (SMT) systems use local cues from n-gram translation and language models to select the translation of each source word. Such systems do not explicitly perform word sense disambiguation (WSD), although this would enable them to select translations depending on the hypothesized sense of each word. Previous attempts to constrain word translations based on the results of generic WSD systems have suffered from their limited accuracy. We demonstrate that WSD systems can be adapted to help SMT, thanks to three key achievements: (1) we consider a larger context for WSD than SMT can afford to consider; (2) we adapt the number of senses per word to the ones observed in the training data using clustering-based WSD with K-means; and (3) we initialize senseclustering with definitions or examples extracted from WordNet. Our WSD system is competitive, and in combination with a factored SMT system improves noun and verb translation from English to Chinese, Dutch, French, German, and Spanish.

Introduction Selecting the correct translation of polysemous words remains an important challenge for machine translation (MT). While some translation options may be interchangeable, substantially different senses of source words must generally be rendered by different words in the target language. In this case, an MT system should identify -implicitly or explicitly -the correct sense conveyed by each occurrence in order to select the appropriate translation. Source: And I do really like this shot, because it shows all the detritus that's sort of embedded in the sole of the sneakers. Baseline SMT: Und ich mag dieses Bild . . .  Current statistical or neural MT systems perform word sense disambiguation (WSD) implicitly, for instance through the n-gram frequency information stored in the translation and language models. However, the context taken into account by an MT system when performing implicit WSD is limited. For instance, in the case of phrasebased SMT, it is the order of the language model (often between 3 and 5) and the length of n-grams in the phrase table (seldom above 5). In attentionbased neural MT systems, the context extends to the entire sentence, but is not specifically trained to be used for WSD. For instance, Figure  1  shows an English sentence translated into German by a baseline statistical MT, an online neural MT, and the sense-aware MT system proposed in this paper. The word shot is respectively translated as Schuss (gun shot), Bild (drawing) and Aufnahme (picture) by the online NMT, the baseline system, and our sense-aware system. The latter selects a correct sense, which is identical to the reference translation, while the first two are incorrect (especially the online NMT). In this paper, we introduce a sense-aware statistical MT system that performs explicit WSD, and uses for this task a larger context than is accessible to state-of-the-art SMT. Our WSD system performs context-dependent clustering of word occurrences and is initialized with knowledge from WordNet, in the form of vector representations of definitions or examples for each sense. The labels of the resulting clusters are used as abstract source-side sense labels within a factored phrasebased SMT system. The stages of our method are presented in Figure  2 , and will be explained in detail in Section 3. Our results, presented in Section 5, show first that our WSD system is competitive on the Se-mEval 2010 WSD task, but especially that it helps SMT to increase its BLEU scores and to improve the translation of polysemous nouns and verbs, when translating from English into Chinese, German, French, Spanish or Dutch, in comparison to an SMT baseline that is not aware of word senses. With respect to previous work that used WSD for MT, discussed in Section 2, we innovate on the following points: ? we design a sense clustering method with explicit knowledge (WordNet definitions or examples) to disambiguate polysemous nouns and verbs; ? we represent each token by its context vector, obtained from word2vec word vectors in a large window surrounding the token; ? we adapt the possible number of senses per word to the ones observed in the training data rather than constraining them by the full list of senses from WordNet; ? we use the abstract sense labels for each analyzed word as factors in an SMT system. 

 Related Work Word sense disambiguation aims to identify the sense of a word appearing in a given context  (Agirre and Edmonds, 2007) . Resolving word sense ambiguities should be useful, in particular, for lexical choice in MT. An initial investigation found that an SMT system which makes use of off-the-shelf WSD does not yield significantly better quality translations than a SMT system not using it  (Carpuat and Wu, 2005) . However, another study  (Vickrey et al., 2005)  reformulated the task of WSD for SMT as predicting possible target translations rather than senses of ambiguous source words, and showed that WSD improved such a simplified word translation task. Subsequent studies which adopted this formulation  (Cabezas and Resnik, 2005; Chan et al., 2007; Carpuat and Wu, 2007) , successfully integrated WSD to hierarchical or phrase-based SMT. These systems yielded slightly better translations compared to SMT baselines in most cases (0.15-0.30 BLEU). Although the WSD reformulation above proved helpful for SMT, it did not determine whether actual source-side senses are helpful or not for endto-end SMT.  Xiong and Zhang (2014)  attempted to answer this question by performing word sense induction for large scale data. In particular, they proposed a topic model that automatically learned sense clusters for words in the source language. In this way, on the one hand, they avoided using a pre-specified inventory of word senses as traditional WSD does, but on the other hand, they created the risk of discovering sense clusters which do not correspond to the common senses of words needed for MT. Hence, this study left open an important question, namely whether WSD based on semantic resources such as WordNet  (Fellbaum, 1998)  can be successfully integrated with SMT.  Neale et al. (2016)  attempted such an integration, by using a WSD system based on a sense graph from WordNet  (Agirre and Soroa, 2009) . This system detects the senses of words in context using a random walk algorithm over the sense graph. The authors used it to specify the senses of the source words and integrate them as contextual features with a MaxEnt-based translation model for English-Portuguese MT. Similarly,  Su et al. (2015)  built a large weighted graph model of both source and target word dependencies and integrated them as features to a SMT model. However, apart from the sense graph, WordNet provides also textual information such as sense definitions and examples, which should be useful for disambiguating senses, but were not used in the above studies. Here, we aim to exploit this information to perform word sense induction from large scale monolingual data (in a first phase), thus combining the benefits of semantic ontologies and word sense induction for WSD. Several other studies integrated additional information from a larger context using factored-based MT models .  used supertags from a Combinatorial Categorial Grammar as factors in phrase-based translation model.  Avramidis and Koehn (2008)  added source-side syntactic information for each word for translating from a morphologically poorer language to a richer one (English-Greek). The levels of improvement achieved with factored models such as the ones above range from 0.15 to 0.50 BLEU points. Here, we also observe improvements in the upper part of this range, and they are consistent across several language pairs. 

 Adaptive Sense Clustering for SMT In this section, we describe our adaptive WSD method and show how we integrate it with SMT, as represented in Figure  2  above. In a nutshell, we consider all source words that have more than one sense (synset) in WordNet, and extract from Word-Net the definition of each sense and, if available, the example. We associate to them word embeddings built using word2vec. For each occurrence of these words in the training data, we also build vectors for their contexts (i.e. neighboring words) using the same model. All the vectors are passed to a clustering algorithm, resulting in the labeling of each occurrence with a cluster number that will be used as a factor in statistical MT. Our method answers several limitations of previous supervised or unsupervised WSD methods. Supervised methods require data with manually sense-annotated labels and are therefore often limited to a small number of word types: for instance, only 50 nouns and 50 verbs were targeted in Se-mEval 2010 1 . On the contrary, our method does not require labeled texts for training, and applies to all word types appearing with multiple senses in WordNet. Unsupervised methods often pre-define the number of possible senses for each ambiguous word before clustering the various occurrences according to the senses. If these numbers come from WordNet, the senses may be too fine-grained for the needs of translation, especially when a specific domain is targeted. In contrast, as we explain below, our WSD method initializes a contextdependent clustering algorithm with information from WordNet senses for each word (nouns and verbs), but then adapts the number of clusters to the observed training data for MT. 

 Representing Definitions, Examples and Contexts of Word Occurrences For each noun or verb type W t appearing in the training data, as identified by the Stanford POS tagger, 2 we extract the senses associated to it in WordNet 3 by using NLTK. 4 Specifically, we extract the set of definitions D t = {d tj |j = 1, . . . , m t } and the set of examples of use E t = {e tj |j = 1, . . . , n t }, each of them containing multiple words. While most of the senses are accompanied by a definition, only a smaller subset also include an example of use, as it appears from the four last columns of Table  1 . Less frequently, some senses contain examples without definitions. Each definition d tj and example e tj is represented by a vector, which is the average of the word embeddings over all the words constituting them (except stopwords). Formally, these are d tj = ( w l ?d tj w l )/m t and respectively e tj = ( w l ?e tj w l )/n t . While the entire definition d tj is used to build the vector, we do not consider all words in the example e tj , but limit the sum to e tj i.e. we consider only a window of size c centered around the noun or verb of type W t (similarly to the window used for context representation below) to avoid noise from long examples. All the word vectors w l above are word2vec pre-trained embeddings from Google 5  (Mikolov et al., 2013) . If d is the dimensionality of the word vector space, then all vectors w l , d tj , and e tj are in R d . Each definition vector d tj or example vector e tj for a word type W t will be considered as a center vector for each sense during the clustering procedure. Similarly, each word token w i in a source sentence is represented by the average vector u i of the words in its context, which is defined as a window of c words centered in w i . The value c of the context size is even, since we calculate the vector u i for w i by averaging vectors from c/2 words before w i and from c/2 words after it. We stop nevertheless at the sentence boundaries, and filter out stop words before averaging. We will now explain how to cluster according to their senses all vectors u i for the occurrences w i of a given word type W t , using as initial centers either the definition or the example vectors. 

 Clustering Word Occurrences According to their Senses We aim to group all occurrences w i of a given word type W t into clusters according to the similarity of their senses, which we will model as the similarity of their context vectors. The correctness of this hypothesis will be supported by the empirical results. We will modify the k-means algorithm in several ways to achieve an optimal clustering of word senses for MT. The original k-means algorithm (MacQueen, 1967) aims to partition a set of items, which are here tokens w 1 , w 2 , . . . , w n of a same word type W t , represented through their embeddings u 1 , u 2 , . . . , u n where u i ? R d . The goal of k-means is to partition (or cluster) them into k sets S = {S 1 , S 2 , . . . , S k } so as to minimize the within-cluster sum of squares, as follows: S = arg min S k i=1 u?S i || u ? ? i || 2 , ( 1 ) where ? i is the centroid of each set S i . At the first iteration, when there are no clusters yet, the algorithm selects k random points to be the centroids of the k clusters. Then, at each subsequent iteration t, k-means calculates for each candidate cluster a new point to be the centroid of the observations, defined as their average vector, as follows: ? t+1 i = 1 |S t i | u j ?S t i u j (2) We make the following modifications to the original k-means algorithm, to make it adaptive to the word senses observed in the training data. 1. We define the initial number of clusters k t for each ambiguous word type W t in the data as the number of its senses in Word-Net (but this number may be reduced by the final re-clustering described below at point 3). Specifically, we run two series of experiments (the results of which will be compared in Section 5.1.1): one in which each k t is set to m t , i.e. the number of senses that possess a definition in WordNet, and another one in which we consider only senses that are illustrated with an example, hence setting each k t to n t . These settings avoid fixing the number of clusters k t arbitrarily for each ambiguous word type. 2. We initialize the centroids of the clusters to the vectors representing the senses from WordNet, either using their definition vectors d tj in one series of experiments, or their example vectors e tj in the other one. This second modification attempts to provide a reasonably accurate starting point for the clustering process. 3. After running the k-means algorithm, we reduce the number of clusters for each word type by merging the clusters which contain fewer than 10 tokens with the nearest larger cluster. This is done by calculating the cosine similarity between each token vector u i and the centroids of the larger clusters and assigning the tokens to the closest large cluster. This re-clustering adapts the final number of clusters to the observed occurrences in the training data. Indeed, when there are few occurrences of a sense for a given ambiguous word type in the data, the SMT is likely not able to translate them properly due to the lack of training samples. Finally, after clustering the training data, we use the centroids to assign each new token from the test data to a cluster, i.e. an abstract sense label, by selecting the closest centroid to it in terms of cosine distance in the embedding space. 

 Integration with Machine Translation Our adaptive WSD system assigns a sense number for each ambiguous word token in the source-side of a parallel corpus. To pass this information to an SMT system, we use a factored phrase-based translation model . The factored model offers a principled way to supplement words with additional information -such as, traditionally, part-of-speech tags -without requiring any intervention in the translation tables. The features are combined in a log-linear way with those of a standard phrase-based decoder, and the goal remains to find the most probable target sentence for a given source sentence. To each source noun or verb token, we add a sense label obtained from our adaptive WSD system. To all the other words, we add a NULL label.  6  The translation system will thus take the source-side sense labels into consideration during the training and the decoding processes. 

 Datasets, Preparation and Settings We evaluate our sense-aware SMT on the UN Corpus 7  (Rafalovitch and Dale, 2009)  and on the Europarl Corpus 8  (Koehn, 2005) . We select 0.5 million parallel sentences for each language pair from Europarl, as shown in Table  1 . We also use the smaller WIT3 Corpus 9  (Cettolo et al., 2012) , a collection of transcripts of TED talks, to evaluate the impact of costly model choices, namely the type of the resource (definition vs. examples), the length of the context window, and the k-means method (adaptive vs. original). Before assigning sense labels, we first tokenize all the texts and identify the parts of speech (POS) using the Stanford POS tagger 10 . Then, we filter out the stopwords and the nouns which are proper names according to the Stanford Name Entity Recognizer 10 . Furthermore, we convert the plural forms of nouns to their singular form and the verb forms to infinitive using the stemmer and lemmatizer from NLTK 11 , which is essential because WordNet has description entries only for singular nouns and infinitive form of verbs. The pre-processed text is used for assigning sense labels to each occurrence of a noun or verb which has more than one sense in WordNet. For translation, we train and tune baseline and factored phrase-based models with Moses 12 . We also carried out pilot experiments with neural machine translation (NMT). However, due to the large datasets NMT requires for training, its performance was below SMT on the datasets above, and sense labels did not improve it. We thus focus on SMT in what follows, and leave WSD for NMT for future studies. We select the optimal model configuration based on the MT performance, measured with the traditional BLEU score  (Papineni et al., 2002) , on the WIT3 corpus for EN/ZH and EN/DE. Unless otherwise stated, we use the following settings in the k-means algorithm, starting from the implementation provided in Scikit-learn  (Pedregosa et al., 2011 ): ? we use the definition of each sense for initializing the centroids in the adaptive k-means methods (and compare this later with using the examples); ? we set k t equal to m t , i.e. the number of senses of an ambiguous word type W t ; ? the window size for the context surrounding each occurrence is set to c = 8. For the evaluation of intrinsic WSD performance, we use the V -metric, the F 1 -metric, and their average, as used for instance at SemEval 2010 . To measure the impact of WSD on MT, besides BLEU, we also measure the actual impact on the nouns and verbs that appear in WordNet with several senses, by comparing how many of them are translated as in the reference translation, by our system vs. the baseline. For a certain set of tokens in the source data, we note as N improved the number of tokens which are translated by our system as in the reference translation, but whose baseline translation differs from it. Conversely, we note as N degraded the number of tokens which are translated by the Table  1 : Statistics of the corpora used for machine translation: '?' indicates a similar size, though not identical texts, because the English source texts for the different language pairs from Europarl are different. Hence, the number of words found in WordNet differ as well. baseline system as in the reference, but differently by our system. We will use the normalized coefficient ? = (N improved ? N degraded )/T , where T is the total number of tokens, as a metric focusing explicitly on the words submitted to WSD. 13 

 Results Using the data, settings, and metrics above, we investigate first the impact of two model choices on the performance: centroid initialization for kmeans (definition or examples vs. random), and the length of the context window for each word. Then, we evaluate our adaptive clustering method on the WSD task, to estimate its intrinsic quality, and finally measure WSD+MT performance. 

 Optimal Values of the Parameters 

 Initialization of Adaptive k-means We examine first the impact of the initialization of the sense clusters, on the WIT3 Corpus. In Table  2 , we present the BLEU scores of our WSD+MT system in two conditions: when the kmeans clusters are initialized with vectors from the definitions vs. from the examples provided in the WordNet synsets of ambiguous words. Moreover, we provide BLEU scores of baseline systems and oracle ones (i.e. using correct senses as factors), as well as the ? score indicating the relative improvement of ambiguous words in our system wrt. the baseline. The use of definitions outperforms the use of examples, probably because there are more words with definitions than with examples in WordNet (twice as many, as shown in Table  1  in Section 4), but also because definitions may provide more helpful words to build the initial vectors, as they are more explicit than the examples.  13  The values of N improved and N degraded are obtained using automatic word alignment. They do not capture, of course, the absolute correctness of a candidate translation, but only its identity or not with one reference translation. All the values of ? show clear improvements over the baseline, with up to 4% for DE/EN. As for the oracle scores, they outperform the baseline by a factor of 2-3 compared to our system. Table 2: Performance of our WSD+MT factored system for two language pairs from WIT3, with two initialization conditions for the k-means clusters, i.e. definitions or examples for each sense. In addition, we compare the two initialization options above with random initializations of kmeans clusters, in Table  3 . To offer a fair comparison, we set the number of clusters, in the case of random initializations, respectively to the number of synsets with definitions or examples, for each word type. Clearly, our adaptive, informed initializations of clusters are beneficial to MT.   (Korkontzelos and Manandhar, 2010) 15.70 20.60 8.50 49.80 38.20 66.60 32.75 29.40 37.50  11.54 KSU KDD  (Elshamy et al., 2010)  15.70 18.00 12.40 36.90 24.60 54.70 26.30 21.30 33.50 17.50 Duluth-WSI  (Pedersen, 2010) 9.00 11.40 5.70 41.10 37.10 46.70 25.05 24.20 26.20  4.15 Duluth-WSI-SVD-Gap  (Pedersen, 2010)  0.00 0.00 0.10 63.30 57.00 72.40 31.65 28.50 36.20 1.02 KCDC-PT  (Kern et al., 2010)  1   11.35 11.00 11.70 53.25 47.70 58.80 32.28 29.30 35.25 3.58  Table  4 : WSD results from the SemEval 2010 shared task in terms of V -score, F 1 score and their average. Our adaptive k-means using definitions (last but one line) outperforms all the other systems on the average of V and F 1 , when considering both nouns and verbs, or nouns only. factored system when varying this size, on EN/ZH translation in the WIT3 Corpus, along with the (constant) score of the baseline. The performance of our system improves with the size of the window, reaching a peak around 8-10. This result highlights the importance of a longer context compared to the typical settings of SMT systems, which generally do not go beyond 6. It also suggests that MT systems which exploit effectively longer context, as we show here with a senseaware factored MT system for ambiguous nouns and verbs, can significantly improve their lexical choice and their overall translation quality. Figure  3 : BLEU scores of our WSD+MT factored system on EN/ZH WIT3 data, along with the baseline score (constant), when the size of the context window around each ambiguous token (for building its context vector) varies from 2 to 14. 

 Word Sense Disambiguation Results We evaluate in this section our WSD system on the dataset from the SemEval 2010 shared task  (Man-andhar et al., 2010) , to assess how competitive it is, while acknowledging that our system uses external knowledge not available to SemEval participants. Table  4  shows the WSD results in terms of Vscore and F 1 -score, comparing our method (bottom two lines) with other WSD systems that participated in SemEval 2010 (top four systems for each metric). We add three baselines provided by the task organizers for comparison: (1) Most Frequent Sense (MFS), which groups all occurrences of a word into one cluster, (2) 1Cluster-PerInstance, which produces one cluster for each occurrence of a word, and (3) Random, which randomly assigns an occurrence to 1 out of 4 clusters (4 is the average number of senses from the ground-truth). The V-score is biased towards systems generating a higher number of clusters than the number of gold standard senses. F 1 -score measures the classification performance, i.e. how well a method assigns two occurrences of a word belonging to the same gold standard class. Hence, this metric favors systems that generate fewer clusters (for instance, if all instances were grouped into 1 cluster, the F 1 -score would be high). As these two metrics are biased towards either small or large numbers of clusters, their average is a useful metric as well. Table  4  shows that k-means initialized with definitions achieves high performance and ranks among the top systems for each metric individually, outperforming all other systems on the averaged metric (especially over nouns or all words). Moreover, the adaptive k-means method finds an Table  6 : BLEU scores of our WSD+MT factored system, trained separately on disambiguated nouns vs. verbs, and tested separately or jointly, along with baseline MT and oracle WSD+MT, on five language pairs. average number of senses of 4, which is close to the ground-truth value provided by SemEval (4.46). These results show that our method, despite its simplicity, is effective and provides competitive performance against prior art, partly thanks to additional knowledge not available to the shared task systems. 

 Machine Translation Results Table  5  displays the performance of our factored MT systems trained with noun and verb senses on five language pairs by using the dataset mentioned in Table  1 . Our system performs consistently better than the MT baseline on all pairs, with the largest improvements achieved on EN/ZH and EN/DE. To better understand the improvements over the baseline MT, we also provide the BLEU score of an oracle system which has access to the reference translation of the ambiguous words through the alignment provided by GIZA++. According to the results, our factored MT system bridges around 40% of the gap between the baseline MT system and the oracle system on EN/DE and 30% on EN/ZH. As shown in Table  6 , the translation quality of our factored MT outperforms the baseline when trained with either noun senses or verb senses separately. However, in some cases, our factored MT system trained with both noun and verb senses performs worse than with noun and verb senses separately. This may be due to the lack of sufficient training data to learn reliably using all the addi-tional factors -as we observed when training on the smaller WIT3 Corpus. Lastly, Table  7  shows the confusion matrix for our factored MT and the baseline MT systems when comparing the reference translation of nouns and verbs separately, using GIZA++ alignment. In particular, the confusion matrix displays the number of labeled tokens which are translated as in the reference or not ('Correct' vs. 'Incorrect'). As we can observe, the number of tokens that our factored MT system translates correctly while the baseline MT does not, is two times largers than the number of tokens that the baseline MT system finds correctly while our factored MT does not. 

 Conclusion We presented a sense-aware statistical MT system which uses a larger context than standard ones, through an adaptive context-dependent k-means clustering algorithm for WSD. The algorithm utilizes semantic information from WordNet to identify the dominant clusters, which correspond to senses in the source side of a parallel corpus. The proposed adaptive k-means method is straightforward, yet it provides competitive WSD performance on data from the SemEval 2010 shared task. For MT, our experiments with five language pairs show that our sense-aware MT system consistently improves over the baseline. As future work, we plan to integrate sense information for ambiguous words to neural  MT     Online NMT: Und ich mag diesen Schuss wirklich, . . .Sense-aware MT:Und ich mag diese Aufnahme wirklich, . . .Reference translation:Ich mag diese Aufnahme wirklich, . . . 
