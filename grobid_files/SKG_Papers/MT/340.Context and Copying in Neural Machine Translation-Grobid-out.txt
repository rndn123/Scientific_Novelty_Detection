title
Context and Copying in Neural Machine Translation

abstract
Neural machine translation systems with subword vocabularies are capable of translating or copying unknown words. In this work, we show that they learn to copy words based on both the context in which the words appear as well as features of the words themselves. In contexts that are particularly copy-prone, they even copy words that they have already learned they should translate. We examine the influence of context and subword features on this and other types of copying behavior.

Introduction In translation, certain tokens -often names and numbers -should be copied from the source sentence to the target sentence. Word copying is fairly straightforward in phrase-based statistical machine translation, where unknown words can be left untranslated (copied to the target). It poses more of a challenge in neural machine translation systems, which often use limited or subword vocabularies and soft attention rather than strict alignment. This has resulted in a variety of approaches to copying, which make use of pre-/postprocessing and/or network modifications (e.g. explicit switching between generation and copying). Neural machine translation models that use subword vocabularies to perform open-vocabulary translation have been observed to correctly translate unknown words or copy words (one subword at a time, if need be) even when the full word to be translated or copied was not observed in training.  Koehn and Knowles (2017)  found that neural machine translation systems using subword vocabularies outperformed phrase-based statistical machine translation systems on the translation of unknown words. This raises the questions that we seek to answer: to what extent does byte-pair encoding 1 solve the copying problem (without requiring modifications to the network structure)? 1 A type of subword vocabulary  (Sennrich et al., 2016b) . More generally, what are subword neural machine translation models learning about copying? We find that neural machine translation systems (with attention, trained on subword vocabularies) learn to copy words (both novel and observed) based on their sentential contexts. Additionally, though the models have no knowledge about the components of each subword unit, they learn that certain categories of tokens (e.g. capitalized tokens) tend to be copied. We use quantitative and qualitative evaluations to shed light on what these models learn about copying tokens and about the contexts in which copying occurs. 

 Related Work Prior work on copying in neural machine translation has typically focused on rare or unknown words.  Luong et al. (2015)  augment data with word alignments to train a neural machine translation system (without attention) that emits both a translation and source word positions for any outof-vocabulary (OOV) tokens emitted. They postprocess OOVs with a dictionary or by copying.  Currey et al. (2017)  augment training data with monolingual target language text as bitext and find that it improves copying in low-resource settings.  Ott et al. (2018)  and  Khayrallah and Koehn (2018)  examine negative effects of source copying. Both  Gu et al. (2016)  and  Gulcehre et al. (2016)  modify neural sequence to sequence models to explicitly perform copying.  Gu et al. (2016)  focus on monolingual tasks (dialogue systems and summarization), proposing a model that can both generate and copy text.  Gulcehre et al. (2016)  perform experiments on neural machine translation (with attention), using whole-word vocabularies (and an UNK token to represent unknown words). Their model incorporates a switching variable that determines whether to copy or generate a translation. In this work, we focus on subword vocabularies for neural machine translation, using byte-pair en-  coding  (BPE, Sennrich et al. (2016b) ). The other approaches described are somewhat orthogonal to the use of subword vocabularies, but may require modifications to handle subwords. 

 Data and Models We train German-English (DE-EN) and English-German (EN-DE) neural machine translation models with attention, similar to the University of Edinburgh's WMT 2016 submissions  (Sennrich et al., 2016a) . Models are trained using the Marian toolkit  (Junczys-Dowmunt et al., 2018) .  2  We use the WMT parallel text 3 (Europarl, News Commentary, and CommonCrawl) along with synthetic backtranslated data. 4 

 Initial Analysis We analyze the training data to learn about the prevalence and characteristics of words that should be copied in translation and the contexts in which they occur. We consider both the full training data (including backtranslations and Common-Crawl) and cleaner subsets. We restrict our search for copied words to tokens of length 3 or more characters.  5  Our heuristic for detecting copied tokens is this: a word is a "copied token" if it appears the same number of times in both the source and target sentence.  6  As we will show, copied words tend to belong to specific categories (proper nouns, numbers, etc.) which coincide with their repeated appearance in certain contexts (e.g. names following titles like "Ms" or "Prime Minister"). 4.1 Where do copied words appear? In Table  1 , we see that between 1.8% and 9.2% of tokens are copied.  7  Though the majority (or nearmajority) of sentences do not contain any copied words (of length 3 or more), copied words are still quite prevalent: approximately 18% of sentences in each full training dataset contain one, 4% to 5% contain four, and there is a long tail (one sentence contains 70). Sentences with many copied words often contain direct quotations, third language text (not source/target), or a sequence of copied words (e.g. comma-separated numbers or names). The cleaner Europarl and News Commentary corpora have lower percentages of copied tokens than the overall training data. Of particular note, the backtranslated data contains some examples of copying that we'd prefer for the system not to learn, such as target language words appearing untranslated in the (backtranslated) source side data. 

 What words are copied? We first examine the part-of-speech (POS) tags 8 of copied words. In the EN-DE training data, most copied words are tagged on the English side as NNP (proper noun, singular), including names of individuals, places, or organizations (eg. Gonz?lez, Wales, Union). The next most frequent categories are CD (cardinal number) -including numbers like 42 that should be copied and ones like seven which should be translated -and NN (noun, singular or mass). The results are similar for DE-EN training data (tagged on German with a different tag set): PROPN (proper noun) is the most frequent tag for copied words, followed by NUM (numbers) and NOUN. Punctuation would rank highly if we included short tokens. 

 Experiments and Analysis We address two main questions: (1) Do certain contexts encourage copying? (2) Do certain words exhibit features that make them more likely to be copied (regardless of context)? 

 Contexts Working from the intuition that certain contexts indicate that copying should occur -for example, a name following a title like "Ms" or "Frau" should often be copied -we examine the relationship between context and copying, focusing on left bigram contexts. We show that the machine translation system learns that certain contexts are so indicative of copying that it will even copy (not translate) words that it has learned to translate if they are seen in a sufficiently copy-prone context. For each POS, we collect a set of left bigram contexts that precede a word with that tag. We filter by frequency and diversity of tokens following the bigram. 9 For each context-POS pair, we select 50 random templates from the training data containing the bigram context followed by a word with that POS. 10 Each context-POS pair is associated with a percentage that represents how often it exhibited copying in the training data. For example, in the copy-prone context "thank Mrs [NNP]" the NNP was copied 91.1% of the time, compared to 15.3% of the time in "Republic of [NNP]".  11  We take all word types with a given POS tag from the WMT 2016 test set, dividing them into four categories based on two binary distinctions: observed (in training data) or novel (not observed in training), and copy (typically copied) or noncopy (not typically copied) and filter the observed ones based on training frequency. We count words as non-copy if they were copied ? 30% of the time, and as copy if they were copied ? 70% of Figure  1 : Percent of NNP (EN-DE) tokens copied by how copy-prone the context is, by category. Each point is the percentage of copying for all within-category words, across all example templates for one particular context (averaged over between 1,100 (novel-non-copy) and 13,150 (observed-non-copy) binary copy values). the time.  12  We then combine each word with each POS-appropriate example template and perform preprocessing (including BPE) and translation.  13  Table  2  shows examples. For each context, we calculate the percentage (across all example templates for that context and all words, separated by observed/novel and copy/non-copy categories) of the time that the words in that context were copied. We then compare it to the percentage of the time that copying occurred for that context-POS tag pair in training. Figure  1  shows NNP (EN-DE) results. Both observed-copy and novel-copy words behave almost identically, with copying percentages generally above 80%, and a slight trend upward as contexts become more copy-prone (moving to the right along the horizontal axis). Novel-non-copy words shadow these, but with a drop in copying percentage (see Section 5.3). Most interesting is the observed-non-copy category. In contexts that are not copy-prone, minimal copying occurs. 14 However, as they are placed in increasingly copyprone contexts, even these words that the system has learned it should translate are being copied. We observe the same trend for words tagged NN and CD, and for PROPN, NOUN, and NUM words in the DE-EN direction. This demonstrates that the machine translation system has learned that certain contexts are copy-prone. We manually analyze outliers that appear much  more or less copy-prone than expected. In both cases, the cause appears the same: the context occurred repeatedly in many very similar sentences in the training data. Highly copy-prone contexts that produced copying percentages greater than 70% even in observed-non-copy tokens often appeared in common boilerplate text (e.g. "stay at [NNP]" or "rates for [NNP]" followed by "Hotel").  15  Where we observe lower than expected rates (e.g. ") of [NNP]"), we find that the system may have memorized training sentences. 

 Analysis of Words That Are Not Copied When words are not copied, what sort of output is the system producing? We find that it typically falls into one of four categories: drop (no target token aligns with the source token), change (the word is changed: partially translated, transliterated, or inflected even if it is not a target language word), substitution (the word is replaced with a fluent but not adequate substitute), or translation (translated into a target language word). We begin with an automatic analysis. We randomly sample 200 examples each of sentences containing words that were not copied for novel-copy, novel-non-copy, observed-copy, and observed-non-copy NNPs (EN-DE). We retranslate each sentence and produce a soft alignment matrix from the attention mechanism, then convert the soft alignments between BPE segments into hard alignments between the source word and one or more target words.  16  A word has been dropped if it is unaligned. We count a word as being changed if any words it is aligned to have any subword (BPE segment) overlap with the original word's subwords. Both substitution and translation fall under other; we analyze those manually. Results are shown in Table  3 . 17 For all novel words, the most frequent output type is change. For example, the novel NNP Bishnu is changed into Bischnu in German.  18  Other changes include translations of parts of the word, and concatenation with other tokens. The output token often starts with the same character or sequence of characters as the source token.  19  We manually inspect examples in the other category. For observed-non-copy words, almost all are translations (e.g. Sea translated correctly as Meer), as expected. For observed-copy words, we see a mix of translations and other changes to the words, which are almost evenly split between substitutions and small changes. These include inflections (e.g. Bremen magazine reasonably translated as Bremer Magazin 20 ). Within the other category, perhaps the most interesting cases are those where words appear to be substituted with a fluent but not adequate alternative. Many substitutions occur when the rare word is inserted next to a word that often forms a collocation (like "United States" -in sentences that include "in the  [NNP]  States" the translation sometimes defaults to a translation of "United States" regardless of the actual NNP inserted in place of "United"). Others have a less common NNP swapped for one that belongs to a similar semantic category (e.g. the place name Dublin being generated instead of the less common Halle -as  Arthur et al. (2016)  and others observed). For novel-copy words labeled as other, three quarters are substitutions and one quarter exhibit small changes. The reverse is true for novel-non-copy words: the majority exhibit small changes while almost thirty percent are substitutions. 

 Properties of Copied Words Certain words exhibit properties that make them more likely to be copied, regardless of context. At first glance, it seems unintuitive that the rate of copying of novel-copy words and novel-noncopy words differs (Fig.  1 ) -the model has never observed any of these words, and they are being presented in identical contexts -why does it differentiate between them? Doing so indicates that the model has learned what makes a sequence of dom sample were copied by the the AmuNMT decoder. 18 A near-transliteration -the "sh"/"sch" transformation is seen in  e.g. "ship" and "Schiff". 19  Appendix D contains examples of this and more.  20  Bremen and Bremer are unique BPE segments, so the change heuristic could not be applied. subwords likely to be copied.  Belinkov et al. (2017)  observe that neural machine translation models may encode information about part-of-speech, which could be used when determining whether or not to copy (but does not explain within-POS differences). For numbers, it mainly learns to copy numerical portions while changing commas to periods and vice versa (as required by the target language's conventions). Nouns and proper nouns are more interesting: some should be translated (e.g. novel noun compounds like hallmate), or, in the case of misspellings (e.g. manfacturer), corrected, while others should be copied. For novel NN words, there is another striking difference between copy and noncopy: most of the former contain capital letters and most of the latter do not. 

 Capitalization and Copying To experiment with the influence of capitalization on copying, we take each novel NNP word (96 copy and 22 non-copy) and convert it to lowercase, leave it in its natural case (all have at least one uppercase letter), or convert it to uppercase. We then translate all of them in all NNP contexts (from previous EN-DE experiments). Using only novel words sidesteps the issue of truecasing. Lowercase words are the least frequently copied (average copy rate of 40.2%), uppercase words are the most copied (94.4%), and the natural case falls in the middle (81.7%). However, changing casing changes the BPE segmentation, and uppercase words tend to be split into more pieces: a mean of 4.4 segments, as compared to means of 3.1 (lowercase) and 2.9 (natural case). The number of subword segments correlates positively with copying rate (Fig.  2 ), but, controlling for that, we still find that NNP words that are completely capital-ized tend to be copied more than those with the same number of subword segments but only lowercased letters, suggesting that the system is encoding information about the connection between capitalization and copying. We also perform this experiment with PROPN words in the DE-EN direction, and find that increased capitalization increases copying, though we do not find there that an increase in the number of BPE segments increases copying. The true casing of the word consistently falls between these two extremes. The high copying rate of fully-capitalized words is intuitive: acronyms are often both uppercased and copied from source to target. That is not to say that the model always learns to copy acronyms; it also learns to translate them when appropriate (such as GDP to BIP). There is always an interplay between learned translations and features that may encourage copying. The connection between copying rate and capitalization provides one explanation for the gap in behavior of the two novel word types, and demonstrates that features of words influence copying. Note that it learns this behavior based on training data, without access to information at a finer granularity (character-level) than the subword units. 

 Conclusion We show that subword vocabulary neural machine translation systems learn about copying from context and the subwords themselves. The effect of context is strong enough to cause words that would otherwise be translated to be copied. Characteristics of subword tokens play a role in copying behavior, with capitalized tokens more likely to be copied. We leave as future work a deeper analysis of the level of character-awareness encoded in representations of the BPE segments as a byproduct of training. We provide an analysis of what happens when words are not copied, showing expected differences between novel words and words that were observed during training. Additionally, we provide more examples and evidence of the problem of substituting fluent but non-adequate translations for rare or unknown words. 
