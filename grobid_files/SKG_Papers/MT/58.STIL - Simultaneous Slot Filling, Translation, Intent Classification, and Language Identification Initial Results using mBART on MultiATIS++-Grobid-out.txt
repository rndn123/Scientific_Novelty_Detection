title
STIL -Simultaneous Slot Filling, Translation, Intent Classification, and Language Identification: Initial Results using mBART on MultiATIS++

abstract
Slot-filling, Translation, Intent classification, and Language identification, or STIL, is a newly-proposed task for multilingual Natural Language Understanding (NLU). By performing simultaneous slot filling and translation into a single output language (English in this case), some portion of downstream system components can be monolingual, reducing development and maintenance cost. Results are given using the multilingual BART model  (Liu et al., 2020)  fine-tuned on 7 languages using the MultiATIS++ dataset. When no translation is performed, mBART's performance is comparable to the current state of the art system (Cross-Lingual BERT by Xu et al. (  2020 )) for the languages tested, with better average intent classification accuracy (96.07% versus 95.50%) but worse average slot F1 (89.87% versus 90.81%). When simultaneous translation is performed, average intent classification accuracy degrades by only 1.7% relative and average slot F1 degrades by only 1.2% relative.

Introduction Multilingual Natural Language Understanding (NLU), also called cross-lingual NLU, is a technique by which an NLU-based system can scale to multiple languages. A single model is trained on more than one language, and it can accept input from more than one language during inference. In most recent high-performing systems, a model is first pre-trained using unlabeled data for all supported languages and then fine tuned for a specific task using a small set of labeled data  (Conneau and Lample, 2019; Pires et al., 2019) . Two typical tasks for goal-based systems, such as virtual assistants and chatbots, are intent classification and slot filling  (Gupta et al., 2006) . Though intent classification creates a language agnostic output (the intent of the user), slot filling does not. Instead, a slot-filling model outputs the labels for each of input tokens from the user. Suppose the slot-filling model can handle L languages. Downstream components must therefore handle all L languages for the full system to be multilingual across L languages. Machine translation could be performed before the slot filling model at system runtime, though the latency would be fully additive, and some amount of information useful to the slotfilling model may be lost. Similarly, translation could occur after the slot-filling model at runtime, but slot alignment between the source and target language is a non-trivial task  (Jain et al., 2019; Xu et al., 2020) . Instead, the goal of this work was to build a single model that can simultaneously translate the input, output slotted text in a single language (English), classify the intent, and classify the input language (See Table  1 ). The STIL task is defined such that the input language tag is not given to the model as input. Thus, language identification is necessary so that the system can communicate back to the user in the correct language. Table  2 : Two text-to-text STIL examples. In all STIL cases, the output is in English. Each token is followed by its BIO-tagged slot label. The sequence of tokens and slots are followed by the intent and then the language. sification, and Language identification (STIL); (2) both non-translated and STIL results using the mBART model  (Liu et al., 2020)  trained using a fully text-to-text data format; and (3) public release of source code used in this study, with a goal toward reproducibility and future work on the STIL task 1 . 

 Dataset The Airline Travel Information System (ATIS) dataset is a classic benchmark for goal-oriented NLU  (Price, 1990; Tur et al., 2010) . It contains utterances focused on airline travel, such as how much is the cheapest flight from Boston to New York tomorrow morning? The dataset is annotated with 17 intents, though the distribution is skewed, with 70% of intents being the flight intent. Slots are labeled using the Beginning Inside Outside (BIO) format. ATIS was localized to Turkish and Hindi in 2018, forming MultiATIS  (Upadhyay et al., 2018) , and then to Spanish, Portuguese, German, French, Chinese, and Japanese in 2020, forming Multi-ATIS++  (Xu et al., 2020) . In this work, Portuguese was excluded due to a lack of Portuguese pretraining in the publicly available mBART model, and Japanese was excluded due to a current lack of alignment between Japanese and English samples in MultiATIS++. Hindi and Turkish data were taken from Multi-ATIS, and the training data were upsampled by 3x for Hindi and 7x for Turkish. Prior to any upsampling, there were 4,488 training samples for English, Spanish, German, French, and Chinese. The test sets contained 893 samples for all languages except Turkish, which had 715 samples. For English, Spanish, German, French, and Chinese, validation sets of 490 samples were used in all cases. Given the smaller data quantities for Hindi and Turkish, two training and validation set configurations were considered. The first configuration matched that of  Xu et al. (2020) , using training sets of 1,495 for Hindi and 626 for Turkish along with validation sets of 160 for Hindi and 60 for Turkish. In the second configuration, no validation sets were made for Hindi and Turkish (though there were still validation sets for the other languages), and the training sets of 1,600 Hindi samples and 638 samples from MultiATIS were used. Two output formats are considered, being (1) the non-translated, traditional case, in which translation of slot content is not performed, and (2) the translated, STIL case, in which translation of slot content is performed. In both cases, the tokens, the labels, the intent, and the detected language are all output from the model as a single ordered text sequence, as shown in Table  2 . 

 Related Work Previous approaches for intent classification and slot filling have used either (1) separate models for slot filling, including support vector machines  (Moschitti et al., 2007) , conditional random fields  (Xu and Sarikaya, 2014) , and recurrent neural networks of various types  (Kurata et al., 2016)  or (2) joint models that diverge into separate decoders or layers for intent classification and slot filling  (Xu and Sarikaya, 2013; Guo et al., 2014; Liu and Lane, 2016; Hakkani-T?r et al., 2016)  or that share hidden states  (Wang et al., 2018) . In this work, a fully text-to-text approach similar to that of the T5 model was used, such that the model would have maximum information sharing across the four STIL sub-tasks. Encoder-decoder models, first introduced in 2014  (Sutskever et al., 2014) , are a mainstay of neural machine translation. The original transformer model included both an encoder and a decoder  (Vaswani et al., 2017) . Since then, much of the work on transformers focuses on models with only an encoder pretrained with autoencoding techniques (e.g. BERT by  Devlin et al. (2018) ) or auto-regressive models with only a decoder (e.g. GPT by  Radford (2018) ). In this work, it was assumed that encoder-decoder models, such as BART  (Lewis et al., 2019)  and T5  (Raffel et al., 2019) , are the best architectural candidates given the translation component of the STIL task, as well as past state of the art advancement by encoder-decoder models on ATIS, cited above. Rigorous architectural comparisons are left to future work. 

 The Model 

 The Pretrained mBART Model The multilingual BART (mBART) model architecture was used  (Liu et al., 2020) , as well as the pretrained mBART.cc25 model described in the same paper. The model consists of 12 encoder layers, 12 decoder layers, a hidden layer size of 1,024, and 16 attention heads, yielding a parameter count of 680M. The mBART.cc25 model was trained on 25 languages for 500k steps using a 1.4 TB corpus of scraped website data taken from Common Crawl  (Wenzek et al., 2019) . The model was trained to reconstruct masked tokens and to rearrange scrambled sentences. SentencePiece tokenization  (Kudo and Richardson, 2018)  was used for mBART.cc25 with a sub-word vocabulary size of 250k. 

 This Work The same vocabulary as that of the pretrained model was used for this work, and SentencePiece tokenization was performed on the full sequence, including the slot tags, intent tags, and language tags. For all mBART experiments and datasets, data from all languages were shuffled together. The fairseq library was used for all experimentation  (Ott et al., 2019) . Training was performed on 8 Nvidia V100 GPUs (16 GB) using a batch size of 32, layer normalization for both the encoder and the decoder  (Xu et al., 2019) ; label smoothed cross entropy with = 0.2  (Szegedy et al., 2016) ; the ADAM optimizer with ? 1 = 0.9 and ? 2 = 0.999 (Kingma and Ba, 2014); an initial learning rate of 3 ? 10 ?5 with polynomial decay over 20,000 updates after 1 epoch of warmup; attention dropout of 0.1 and dropout of 0.2 elsewhere; and FP16 type for weights. Each model was trained for 19 epochs, which took 5-6 hours. 

 Results and Discussion Results from the models are given in Table  3 . Statistical significance was evaluated using the Wilson method  (Wilson, 1927)  with 95% confidence.  Xu et al. (2020)  Examining the first training configuration (1,496 samples for Hindi and 626 for Turkish), the nontranslated mBART's macro-averaged intent classification (96.07%) outperforms Cross-Lingual BERT by  Xu et al. (2020)  (95.50%), but slot F1 is worse (89.87% for non-translated mBART and 90.81% for Cross-Lingual BERT). The differences are statistically significant in both cases. 

 Comparing to 

 With and Without Translation When translation is performed (the STIL task), intent classification accuracy degrades by 1.7% relative from 96.07% to 94.40%, and slot F1 degrades by 1.2% relative from 89.87% to 88.79%. The greatest degradation occurred for utterances involving flight number, airfare, and airport name (in that order). 

 Additional Hindi and Turkish Training Data Adding 105 more Hindi and 12 more Turkish training examples results in improved performance for the translated, STIL mBART model. Macro-averaged intent classification improves from 94.40% to 95.94%, and slot F1 improves from 88.79% to 90.10%, both of which are statistically significant. By adding these 117 samples, the STIL mBART model matches the performance (within confidence intervals) of the non-translated mBART model. This finding suggests that the STIL models may require more training data than traditional, non-translated slot filling models. Additionally, by adding more Hindi and Turkish data, both the intent accuracy and the slot filling F1 improves for every individual language of the translated, STIL models, suggesting that some portion of the internal, learned representation is language agnostic. Finally, the results suggest that there is a trainingsize-dependent performance advantage in using a single output language, as contrasted with the nontranslated mBART model, for which the intent classification accuracy and slot F1 does not improve (with statistical significance) when using the additional Hindi and Turkish training samples. 

 Language Identification Language identification F1 is above 99.7% for all languages, with perfect performance in many cases. Seq2Seq-Ptr  (Rongali et al., 2020)  97.42 Stack Propagation  (Qin et al., 2019)  97.5 Joint BERT + CRF  (Chen et al., 2019)  97.9 Non  Perfect performance on Chinese and Hindi is unsurprising given their unique scripts versus the other languages tested. 

 Conclusion This preliminary work demonstrates that a single NLU model can perform simultaneous slot filling, translation, intent classification, and language identification across 7 languages using MultiATIS++. Such an NLU model would negate the need for multiple-language support in some portion of downstream system components. Performance is not irreconcilably worse than traditional slot-filling models, and performance is statistically equivalent with a small amount of additional training data. Looking forward, a more challenging dataset is needed to further develop the translation compo-nent of the STIL task. The English MultiATIS++ test set only contains 455 unique entity-slot pairs. An ideal future dataset would include freeform and varied content, such as text messages, song titles, or open-domain questions. Until then, work remains to achieve parity with English-only ATIS models. Table 1 : 1 Input ? intent: flight Traditional slots: (?, fromloc.cityname), Output . . . (?, toloc.cityname), . . . (?, toloc.statename) intent: flight STIL Output slots: (salt lake city, fromloc.cityname), . . . (oakland, toloc.cityname), . . . (california, toloc.statename) lang: zh Today's slot filling systems do not translate the slot content, as shown in "Traditional Ouput." With a STIL model, the slot content is translated and language identification is performed. 
