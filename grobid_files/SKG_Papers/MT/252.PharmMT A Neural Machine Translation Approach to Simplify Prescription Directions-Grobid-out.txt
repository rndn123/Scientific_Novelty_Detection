title
PharmMT: A Neural Machine Translation Approach to Simplify Prescription Directions

abstract
The language used by physicians and health professionals in prescription directions includes medical jargon and implicit directives and causes much confusion among patients. Human intervention to simplify the language at the pharmacies may introduce additional errors that can lead to potentially severe health outcomes. We propose a novel machine translation-based approach, PharmMT, to automatically and reliably simplify prescription directions into patient-friendly language, thereby significantly reducing pharmacist workload. We evaluate the proposed approach over a dataset consisting of over 530K prescriptions obtained from a large mail-order pharmacy. The end-to-end system achieves a BLEU score of 60.27 against the reference directions generated by pharmacists, a 39.6% relative improvement over the rule-based normalization. Pharmacists judged 94.3% of the simplified directions as usable as-is or with minimal changes. This work demonstrates the feasibility of a machine translation-based tool for simplifying prescription directions in real-life.

Introduction Adverse drug events stemming from medication errors are a vital cause of concern in patient care and are estimated to cost US$42 billion annually or roughly 1% of total global expenditure. In the US alone, medication errors cause one death every day and are responsible for over 700,000 visits to the emergency department and over 100,000 hospitalizations each year  (Budnitz et al., 2006 (Budnitz et al., , 2011 WHO, 2017) . One of the frequent sources of medication errors in the US is the directions on the 1.91 billion electronic prescriptions (e-prescriptions) transmitted annually  (Moniz et al., 2011; Odukoya et al., 2014 Odukoya et al., , 2015 . The style and language used in eprescriptions are highly variable and often filled with medical jargon. For example, in a recent study  (Yang et al., 2018) , the authors noted that the direction "Take 1 tablet by mouth once daily" was represented in 832 different ways. The study also found that 10.1% of e-prescriptions contained incorrect or confusing language. Pharmacists play a vital role as intermediaries between physicians and patients by translating the rich medical jargon in the e-prescriptions written by physicians to patient-comprehensible directions on the prescription labels printed on pill bottles. However, human translation is time-consuming and subject to errors, potentially leading to medication errors and other patient safety risks due to prescription ambiguity. In this paper, we propose a machine translationbased system, called PharmMT, to simplify the e-prescription directions authored by physicians into patient-friendly language. The system aims to automate the translation and normalization of e-prescription directions and reduce the pharmacists' overall workload. We investigate multiple neural network-based models, including transformer-based models and bi-directional LSTM models, rule-based approaches, and a hybrid model combining neural network-based models with a rule-based backoff. We train and evaluate the proposed system over a dataset of over 530K paired e-prescriptions and their humantranslated text, obtained from a large mail-order pharmacy. Using automated measures to evaluate machine translation output, we compare the PharmMT system against a rule-based approach developed based on domain knowledge from pharmacists. Our results show that PharmMT performs significantly better than the rule-based baseline. Manual evaluation by pharmacists also shows a high potential to directly apply the proposed approach in pharmacies to translate e-prescription directions. The contributions of this work are: 1. We develop a neural machine translation model for simplifying e-prescriptions and build an end-to-end system to generate normalized, patient-friendly, and usable translations. The model achieves a BLEU score of 60.27 against the reference directions generated by pharmacists, and 94.3% of simplified prescriptions are judged as usable as-is or with minimal changes by pharmacists. 2. To the best of our knowledge, our work is the first systematic effort to study neural network models to simplify e-prescription directions. We also developed a rule-based approach as the baseline of this task. 3. Our work adds additional insights into the limitations of purely automated evaluation metrics of machine translation for domain-adaptive tasks, and offers alternative modes of evaluation. 

 Related work Prior work on automated approaches for translating e-prescription directions mainly focused on information extraction models relied on handwritten rules or linguistic signals found in prescription free text. Tools such as MetaMap (Aronson and Lang, 2010) and MedLEE  (Friedman et al., 1996)  extract and organize clinical information in text documents using external knowledge sources, such as the Unified Medical Language System (UMLS). Other systems, such as FABLE  (Tao et al., 2018) , employed a conditional random fields-based model to recognize medication entities. Other researchers have proposed rule-based approaches to normalize and simplify directions using task-specific knowledge such as common abbreviations used in prescriptions  (Qenam et al., 2017; Kandula et al., 2010) . While machine translation-based approaches have not yet been proposed for translating eprescription directions, prior works such as  (Yolchuyeva et al., 2018; Shardlow and Nawaz, 2019; Van den Bercken et al., 2019)  have suggested solving machine translation tasks without the need for explicitly-defined rules. Neural machine translation (NMT) models have been shown to be able to learn contextual rules automatically from large corpora and produce higher quality translations  (Bahdanau et al., 2014; Wu et al., 2016b; Lee et al., 2017) . Other researchers, such as  (Aw et al., 2006; Xu et al., 2016) , have shown that while statistical machine translation methods mainly focused on lexical rules to minimize sentence complexity, NMT models could capture richer syntactic information  (Shi et al., 2016) . Researchers studying deep neural network models have explored multiple encoder-decoder frameworks, such as Transformer-based networks  (Vaswani et al., 2017) , and Recurrent Neural Networks (RNN), including Long Short-Term Memory (LSTM) models  (Hochreiter and Schmidhuber, 1997)  and Gated Recurrent Units (GRU)  (Chung et al., 2014) . RNN units have been used to encode source sentences into fixed-length representations and then decoded into reference sentences . Models with deep LSTM-based RNN units have shown the benefits of using deeper structure  (Wu et al., 2016a) . In other works,  (Gehring et al., 2017)  introduced a convolution neural network with an attention-based mechanism to learn long-range dependency. In recent work,  (Vaswani et al., 2017)  developed a novel Transformer-based architecture using attention mechanism without recurrence or convolution, resulting in a state-of-the-art performance for many natural language processing tasks, such as recognizing textual entailment, sentiment analysis, and natural language inference.  (Raffel et al., 2019; Lan et al., 2019; Devlin et al., 2018)  3 Simplifying e-prescription directions We frame the challenge of simplifying eprescription directions as a machine translation task from physician-authored directions ("source") to patient-facing text authored by pharmacists ("reference"). This monolingual translation task focuses on replacing highly-abbreviated medical jargon with patient-friendly vocabulary, simplifying cryptic expressions, and normalizing them so that they can be used with minimal changes by the pharmacists. Table  1  (top panel) shows three examples of e-prescriptions and their corresponding simplified directions. E-prescription directions consists of specific components related to the prescribed drug, viz., dosage, form, route, duration, frequency, and reason for prescribed use. For example, the eprescription "2 puffs orally q 4 hrs x90 dys wheeze" specifies that the patient should inhale 2 (dosage) puffs (form) by mouth (route) every 4 hours (frequency) for 90 days (duration) for wheezing (reason). While not all components are present in every e-prescription direction, some components are critical and need to be stated explicitly. The name and 

 E-prescription direction Simplified direction 2 puffs orally q 4 hrs x90 dys wheeze Inhale 2 puffs by mouth every 4 hours for 90 days for wheeze 1 g vaginal mon/tu/th/fr Insert 1 gram vaginally monday, tuesday, thursday and friday as needed prn; 1 po qd prn Take 1 tablet by mouth once a day as needed oral one tab po qd prn Take 1 tablet by mouth every day as needed Take 1 tablet by mouth daily as needed Drug name and strength Normalized drug name and strength albuterol 90 mcg/inh inhalation aerosol PROAIR HFA AER 0.1 mg/g vaginal cream ESTRADIOL CRE 0.01% traMADol 50 mg tablet TRAMADOL HCL TAB 50MG  

 Neural Machine Translation Numerical Checker 

 Normalization Correct Wrong Graceful Back-off Simplified direction strength of the prescribed drug are also available as auxiliary information. Examples of drug names and strengths are shown in the bottom panel of Table  1 . 

 E-prescription direction While we formulate the challenge as a machine translation task in the pharmacy domain, key desiderata for the automated approach are to preserve the accuracy and consistency of the critical components in a prescription. To achieve this, we develop an end-to-end system called PharmMT, consisting of three stages: neural machine translation, numerical check and graceful backoff, and normalization, as depicted in Figure  1 . 

 Neural Machine Translation (NMT) The primary component of the proposed approach is a sequential model that "translates" physicianauthored e-prescription text to normalized, patientfriendly language using an NMT framework. NMT models map a source sequence, x : x 1 , x 2 , . . . , x n into a reference sequence, y : y 1 , y 2 , . . . , y m by maximizing the conditional probability p(y|x) using an Encoder-Decoder framework  (Neubig, 2017) . One such model is a recurrent sequenceto-sequence model, which consists of a bidirectional LSTM model  (Schuster and Paliwal, 1997)  with global attention as the encoder and a forwardsequence LSTM model  (Hochreiter and Schmidhuber, 1997)  as the decoder. Both encoder and decoder stages are configured as multi-layer models, with a hidden state in each layer, to sufficiently capture the deep semantic components in the eprescription  (Barone et al., 2017) . To compare against the performance of the recurrent sequence-to-sequence model, we also trained an attention-based transformer model  (Vaswani et al., 2017) . Position embedding was enabled to capture sequence information and provide similar architectural complexity as a recurrent network. Both models were developed using the Open-NMT framework  (Klein et al., 2017 (Klein et al., , 2018 , and the dropout probability was adjusted to prevent over-fitting  (Srivastava et al., 2014) . Additional experimental details can be found in Section 4.2. 

 Augmenting auxiliary information As described in Section 3, e-prescriptions contain auxiliary information on the drug name and strength. While the primary task is to simplify just the direction, access to the auxiliary information may help distinguish directions based on the context associated with drugs. We hypothesize that the auxiliary information will improve the neural machine translation models to simplify directions. This hypothesis also matches with real-life information available to pharmacists. To test this hypothesis, we prepend the drug name and strength information to the "source" direction before training the models. We evaluate the updated model on the original task of simplifying just the directions. 

 Pre-trained word embeddings The input representation is a pre-trained word embedding layer to allow for similar representations of words in similar contexts. Word embeddings can capture fine-grained semantic and syntactic word relationships and, in turn, allow for a better initialization for gradient optimization. We explored static pre-trained embedding models and compared them against a randomly-initialized representation vector. The first one was the general-domain GloVe word embeddings, pre-trained on the Wikipedia and Gigaword corpora  (Pennington et al., 2014) . The second one was clinical domain-adaptive word embeddings that we trained on MIMIC-III, a large corpus of clinical notes  (Johnson et al., 2016)  and a dataset of pharmacy directions  (Zheng et al., 2020) . We hypothesize that domain-adaptive word embeddings would outperform both the general-domain embeddings and randomly-initialized vector embeddings. 

 Learning ensemble models The primary motivation of ensemble learning over neural network models is to improve the final model's robustness to the variations introduced in parameterized modules because of dropout probability and random seeding. In an ensemble model, the final distribution of the output dictionary is computed by averaging the output distributions from the trained models in the ensemble during the inference phase. 

 Numerical check Once the machine translation module generates the simplified candidate directions, the candidates are checked for consistency of key components of the prescription. Numerical components -including dosage, frequency, and duration -are critical in prescriptions. Medication under-dosage often leads to poorer health outcomes, while over-dosage can be severe, even fatal. The correctness of the numerical components in the simplified directions is checked by comparing against the source e-prescription. We incorporated two different numerical checking strategies -Token-based and NER-based. In the token-based checking, all numeric tokens that appear in the simplified direction were checked against numeric 

 Fields Original Normalized  tokens in the source direction. The bag of tokens approach helps tag any simplified direction that "makes up" numeric values in a key component. On the other hand, the token-based checker can also generate faulty consistency claims, for example, when the simplified direction swaps a dosage term with the frequency. To overcome this, we incorporated a pre-trained medication NER model  (Zhao and Vydiswaran, 2020)  to tag dosage, frequency, and duration components in both source and simplified directions, and compared them component-by-component. The NER model was trained over a medication extraction task  (Henry et al., 2020)  and achieved an overall F1 score of 0.9571 over all medication components. 

 Graceful backoff If the simplified direction is deemed consistent after the numeric check, the direction is considered as the final candidate for normalization. However, if the numeric check fails, the NMT output is discarded and the original source direction is used as the final candidate. This graceful backoff represents a trade-off between information accuracy and good language model performance. 

 Normalization Before the candidate direction from the numerical check phase is finalized, the candidate text undergoes pharmacy-specific post-processing and simplification. Two pharmacists identified common linguistic patterns in pharmacy directions, which were coded into normalization rules. Highly-abbreviated  medical jargon was replaced, for example, by replacing the Latin term bid with its synonymous phrase twice a day. Action verbs appropriate for the form of the drug, such as inject (syringe), inhale (nebulizer), and take (capsule), were added. Numerical values in words or fractions were converted to digits (e.g. 1 1/2 was converted to 1.5). Abbreviations and other common medical expressions were normalized into standard and patient-friendly variants, e.g. inj or injector to injection. Overall, the normalization step included more than 300 rules. Table  2  shows examples of these normalization and simplification rules. The normalization module also served as the rule-based baseline. 4 Experimental setup 

 Data set description The e-prescription corpus used in this study consists of all e-prescriptions dispensed by an online outpatient mail-order pharmacy from their dispensing software from January 2017 to October 2018. The corpus consists of 530,988 e-prescriptions received from 65,139 unique physicians from all fifty US states  (Zheng et al., 2020) . Each e-prescription direction in the data set is paired with the corresponding simplified text authored by a mail-order pharmacy team member. Table  1  shows some example e-prescription directions and the corresponding simplified text. In addition to the e-prescription, each direction in the corpus also contains auxiliary information about the name and strength of the drug. However, similar to the directions, physician-authored information often included chemical or ingredient names for the drug, while the pharmacist-translated direction contained generic drug names or brand names. In all, there are 120,402 unique e-prescription directions and 83,823 unique pharmacist-authored directions in the dataset. The difference in these numbers is due to the diverse writing styles of physicians and pharmacists. On an average, there were 6.33 e-prescription directions mapped to a single pharmacist-authored direction; while one eprescription direction mapped, on an average, to 4.41 different pharmacist-authored directions. We split our data into train, validation, and test sets. To avoid information leak during the evaluation, we remove all duplicates appearing in more than one set, but retain those appearing within a single set. Table  3  summarizes the distribution of the instances over the three sets. None of the instances in the validation or test sets were used during the training phase. 

 Training process To prepare the data for training, the source eprescription directions and reference pharmacistauthored directions are prepended with the drug name and strength, as described in Section 3.1.1. Pre-trained word embeddings: We tested two static pre-trained word embeddings -generaldomain GloVe embeddings and a second one trained explicitly over two clinical domain corpora -against a randomly-initialized representation. The out-of-vocabulary rate is shown in Table  4 . While only 10% of the source words and 6.69% of the target words had no word embeddings in the clinicaldomain word embeddings, the out-of-vocabulary ratio was 7 to 9 times higher in the general-domain word embeddings. 

 Model configuration: The number of layers in the encoder and decoder stages of the Bi-LSTM, LSTM-based, and Transformer-based models was empirically chosen from the set {2, 4, 6, 8}. The length of hidden states was chosen from the set {128, 256, 512}. In the following description, we denote the number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A, consistent with the BERT notation  (Devlin et al., 2018) . After choosing the hyper-parameter based on highest BLEU score, we primarily report results on two best performance architectures: Bi-LSTM/LSTMbased model (L = 4, H = 256, Dropout = 0.4) and Transformed-based model (L = 4, H = 128, A = 2, Dropout = 0.2). We trained our settled models  

 Evaluation metrics Automatic evaluation: We evaluated the translation model using two automated candidatereference comparison metrics: BLEU  (Papineni et al., 2002)  and METEOR  (Denkowski and Lavie, 2014) . The BLEU-4 score is the most popular metric used to evaluate the similarity between the candidate text and human reference in machine translation tasks  Koehn et al., 2003; Lipton et al., 2015) . It is computed as the geometric mean of precision of unigram, bigram, trigram, and 4-gram matches between the candidate and reference texts. In contrast to the ngram-based overlap in BLEU-4, the METEOR score considers unigram alignment between candidate and reference texts. This results in more flexible matching, including stem match and synonym match using WordNet  (Miller, 1995) . METEOR scores are known to achieve a better correlation with human judgment  (Banerjee and Lavie, 2005) . Sample comparisons of two metrics in Table 5 (top panel) show the limitation of using the BLEU score to compare pharmacy instructions, while also showing the feasibility of using METEOR score as a viable alternative. The bottom panel of Table  5  highlights the limitation of both metrics in checking the consistency of prescription components, and is discussed in more detail in Section 6.4. Manual evaluation: While automated metrics such as BLEU and METEOR are commonly used to evaluate machine translation tasks, they do not sufficiently evaluate the clinical usability of the candidate texts. Hence, in addition to the automated evaluation, we asked two pharmacist trainees to evaluate 300 pairs of e-prescription directions and corresponding simplified directions randomly sampled from the test set. The pharmacist trainees were asked to classify the direction pairs into one of three categories -Correct: all information in the simplified direction was correct; Missing: the simplified direction was correct, but missed some essential information; and Wrong: the simplified direction contained fundamental errors that needed to be corrected. A pharmacist expert resolved labeling disagreements. This manual evaluation simulates the human effort undertaken in real-life at the pharmacies to simplify e-prescription directions. Use spray 1 spray 4 times a day in the nose route as needed for 90 days. Use 1 spray in the nose 4 times a day as needed . 3 Re-ordering components tablets by mouth daily; 3.5 tab 7 mg. Take tablets by mouth daily; 3.5 tablet 7 mg. Take 3.5 tablets by mouth daily. 4 Handling misspelling one tablet by mouth oce daily. Take one tablet by mouth oce daily. Take 1 tablet by mouth once a day. 5 Informal abbreviations 1 puff aero pow br act bid. Inhale 1 puff aero pow br act twice a day. Inhale 1 puff by mouth twice a day. Table  7 : Examples comparing PharmMT model against a rule-based baseline, highlighting potential issues with rule-based approaches. 

 Results We present our results first by evaluating the NMT module by comparing the two proposed architectures using the automated BLEU and METEOR scores. After finalizing the best performing NMT model, we compare its results against a rule-based baseline and demonstrate the significance of the individual stages through an ablation study. Finally, we report the performance of the end-to-end system based on the manual evaluation. 

 Evaluating Neural Machine Translation module We compared two classes of NMT models -Transformer-based model and BiLSTM/LSTMbased model under different pre-trained word embeddings. The results are summarized in Table  6 . The reported values are mean and standard deviation over ten independent iterations of training and validation using the same model hyper-parameters. Both automated metrics were consistent in their ranking of the systems. On both metrics, LSTM-based models outperformed transformerbased models. One possible explanation for these results is that although transformer-based models are better at capturing long-range dependencies, their advantage is nullified by the relatively short sentences in this task. The average length of eprescription directions is 10.42?4.55 tokens. Models using the pre-trained clinical-domain word embeddings led to the highest performance on both metrics and were statistically better than models that used general-domain word embeddings. Models using the randomly-initiated word representation performed the worst. The model performance improved further when ensemble learning was applied. The ensemble BiLSTM / LSTM model with clinical domain-adaptive word embeddings achieved the highest overall BLEU score of 66.61?0.29 and the METEOR score of 82.73?0.10. We also note that in Section 3.1.2, we stated our hypothesis that domain-adaptive word embeddings would outperform both the general-domain embeddings and randomly-initialized vector representations. This hypothesis was shown to be valid in our results in Table  6 . Instead of the static, but domain-adaptive, word embeddings explored in this work, other alternatives such as contextual word embeddings could also be used, including BioBERT  and Clinical-BERT  (Huang et al., 2019) . 

 Comparison to rule-based baseline Next, we compared the translated directions generated by the PharmMT model against a rule-based baseline in which the e-prescriptions are passed directly through the Normalization module to produce the outputs. Table  7  shows some examples of rule-based translation against PharmMT output. These examples highlight three potential issues of rule-based systems, viz., handling ambiguity, reordering of direction components, and sensitivity to misspelled tokens and abbreviations. In the first example, the rule-based approach fails to recognize '90' as duration without any contextual clues, whereas PharmMT correctly normalizes it as 'for 90 days'. Similarly, in the second example, the rule-based approach fails to identify 'spray' as both an action verb and the form token. This highlights the difficulty in manually curating rules to cover all ambiguous cases. Second, while rule-based approaches are very effective when the order of prescription components is as expected, they do not handle reordered components well. The third example in Table  7  shows one such instance, where unlike the rule-based approach, the PharmMT model correctly reorders the direction components by inserting dosage tokens ('3.5 tablets') before the form token, 'tablet'. Finally, rule-based approaches are also more sensitive to misspelled tokens and informal abbreviations, compared to PharmMT, as shown in the final two examples in Table  7 . 

 Results of the ablation study The best performing NMT model achieved a BLEU score of 67.21 and a METEOR score of 82.90. After finalizing the best NMT model, the significance of the remaining components is shown using an ablation study. The results are summarized in Table 8. Removing auxiliary information: Without augmenting auxiliary drug information, the performance of the NMT model drops by 5.4% on the BLEU score and 2.5% on the METEOR score. These results indicate that augmenting directions with auxiliary drug information helps improve the overall performance, as hypothesized in Section 3.1.1. Graceful backoff and normalization: Adding the NER-based numeric check and resorting to graceful backoff, when necessary, reduces the overall scores on the automated metrics (BLEU: 66.24, METEOR: 79.59). Adding normalization decreases both metrics even further  (BLEU: 60.27, METEOR: 76.11 ). This performance drop is because the normalization-based approaches tend to produce reference direction texts influenced heavily by preference rules from pharmacists. So, while the resultant directions are more readable, patientfriendly, and preferred by pharmacists, they do not accurately reflect the preferred style in the original reference corpus. We expand on this further in Section 6.3.   

 Manual evaluation of end-to-end system The final output of the end-to-end system was evaluated by domain experts. Of the 300 pairs of eprescription directions and their corresponding simplified texts, 86.7% (n=260) were labeled as Correct, 7.6% (n=23) as Missing; and 5.7% (n=17) as Wrong. The missing errors were primarily related to missing adjectives and adverbs (e.g., transdermal, slowly), or typographic omissions, such as brackets. The incorrect errors were primarily related to special directions (e.g. taking medications before meals, with food), formatting issues with dosage (e.g. 10-12), or complex directions based on days of the week (e.g. every day except Sundays). These results show that in 94.3% instances, the simplified output can be used as-is or after minimal changes to add the missing elements. 

 Discussion 

 Error analysis We further analyzed all non-'Correct' instances (n=17; 5.7%) identified during the manual evaluation. A major class of errors was complicated instruction and language patterns in the eprescription. On average, these directions were 16.86 words long, compared to an average of 12.57 words for 'Correct' instances. For example, one direction that was not simplified correctly was: 30 units with meals plus ssi 150-200 2 units, 201-250 4 units, 251-300 6 units, 301-350 8 units, greater than 351 10 units. This direction instructed patients to change dosage depending on the sliding scale for insulin (ssi). Based on the hypothesis that shorter directions will have simpler language patterns, we evaluated a subset of test instances (n=11,977; 32.6%) that were under 12 words long. This 'shorter length' subset achieved an aggregate BLEU score of 71.14, while the complementary 'longer length' subset managed an aggregate BLEU score of 64.02.  

 Numeric checker and Graceful backoff We further investigated the performance of the numeric checker. The number of instances marked as inconsistent by the two approaches is summarized in Table  9 . The stricter, NER-based numeric checker flagged 4,027 (17.33%) instances as inconsistent, while the token-based checker flagged only 1,390 (5.98%) of instances as inconsistent. 

 Need for normalized reference The normalization process is heavily influenced by the style preferred by pharmacists coding the normalization rules. Since the preferred style of the team that generated the original reference differed from the expert pharmacists in our team, the original reference data were themselves not normalized. This led to a reduction in BLEU scores when normalization was added (see Table  8 ). To understand how well our trained models could perform on this corpus, we created a normalized version of the reference corpus. Using this as the gold reference, the original reference corpus has a BLEU score of 82.48, and that of the PharmMT system was 62.68 (see Table  10 ). The table also shows the ratio of test instances that are normalized to indicate how close the output is to the normalization rules: the lower the ratio, the closer it is. The results indicate that the NMT model learned more latent rules from the train data set than the hand-crafted normalization rules, while having a higher BLEU score. 

 Limitation of BLEU and METEOR Automated metrics such as BLEU and METEOR can only evaluate the translation results using a linguistic, token-level approach, but fail to capture the nuanced semantic-level information. However, in prescription directions, different words contain unequal useful information, and hence should be re-weighted during the evaluation process. As we noted in Section 3.2, consistency of key information is vital for patient safety. For example, in the translation shown in bottom of Table  5 , both ma-chine translation outputs NMT 1 and NMT 2 have only one token different from the reference. But, NMT 1 is labeled as 'Correct' in the manual evaluation while NMT 2 is labeled as 'Wrong' because of a serious error on dosage. However, both translations got similar BLEU and METEOR scores. In the future, we will focus on improving information consistency while maintaining high model performance. 

 Conclusion We proposed and developed a machine translationbased approach, called PharmMT, to simplify eprescription directions. We systematically evaluated the individual stages and the overall approach over a large mail-order pharmacy data corpus. Our results showed that an ensemble model with a bidirectional LSTM encoder and an LSTM decoder, trained over a clinical-domain word embedding representations, achieved the best overall BLEU score of 60.27. NER-based numeric check and graceful backoff ensure information consistency and the normalization stage helps generate patient-friendly directions. Qualitative evaluation by domain experts showed that 94.3% of the simplified directions could be used as-is or with minimal changes. These results indicate that the proposed approach could be deployed in practice to automate the simplification of prescription directions. Figure 1 : 1 Figure 1: Schematic diagram of the PharmMT system 
