title


abstract


Introduction The EMNLP 2011 Workshop on Statistical Machine Translation (WMT-2011) took place on Saturday and Sunday, July 30-31 in Edinburgh, Scotland, immediately following the Conference on Empirical Methods on Natural Language Processing (EMNLP) 2011, which was hosted by the University of Edinburgh. WMT 5-year Retrospective Best Paper Award Since this is the Sixth Workshop on Statistical Machine Translation, we have decided to create a WMT 5-year Retrospective Best Paper Award, to be given to the best paper that was published at the first Workshop on Statistical Machine Translation, which was held at HLT-NAACL 2006 in New York. The goals of this retrospective award are to recognize high-quality work that has stood the test of time, and to highlight the excellent work that appears at WMT. The WMT11 program committee voted on the best paper from a list of six nominated papers. Five of these were nominated by high citation counts, which we defined as having 10 or more citations in the ACL anthology network (excluding self-citations), and more than 30 citations on Google Scholar. We also opened the nomination process to the committee, which yielded one further nomination for a paper that did not reach the citation threshold but was deemed to be excellent. This short paper described Zollmann and Venugopal's entry into the WMT06 shared translation task. Their system introduced a parsing-based machine translation system. Like David Chiang's Hiero system, Zollmann and Venugopal's system used synchronous context free grammars (SCFGs). Instead of using a single non-terminal symbol, X, Zollmann and Venugopal's SCFG rules contained linguistically informed non-terminal symbols that were extracted from a parsed parallel corpus. This paper was one of the first publications to demonstrate that syntactically-informed approaches to statistical machine translation could achieve translation quality that was comparable to -or even better than -state-of-the-art phrase-based and and hierarchical phrase-based approaches to machine translation. Zollmann and Venugopal's approach has influenced a number of researchers, and has been integrated into open source translation software like the Joshua and Moses decoders. In many ways this paper represents the ideals of the WMT workshops. It introduced a novel approach to machine translation and demonstrated its value empirically by comparing it to other state-of-the-art systems on a public data set. 

 Congratulations to Andreas Zollmann and Ashish Venugopal for their excellent work! 

 Organizers: Chris Callison-Burch (Johns Hopkins University) Philipp Koehn (University of Edinburgh) Christof Monz (University of Amsterdam) Omar F. Zaidan (Johns Hopkins University)  The program committee decided to award the WMT 5-year Retrospective Best Paper Award to: Andreas Zollmann and Ashish Venugopal. 2006. Syntax Augmented Machine Translation via Chart Parsing. In Proceedings of the Workshop on Statistical Machine Translation. Pages 138-141. 

 Table of Contents of A Grain of Salt for the WMT Manual Evaluation Ond?ej Bojar, Milo? Ercegov?evi?, Martin Popel and Omar Zaidan . . . . . . . . . . . . . . . . . . . . . . . . . . 1 A Lightweight Evaluation Framework for Machine Translation Reordering David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Jason Katz-Brown, Masakazu Seno and Franz Och . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 Findings of the 2011 Workshop on Statistical Machine Translation Chris Callison-Burch, Philipp Koehn, Christof Monz and Omar Zaidan . . . . . . . . . . . . . . . . . . . . . 22 Evaluate with Confidence Estimation: Machine ranking of translation outputs using grammatical features Eleftherios Avramidis, Maja Popovi?, David Vilar and Aljoscha Burchardt . . . . . . . . . . . . . . . . . . 65 AMBER: A Modified BLEU, Enhanced Ranking Metric Boxing Chen and Roland Kuhn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 TESLA at WMT 2011: Translation Evaluation and Tunable Metric Daniel Dahlmeier, Chang Liu and Hwee Tou Ng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems Michael Denkowski and Alon Lavie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 Approximating a Deep-Syntactic Metric for MT Evaluation and Tuning Matou? Mach?ek and Ond?ej Bojar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 Evaluation without references: IBM1 scores as evaluation metrics Maja Popovi?, David Vilar, Eleftherios Avramidis and Aljoscha Burchardt . . . . . . . . . . . . . . . . . . 99 Morphemes and POS tags for n-gram based evaluation metrics Maja Popovi? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 E-rating Machine Translation Kristen Parton, Joel Tetreault, Nitin Madnani and Martin Chodorow . . . . . . . . . . . . . . . . . . . . . . . 108 TINE: A Metric to Assess MT Adequacy Miguel Rios, Wilker Aziz and Lucia Specia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 Regression and Ranking based Optimisation for Sentence Level MT Evaluation Xingyi Song and Trevor Cohn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 MAISE: A Flexible, Configurable, Extensible Open Source Package for Mass AI System Evaluation Omar Zaidan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
