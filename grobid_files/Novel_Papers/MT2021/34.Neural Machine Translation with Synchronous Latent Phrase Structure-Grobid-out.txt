title
Neural Machine Translation with Synchronous Latent Phrase Structure

abstract
It is reported that grammatical information is useful for machine translation (MT) task. However, the annotation of grammatical information requires the highly human resources. Furthermore, it is not trivial to adapt grammatical information to MT since grammatical annotation usually adapts tokenization standards which might not be suitable to capture the relation of two languages, and the use of subword tokenization, e.g., Byte-Pair-Encoding, to alleviate out-of-vocabulary problem might not be compatible with those annotations. In this work, we propose two methods to explicitly incorporate grammatical information without supervising annotation; first, latent phrase structure is induced in an unsupervised fashion from a multi-head attention mechanism; second, the induced phrase structures in encoder and decoder are synchronized so that they are compatible with each other using constraints during training. We demonstrate that our approach produces better performance and explainability in two tasks, translation and alignment tasks without extra resources. Although we could not obtain the high quality phrase structure in constituency parsing when evaluated monolingually, we find that the induced phrase structures enhance the explainability of translation through the synchronization constraint.

Introduction Although machine translation (MT) has achieved improved performance using neural machine translation (NMT), the translation qualities for distant languages are still poor  (Johnson et al., 2017) . As a way to tackle the problem, statistical MT (SMT) incorporates synchronous grammar to achieve more linguistically accurate translations, in which complex structural relations between source and target languages are expressed using phrase structure  (Wong et al., 2005) . The synchronous grammar expresses the complex relationships between source and target languages and incorporates phrase structure to enable more linguistically accurate translation. A similar idea could be employed for NMT to achieve improved performance on those distant language pairs. However, grammatical information annotation demands high human resources. In addition, such grammatical annotation is done on word-level granularities, which might not be the best tokenization for MT tasks due by language mismatch or out-of-vocabulary problem, and often sub-word tokenization, e.g., Byte-Pair-Encoding (BPE)  (Sennrich et al., 2016) , is employed to alleviate the problem. As a result, it is difficult to incorporate grammatical information into NMT that handle multiple languages simultaneously. Recently, there have been researches on unsupervised learning of phrase structure without relying on human annotations. Although these phrase structures learned in an unsupervised fashion are very close to the human annotation  (Shen et al., 2018a,c) , there exists no model which incorporates phrase structures as latent information to improve the performance and explainability of translation. In this work, we introduce an approach to incorporate the phrase structure explicitly into Transformer  (Vaswani et al., 2017) . The approach can split into two steps; first, latent phrase structures are induced in an unsupervised fashion for the source and target sides  (Shen et al., 2018a) ; second, the two induced latent phrase structures are synchronously agreed with each other through an attention mechanism  (Deguchi et al., 2021) . Experiments on German-English and Japanese-English show that our synchronous latent structures have achieved better performance on translation and alignment tasks. We also show that the induced phrase structures and synchronous structures can enhance the explainability of translation through our detailed analysis in word alignment task. 

 Related Work 

 NMT with Supervised Tree Structure In the previous work, it is reported that supervised phrase structures  (Eriguchi et al., 2017; Nguyen et al., 2020)  and dependency structures  (Ma et al., 2019; Deguchi et al., 2019)  can help the performance of MT. However, these approaches require an annotated corpus of syntactic structures. In addition, such syntactic annotation is done on wordlevel granularities, which might not be the best tokenization for MT tasks due by language mismatch or out-of-vocabulary problem, and often BPE  (Sennrich et al., 2016) , is employed to alleviate the problem. However, the application of BPE to grammatical information might require a different approach for each language. 

 Latent Grammar Induction with Neural Machine Translation  Shen et al. (2018a)  introduce the concept called "syntactic distance" which represents the syntactic relation of word pairs. Similarly,  Shen et al. (2018c)  introduce ordered neurons which allows to learn long-term or short-term information by a novel gating mechanism and activation function.  Kim et al. (2019)  apply amortized variational inference for recurrent neural network grammar to learn the phrase structures in an unsupervised fashion.  Wang et al. (2019)  add an extra constraint to the multi-head self-attention mechanism in order to encourage the attention heads to follow phrase structures.  Shen et al. (2020)  introduce the constrained multi-head self-attention mechanism that allows to induct phrase and dependency structure at the same time. These works successfully learn to induce phrase structure from language modeling task without extra linguistic resources. It is described in  (Htut et al., 2019)  that translation task is a conditional language modeling task with many supervisory signals and is suitable for deriving phrase structure. Unfortunately, despite grammatical information helps the understanding model work, previous work has not explicitly used induced phrase structures. 

 Transformer NMT We employ the Transformer  (Vaswani et al., 2017)  as our base model, which is an encoder-decoder model that relies on an attention mechanism for computing the contextual representations of source and target text. Both the encoder and decoder are composed of multiple layers, each of which includes a multi-head attention (MHA) and a feedforward sub-layer. To compute the MHA output, three inputs, query Q, key K, and value V are projected into N different sub-spaces, namely heads, with each output computed in each subspace, then, projected back to the original space after aggregation: Q1:N = QW Q , K1:N = KW K , V1:N = VW V (1) H n = A Vn = softmax Qn Kn ? d h Vn (2) MHA( Q, K, V) = concat H 1 , ..., H N W O (3) where W Q ? R do?d h , W K ? R do?d h , W V ? R do?d h , W O ? R do?d h are projection parameters. d o is dimension of original space. d h = d o /N is the dimension of subspace. The value A denotes the attention probability for the jth target token overall the ith source token, computed by nth head. In the translation task, Transformer is frequently used for its translation accuracy and efficiency. Transformer decoder employs the autoregressive model which guesses the next token having read all the previous ones. Also, since attention represents relationship the between source and target tokens, it is used in the alignment task  (Garg et al., 2019) .  et al. (2021)  find that NMT performance can be improved by synchronizing the encoder attention to decoder attention, which is called "synchronous syntactic attention". The dependency information is embedded in these attention by supervised learning task. The encoder-decoder attention can be viewed as a soft word alignment, which is a weight that can project the source vector into the target vector space without additional model parameters. This work synchronize the source and target attentions that be embedded dependency information by supervision task. To match the attention of encoder and decoder, they project the encoder attention to the target one, and incorporate constraints such that the source and target attention agree with each other.  

 Synchronous syntactic attention 

 Deguchi ? ? ? ? ? ? ? ? ? ? ? ? Source distance: Target distance: Projected target distance: 

 Synchronous constraint Encoder-Decoder attention  

 Synchronous Latent Phrase Structure In this section, we present the Synchronous Latent Phrase Structure. This proposed method is split into two steps. One is Latent Phrase Structure Induction (LPSI) and the other is Synchronous Constraint. Figure  1  shows the flow of synchronizing Japanese source and English target syntactic distances. 

 Latent Phrase Structure Induction We employ syntactic distance  (Shen et al., 2018a)  as a way to induce phrase structure. Each syntactic distance d i is associated with each span (i, i + 1) which indicates the relative order of hierarchically splitting a sentence into smaller components. For example, Figure  1  shows that the target syntactic distance between 'woman' and 'with' covers the phrase 'the woman with the telescope'. Mathematically, syntactic distance d i is computed through the convolution-based network: d i = tanh(W D ? ? ? ? k i?M k i?M +1 ? ? ? k i ? ? ? ? + b D ) (4) where W D and b D are convolution kernel parameter, kernel size M represents a look-back range to calculate syntactic distance d. k i ? Kn is same as key used in MHA. The attention gate values are computed as follows: g i,t = P (b t ? i) = t?1 j=i+1 ? j,t (5) ? j,t = hardtanh((d t ? d j ) ? ? ) + 1 2 where t is the current time step. ? j,t is a probability value that represents the syntactic relationship of distance d j and d t , and hardtanh(x) = max(?1, max(1, x)). ? is the temperature hyper parameter that controls the sensitivity of ? j,t to the differences between syntactic distances. b t is a variable that indicates the position of break in the phrase structure. This ? is sharper than softmax function, which allows to separate the constituents more easily. The phrase structured MHA is defined based on the gates: ?i,t = g i,t ? a i,t i g i,t ? a i,t (6) where a is an element of attention A. The gate g i,t is a weight that constrains attention to only the same hierarchy in the phrase structure. Here, ? is used in place of the elements of A in Equation  2 . 

 Synchronous Constraint In the MT model, encoder and decoder learn separate phrase structures, which are not necessarily synchronized in that two structures may not be compatible with each other in terms of vector representations. Therefore, synchronizing each phrase structure learned in encoder and decoder, inspired by synchronous grammar in SMT, may improve the performance of translation by the synchronous structure. Inspired by synchronous syntactic attention  (Deguchi et al., 2021) , we project the structure expressed by the encoder syntactic distance to the target one, and incorporate constraints such that the source and target syntactic distances agree with each other. In Figure  1 , the source syntactic distance is projected to the target syntactic distance through the attention weight, and the syntactic correspondence between Japanese and English is learned from the target and projected syntactic distances of the phrase 'saw the woman with the telescope'. The synchronous constraint can be represented by using the Mean Squared Error (MSE) of the syntactic distance between the source and target languages:  l)  is projected syntactic distance in lth decoder layer and computed as: L sync = L l i d (l) i ? d(l) i 2 (7) d ( d(l) = C (l) e (l) (8) where e (l) is syntactic distance in lth encoder layer. C (l) ? R J?I is the lth encoder-decoder attention weight, which represents the relationships of encoder and decoder representations, works just like MHA. Here, I and J are length of source and target sentence. The lth encoder-decoder attention weight is computed as: C (l) = softmax( Q(l) dec K(l) enc ? ? h ) (9) where Q (l) dec and K (l) enc are lth decoder and encoder hidden weights. The important element in phrase structure is the hierarchical positional relationship derived from syntactic distance. However, MSE over-penalizes the models, because it results in the exact distance prediction task. Therefore, we use the rank loss  (Burges et al., 2005)  as proposed by  Shen et al. (2018b) , which takes hierarchical positioning into account. Applying the rank loss to the synchronous constrict, we obtain the following: L sync = L l i,j>i hinge d (l) i ? d (l) j , d(l) i ? d(l) j (10) where hinge(x 1 , x 2 ) = max (0, 1 ? sign(x 1 ) ? x 2 ) and sign(x) is sign function. Therefore, the overall objective L is represented by: L = L trans + ?L sync (11) where L trans = ? J i log p(y i |x, y <i ) where L trans is the objective of machine translation task and ? ? 0 is hyper parameter to control the degree of the synchronous constraint L sync . x and y are source and target sentences, respectively. 

 Experiments We train our proposed models using the training objective in Equation 11 and evaluate them on three tasks: translation, constituency parsing, and word alignment. We implement models within the Fairseq sequence modeling toolkit  (Ott et al., 2019) . 

 Training Details We employ the transformer iwslt de en align fairseq configuration for German-English dataset and the transformer align fairseq configuration for Japanese-English dataset. We use two MHA layers from the bottom to induct the phrase structures, and two encoder-decoder MHA layers from the top to synchronize the encoder and decoder syntactic distances 1 . The hyper parameters are set as look back range M = 5 and temperature ? = 1.0 1 . The synchronous constrain hyper parameter is set by ? = 0.01 for MSE and Rank loss. 

 Tasks 

 Translation Task We evaluated the effectiveness of the synchronous latent phrase structures for MT tasks on IWSLT'14 German-English and ASPEC Japanese-English datasets. We train the translation models on the IWSLT'14 German-English and ASPEC Japanese-English  (Nakazawa et al., 2016)  datasets. We use the prepare iwslt14.sh for IWSLT'14 German-English and follow the instruction of constructing the baseline system of WAT 2 , but KyTea  (Neubig et al., 2011)  is used as the tokenizer for Japanese sentences. These datasets are applied BPE. Table  1  shows the detailed data statistics. To compare the effectiveness of synchronous latent phrase structure, we run additional baselines without latent phrase induction but with synchronous constraints applied to the attention weights. We run inference with a beam size of 5 and report the quality of translation of our models with BLEU  (Papineni et al., 2002) . 

 Constituency Parsing Task In this experiment, we did not apply BPE and English data was parsed using Stanford CoreNLP version 4.1.0 3 , and thus the number of tokens in each sentence is preserved. The latent phrase structure is obtained by force decoding; we feed the gold target sentences from the test set into the word-wise trained MT models. We report unlabeled F-measure (UF) as the quality of English latent phrase structures, inducted from the bottom syntactic distances, with scoring script Evalb 4 . Here, UF is an F-measure that ignores constituency tags and evaluates only by bracketing. 

 Alignment Task We also measure the impact of the alignment qualities represented by our synchronous grammar against other models including a statistical model FAST-ALIGN  (Dyer et al., 2013)  5 . We use the same experimental setup as described in  (Chen et al., 2020)   datasets, but we only use German-English Europarl v7 training data and the gold alignments 7 provided by  (Vilar et al., 2006) . Table  1  shows the detailed data statistics. We report the alignment quality in the penultimate layer following  (Garg et al., 2019)  with Alignment Error Rate (AER) introduced in  (Vilar et al., 2006) . In this task, the trained model is BPE-wise, but the reported AER is word-wise. Furthermore, we report the quality of symmetrized alignments that combined both unidirectional alignments. The combination method is employed the grow-diagonal heuristic  (Koehn et al., 2005) , in which alignments are greedily enlarged from the intersected alignments.  structure is not well inducted from the Japanese-English dataset and the advantage of Rank synchronous constraint is not utilized. The difficulty of induction phrase structure in the Japanese-English dataset can also be read from the results of Transformer with LPSI. 

 Results 

 Translation Task The synchronous syntactic attention model  (Deguchi et al., 2021)  also have good translation performance, but we can improve it further by incorporating the syntactic distance into the attention. Although not shown in previous work  (Htut et al., 2019) , Table  2  shows that the use of explicit latent phrase structure is useful for the MT task. Interestingly, we found that the effective synchronous constrain differed between syntactically close, i.e., German-English, and distant languages, i.e., Japanese-English. 

 Constituency Parsing Task Table  3  compares the performance of our methods against baselines. The results show that the synchronous constraint hurt the quality of latent phrase structures. Especially, in MSE synchronous constraint, UF is drooped 17.01 points from the result of Transformer with latent phrase structure induction. This is because the MSE synchronous constraints induct a synchronous grammar that is different from the phrase structure being evaluated. In other words, synchronous constrain hinders the derivation of the latent phrase structures. However, the decrease in UF by synchronous constrain by rank loss is small, whereas synchronous constrain by MSE greatly reduced UF. It suggests that synchronous constrain by MSE derives an exact synchronization grammar and synchronous constrain by rank loss derives a minimal synchronization grammar. As with prior study  (Htut et al., 2019) , we did not find any correlation between the phrase structure qualities and translation qualities especially when two structures are synchronized in encoder and decoder. This indicates that our induced grammatical structures using synchronous constraints might capture bilingual correspondence better than non-constrained models. Figure  2  shows examples of parse tree from Stanford Parser and our Transformer with LSPI. In the first example "a flash of the human spirit", our model almost correctly inducts phrase structure in comparison with Stanford Parser. The only mistake is grouping "the" and "human" first in the noun phrase "the human spirit". This mistake can be unique to concepts of syntactic distance, as it is the same as in the prior study  (Htut et al., 2019 ). In the second example "have you ever seen a climate neutral tree ?", our model correctly inducts the verb phrase "ever seen a climate neutral tree", but fails to induct the phrase "have you ever" correctly.   30.8 (68.2, 70.3) 32.4 (66.8, 68.4) 27.7 (81.4, 65 .0) --Transformer 46.2 (51.0, 57.1)  47.5 (49.5, 56.1) 35.8 (84.9, 51.3) 33.62 26.59 Transformer + LPSI 43.4 (53.5, 60.1) 45.9 (51.1, 57.6) 34.3 (84.6, 53.4)  33    (Cui et al., 2019) . 

 Alignment Task Table  4  compares the performance of our methods against statistic and neural baseline approaches. Compared with Transformer, the model with latent phrase structure show better translation performance and quality of alignments. Furthermore, synchronizing source and target latent phrase structure decreases the AER, which indicates that synchronous constrain improves the interpretability of translation. However, synchronous constrain by Rank loss resulted in a deterioration in AER, despite improving the translation performance BLEU. Therefore, the relationship between BLEU and AER does not seem to be significantly correlated. Table  5  shows that the effectiveness of synchronous latent phrase structure for two layers from the top in terms of AER. In the penultimate layer, while synchronous constrain by MSE contributed to the improvement of AER, but synchronous constrain by rank loss conversely worsened AER. However, rank loss resulted in a significant improvement AER in the third and fourth layers. In the final layer, both synchronous constraints by MSE and rank loss result in the worse AER. It suggests that the quality of the latent phrase structure derived from the second layer from the bottom is poor and this may have affected the results adversely. 

 Analysis 

 Effectiveness of Attention Gate We realize that our gated multi-head attention (GMHA), without synchronous constraint, is very similar to local attention within mixed multi-head attention (MMHA)  (Cui et al., 2019) . MMHA encourages each head to acquire different features by masking them differently and allows the model to be aware of the order of the sequence.  German-English and 14.08 BLEU point in ASPEC Japanese-English. In the Transformer with latent phrase structure induction (LPSI), the performance is only reduced by 0.89 BLEU point in IWSLT'14 German-English and 0.55 BLEU point in ASPEC Japanese-English without position embedding. For a fair comparison, we employ local attention with 2 window in the two bottom layers of encoder. Similarly, in the Transformer with local attention, the performance is only reduced by 0.93 BLEU point in IWSLT'14 German-English and 0.61 BLEU point in ASPEC Japanese-English without position embedding. It indicates that local constraints on attention mechanisms help learning the order of the sequence rather than latent phrase structure induction. 

 Effectiveness of Synchronous Latent Phase Structure Figure  3  shows examples from the German-English alignment test set. In the first example, we find that there are no false alignments in our models with synchronous constraints. However, in rank loss, the alignment between 'Therefore' and 'Daher', which was captured by MSE, is lost. In the sec-ond example, duplicated our model correctly aligns them with 'um' compared with FastAlign. Therefore, The synchronous constraints by MSE and rank loss indicate that only alignments with high confidence are provided. Furthermore, as can be seen from the precision values in this Table  4 , there are no false alignments in synchronous constrain by rank loss, and definite explainability of translation is achieved. In other words, the synchronization constraint favors precision over recall, which may make the AER worse, but it can provide a reliable explanation for human. The prior study  (Jain and Wallace, 2019; Serrano and Smith, 2019)  conclude that the attentions have not explainability. However, our attention is constrained by the syntactic distance, it can explain the relation between source and target sentence following the constituency tree. We will work it as the future works. 

 Conclusion This paper introduces the approach to improve the performance and explainability of MT. In the MT task, our model improves the quality of translation even through distant language pairs. In the alignment task, we demonstrate that synchronous constraint for syntactic distance can produce high precisional alignments to interpret MT hypothesis. Currently, our approach induces the poor latent phrase structure constructed with the previous work. To achieve the more high performance and explainability of MT, we would like to investigate other syntactic structures and a translation model which can induce better latent phrase structure. Figure 1 : 1 Figure 1: The example of relation between syntactic distances and synchronous constraint on Japanese to English translation task. Starting from induction of source and target syntactic distances, we project the source distance to the target one through encoder-decoder attention weight. By measuring the difference between the projected target syntactic distance and target one with the synchronous constraint. It can embed the syntactic correspondences of source and target language into the encoder-decoder attention weight. 
