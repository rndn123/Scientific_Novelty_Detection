title
Attainable Text-to-Text Machine Translation vs. Translation: Issues Beyond Linguistic Processing

abstract
Existing approaches for machine translation (MT) mostly translate a given text in the source language into the target language, without explicitly referring to information indispensable for producing a proper translation. This includes not only information in the textual elements and non-textual modalities in the same document, but also extra-document and non-linguistic information, such as norms and skopos. To design better translation production workflows, we need to distinguish translation issues that could be resolved by the existing text-to-text approaches from those beyond them. To this end, we conducted an analytic assessment of MT outputs, taking an English-to-Japanese news translation task as a case study. First, examples of translation issues and their revisions were collected by a two-stage post-edit (PE) method: performing a minimal PE to obtain a translation attainable based on the given textual information and further performing a full PE to obtain an acceptable translation referring to any necessary information. The collected revision examples were then manually analyzed. We revealed the dominant issues and information indispensable for resolving them, such as fine-grained style specifications, terminology, domain-specific knowledge, and reference documents, delineating a clear distinction between translation and the translation that text-to-text MT can ultimately attain.

Introduction Translation is not a purely linguistic process  (Vermeer, 1992)  but also the process of producing a document in the target language that plays the same role (has the same effect) as the given source document written in the source language. When translating a given document, translators refer not only to the textual elements in the document, but also to the role of each textual element (e.g., running text, section title, table element, and caption), other non-linguistic elements (e.g., figures and formulae), and their structure. To produce a translation, we also need some extra-document and non-linguistic information, such as the norms specific to the register of the document and corresponding target sub-language  (Toury, 1978) , the objective and the intended usages of translation, i.e., skopos  (Vermeer, 2004) , and various specifications  (Melby, 2012)  designated by the translation client if any. Despite the requirements a (proper) translation must satisfy, techniques for machine translation (MT) have been developed by regarding the task of translation as text-to-text transfer. Until very recently, most studies have performed a text-to-text MT for each text segment, 1 even though a sequence of perfect segment-level text-to-text translations does not necessarily qualify as a proper translation. Recent studies on neural MT (NMT) have addressed issues beyond this formulation, exploiting further information such as document-level textual context  (Voita et al., 2018 (Voita et al., , 2019 Lopes et al., 2020)  and other modalities  (Barrault et al., 2018) . There are also several focused studies on exploiting extra-document and non-linguistic information. However, such information has not been extensively discussed. As a result, in translation production workflows at translation service providers (TSPs), where MT outputs are treated as draft translations, heavy human labor is necessary to fill the gap between MT outputs and translations in addition to resolving issues at the text-to-text level, for instance, by manual post-editing (PE). To design and establish more practical ways of exploiting MT systems in translation production workflows as well as to discuss how to make MT systems more useful, we need to understand what lies in the gap between a translation that text-to-text processing can attain and a truly acceptable translation. Moreover, this should be shared among not only translators but also MT researchers and MT users. From this point of view, this paper presents our analytic assessment of MT outputs, taking an English-to-Japanese news translation task as a case study. First, we obtained segment-level text-to-text translation by resolving translation issues in MT outputs. At this stage, a minimal PE was performed referring only to each source segment isolated from any other information, and thus the results represent what segment-level text-to-text MT systems can ultimately attain. Then, the document-level full PE (ISO/TC37, 2017) in the succeeding stage resolved all the remaining issues, i.e., those issues lying in the gap between acceptable segment-level text-to-text translation and proper translation. Finally, the collected revision examples were manually analyzed based on an issue classification scheme. This revealed several dominant issues as well as the information indispensable for resolving them. The remainder of this paper is organized as follows. Section 2 summarizes related work in translation studies and MT. Section 3 presents the material for our case study. Section 4 describes our workflow, designed for collecting translation issues that cannot be solved by textto-text processing. Section 5 presents our analytic assessment of translation issues, which relies on an existing issue typology, and explains the dominant issues as well as several types of extra-document and/or non-linguistic information that must be used to solve them. Section 6 describes future research directions and advice for non-expert MT users, and Section 7 concludes the paper. 

 Related Work In the literature of translation studies, linguistic approaches to translation have been criticized  (Kenny, 2001) , and the equivalence of a source document and a target document has been studied from a diverse range of aspects. In a seminal work,  Nida (1964)  claimed the necessity of equivalence of recipients' reactions when reading source and target documents.  Chesterman (1997)  compiled a typology of translation strategies adopted to guarantee the equivalence when producing a translation. His syntactic and semantic strategies can be explained (and potentially realized) referring only to textual information in the source document and linguistic knowledge in general. In contrast, some of his pragmatic strategies, such as cultural filtering and illocutionary changes, require extra-document and/or non-linguistic information. Some of the kinds of information that must be referred to for producing a proper translation, including terminologies and style specifications, are mentioned in the translation workflow standard, ISO 17100 (ISO/TC37, 2015). Other items are mentioned in existing criteria for quality assurance, such as the Multidimensional Quality Metrics (MQM) 2 and the Dynamic Quality Framework (DQF).  3  Reference sources, such as translation memories and bilingual concordancers, and other access to past translations are valuable assets for improving efficiency in personal practices and workflows in TSPs. However, there is neither a comprehensive inven-tory of references, nor a common view of the extent of the necessity and availability of each reference depending on the given skopos. Recent advances in MT go beyond segment-level and/or text-to-text processing. For instance,  Voita et al. (2019)  focused on several discourse-level issues, i.e., deixis, lexical cohesion, and ellipsis, occurring in segment-level text-to-text MT. Following studies proved that context-aware decoding that refers to several preceding segments better handles these linguistic phenomena  (Lopes et al., 2020) . There are several focused studies on exploiting extra-document and non-linguistic information, including terminologies  (Arthur et al., 2016; Hasler et al., 2018) , politeness  (Sennrich et al., 2016a) , domain  (Chu et al., 2017; Kobus et al., 2017; Bapna and Firat, 2019) , style  (Niu et al., 2017; Michel and Neubig, 2018b) , markups  (Chatterjee et al., 2017; Hashimoto et al., 2019) , and external lexical knowledge  (Moussallem et al., 2019) . However, the information indispensable for producing a proper translation have not been thoroughly studied. More importantly, no work guarantees to perfectly reflect such information. The MT community has benefited from manual analyses of translation issues 4 caused by MT systems. Existing methodologies for analyzing translation issues in MT outputs can be two-fold: (a) comparisons of independent products, i.e., MT outputs and human translations  (Popovi? and Ney, 2011; Irvine et al., 2013; Toral, 2020) , and (b) annotations of the issues in MT outputs according to pre-determined issue typologies, such as MQM and DQF  (Lommel et al., 2015; Ye and Toral, 2020; Freitag et al., 2021) . The issues identified in the former approach contain both true errors and preferential differences, i.e., alternative acceptable translations independently selected by MT systems and humans. The latter approach enables us to clearly separate them. For instance, past studies  (Hardmeier, 2014; Scarton et al., 2015; Voita et al., 2019)  analyzed outputs of segment-level text-to-text MT, showed the limitation of that approach, and encouraged the research on document-level MT. However, they discussed only the differences between two text-to-text approaches. Issues beyond the text-to-text processing, such as those related to extra-document and/or non-linguistic information, have seldom been mentioned  (Castilho et al., 2020) , and no focused and empirical analysis has been conducted. 

 Subject of Our Case Study Our focus in this paper is to clarify the types of extra-document and/or non-linguistic information that are indispensable for producing a translation. Among several translation tasks, this paper takes an English-to-Japanese news translation task as a case study and presents our indepth analysis. We chose it for two reasons. First, despite the high demand for it, the task is still very difficult, since the two languages are linguistically distant and used in substantially different cultures (cf. English-to-German studied by  Scarton et al. (2015) ). The norms for news texts are also substantially different in these languages, making them more difficult to translate than texts in other domains, such as scientific paper abstracts  (Nakazawa et al., 2019)  and patent documents  (Goto et al., 2013) . The second reason is that we wished to conduct an indepth analytic assessment of translation (see Section 5) by ourselves. We have a linguist who is highly competent in both linguistics and translation and has ample experiences in the analytic assessment of both MT outputs and human translations. As material for this case study, we used the documents in the Asian Language Treebank (ALT)  (Riza et al., 2016) .  5  Table  1  gives statistics for the English source documents and Japanese target documents produced by professional human translators, where the numbers of tokens were counted after applying our in-house tokenizers.  

 Data Collection To clarify the limitations of the text-to-text approach for MT while acknowledging its status, we began with the outputs of a reasonably strong NMT system and collected examples of translation issues with their revisions through a modified version of the two-stage PE workflow originally proposed by  Scarton et al. (2015) . Our procedure is as follows. Stage (1) Segment-level text-to-text NMT: Given source documents are translated by an MT system, which is preferably the one that can produce a translation of exploitable quality. We regard a segment-level text-to-text NMT as the subject. Stage (2) Segment-level minimal PE: Each segment-level MT output is separately postedited without referring to any information other than the segment itself, for example, other segments in the same document and other reference documents. To avoid introducing any preferences from human workers, this stage allows only minimal edits. 

 Stage (3) Document-level full PE: The results of stage (  2 ) are further post-edited at document level to resolve the remaining issues caused by segment-level and/or text-to-text processing, where the human workers are allowed to refer to any necessary information. The resulting data exhibit the limitations of the segment-level text-to-text processing. 6 Figure  1  compares our workflow (in the right-most path) with conventional human translation ("Non-MT workflow") and the prevalent one in TSPs ("MT+PE"), i.e., segment-level text-to-text MT followed by document-level manual full PE. Our workflow can be seen as an extension of "MT+PE" with an intermediate segment-level minimal PE stage. The division of segment-level and document-level PE was originally proposed by  Scarton et al. (2015)  as a means of manually assessing the outputs of statistical MT (SMT) systems. Note that our subject is not the gap between segment-level and document-level text-to-text processing, i.e., MT systems, as in  Scarton et al. (2015) , but the limitation of such text-totext processing. We therefore need to collect translation issues that can only be resolved by referring to information other than the given textual information. To exclude issues that can be resolved by referring only to the given textual information as much as possible, we decided to obtain translations that are attainable but closest to the outputs of text-to-text MT through minimal PE; we explicitly constrain the human workers by (i) prohibiting them from referring to any information other than the textual information and (ii) allowing only minimal edits, 7 while also avoiding subjective stylistic changes.  8  Even though document-level text-to-text MT has been actively studied  (Voita et al., 2018 (Voita et al., , 2019 Lopes et al., 2020) , we decided to begin with segment-level MT and PE because we can ensure the minimality of the edits using segmentlevel automatic metrics (see Section 4.2). By performing only minimal PE at segment level, we can leave all the translation issues that can only be resolved by referring to extra-document and/or non-linguistic information for a later stage. These issues are resolved in the succeeding document-level full PE stage, and we distinguish (a) those issues revealing the gap between segment-level and document-level processing and (b) those issues revealing the limitations of the text-to-text processing, through our manual analysis (see Section 5). Our process for collecting translation issues uses some parameters that differ from those in  Scarton et al. (2015) , including the MT paradigm (SMT vs. NMT), translation task (English-to-German vs. English-to-Japanese), and worker experiences (students vs. professionals employed by a TSP with ISO certificates (ISO/TC37, 2015, 2017)). 

 Stage (1) Segment-level Text-to-Text NMT To begin with a translation of exploitable quality, we trained a segment-level but reasonably strong 9 English-to-Japanese NMT system on a large-scale in-house English-Japanese parallel corpus (henceforth, TexTra) 10 in addition to the ALT training data, using a method for domain adaptation  (Chu et al., 2017) . First, we trained an English-to-Japanese NMT model on TexTra alone, explicitly excluding all the segment pairs in the ALT. For each source and target language, a sub-word vocabulary was also created from the corresponding side of this corpus: we determined 32k sub-words with byte-pair encoding  (Sennrich et al., 2016b)  after tokenization. Then, we fine-tuned the model parameters on a mixture of TexTra and the ALT training data. Following  Chu et al. (2017) , we used a balanced mixture of the two corpora by inflating the ALT training data K times and randomly sampling the same number of segment pairs from TexTra. Finally, we further fine-tuned the NMT model on the ALT training data only. We used Marian NMT  (Junczys-Dowmunt et al., 2018)  11 for all the NMT training and decoding processes, using the Transformer Base model and the hyper-parameters for training as used in  Vaswani et al. (2017) . We terminated the training at each phase by early-stopping with a patience of 5, regarding the model perplexity on the ALT development data, computed after every T iterations, as the evaluation criterion. The value of T was set to 5,000 for the phase 1, and 10 for the phases 2 and 3. For the value of sample size K in phase 2, we selected 32 from the options 1, 2, 4, 8, 16, 32, and 64 according to the BLEU score  (Papineni et al., 2002)  on the ALT development data, computed by SacreBLEU  (Post, 2018) .  12  When decoding the ALT test data, the beam size was fixed 10, and the value for the length penalty was tuned on the ALT development data and set to 0.8. 

 Stage (2) Segment-level Minimal PE To perform a segment-level PE, we isolated each segment from the others in the same document by shuffling the pairs of source segment and corresponding segment-level MT output across all the test documents. We then asked 13 an experienced, ISO-certified TSP with well-designed workflows for translation (ISO/TC37, 2015) and PE (ISO/TC37, 2017) to revise the MT output of each segment independently without referring to any information other than the individual segment. The goal of this stage was to obtain a segment-level translation that fluently and accurately conveys the information in the corresponding source segment. To avoid excessive PE, we imposed a constraint, hter (m, p) ? hter (m, r), where m, p, and r stand for the MT output, its post-edited version, and reference translation, 14 respectively. hter (a, b) is the Human-targeted Translation Edit Rate (HTER)  (Snover et al., 2006) , which computes how one segment a is dissimilar from another segment b at surface level, implemented in tercom.  15  We used MeCab 16 to tokenize the Japanese translation, unlike our implementation of NMT, in order to enable the consistent tokenization in both our environment and the workers' environment. During this process, 95% of the segments (970/1,018) received some revisions. This suggests that our system still seldom generates acceptable segment-level translation in this Englishto-Japanese news translation task. Because we allowed only minimal editing operations, the results represent the closest goal of segment-level text-to-text MT. 

 Stage (3) Document-level Full PE After completing segment-level minimal PE for all segments, the documents were reverted by ordering the segments. We then asked 17 another set of workers through the same TSP to further revise the translation referring not only to the entire document but also to any extra-document and/or non-linguistic information, as in the ordinary document-level full PE workflow, i.e., "MT+PE" in Figure  1 . Note that we hid the original MT outputs and provided the results of segment-level PE as the draft translation for revision. The workers were asked to make the target documents cohesive, consistent, and appropriate for news articles, also correcting content errors if any. Some examples are presented in Section 5.1. As a result, 320 segments (31%) in 86 documents (89%) were revised. The total quantity of edits during this stage was much smaller than in the previous stage, but they were indeed necessary to obtain proper translations. This also confirms that a sequence of acceptable segmentlevel text-to-text translations does not necessarily qualify as translation. It further confirms that, 12 https://github.com/mjpost/sacreBLEU/, short signature: BLEU+c.mixed+l.en-ja+#.1+s.exp+t.13a+v.1.4.1  13  The price was based on the number of tokens in the source documents as in an ordinary translation contract. Thus, there was no incentive to increase the amount of PE.  14  The TSP and workers did not see the ALT reference translation, and were asked to redo the task from the given MT output if we judged that their PE result did not satisfy the constraint. Table  2 : BLEU and HTER scores of different versions of translations with respect to the ALT reference translation (ALT). Note that these results are based on our in-house Japanese tokenizer (cf. MeCab used in the workflow for consistent tokenization). " ?1" and " ?3" respectively denote the score is significantly better than that for phases 1 and 3 (p < 0.05). as in other well-studied translation tasks  (L?ubli et al., 2020; Freitag et al., 2021) , human parity  (Hassan et al., 2018)  is not yet attainable in this English-to-Japanese news translation task. 

 Translation Quality Measured by Automatic Evaluation Metrics Table  2  summarizes the BLEU and HTER scores of different versions of translations obtained in our workflow. To determine if differences in BLEU scores are significant, we performed statistical significance testing (p < 0.05).  18  The BLEU score of our adapted NMT system (phase 3) was significantly better than the non-adapted system (phase 1). We consider that it generated a translation of sufficient quality for this first stage in the process. Whereas the improvement brought by segment-level minimal PE was visible and the BLEU gain was statistically significant, the document-level full PE improved neither BLEU nor HTER scores. 

 Manual Analysis of Translation Issues Our post-edited translation data contain two separate and different types of translation issues: the remaining issues from the segment-level text-to-text MT, and the issues that require information other than the individual segments to resolve. We manually analyzed the latter translation issues resolved during the document-level full PE in stage (3). First, using tercom, we automatically identified the corresponding text spans in the two versions of the translations obtained in stages (  2 ) and (3). Then, we manually extracted pairs of text spans: one for an issue in the segment-level PE result, and the other for its revision in the document-level PE result. As a result, we obtained 529 such revision examples. Finally, we annotated each revision example with the following three types of labels. Need for document-level textual information: whether the textual information outside the segment but within the document was necessary to solve the issue. Need for extra information: whether any extra-document and/or non-linguistic information was necessary to solve the issue. If it was needed, we also noted the information types (more than one if applicable). Issue type: one of the 16 types in a translation issues typology designed for assessing and learning English-to-Japanese translation  (Fujita et al., 2017) . We chose this typology because its usefulness for this translation direction had been verified, whereas a widely used MQM had not.    Fujita et al. (2017)  for the definition of each issue type and the classification procedure, and Table  3  for the classification of (a) to (d). Tables  3 and 4  show our classification results: whereas Table  3  shows a contingency table based on the first two labels, Table  4  shows the type-wise numbers of revision examples, merging (c) and (d) in Table  3  for the sake of simplicity. 

 Issues Beyond Text-to-text MT Among the four classes shown in Table  3 , our main subjects are 217 examples in (c) and (d) that can only be resolved by referring to some extra-document and/or non-linguistic information. Such information is categorized into the following four types. A) Fine-grained style specifications (121 examples): Texts in Japanese newspapers are written following various specifications, including those for vocabulary, set of characters, usages of symbols including parentheses, degree of formality, and other notational rules. Our source texts themselves might have revealed that they are from the news domain. However, the workers for the segment-level minimal PE task did not perform revisions to fulfill such specifications, leading to translation that is inappropriate for the register (81 X14 issues). Because of a lack of a specification for transliteration at the segment-level PE stage, the workers left some named entities untranslated (16 X4a issues), considering that Latin characters are sometimes used in Japanese documents and that the contents in the source segments are comprehensible. Source: Clemens (3-0(#1), 1.90 ERA in seven World Series starts) will make his 33rd career postseason(#6,#7) start(#8) Saturday, at least for a day matching(#5) Pettitte (3-4(#3), 3.90 in 10 World Series starts) for the most ever(#4). Seg.PE:   3 ) and the issue type (see Table  4 ). ? ? ? ? ? (? ? ? ? ? ? ? ? ? ? ? ? ?(#1/3 points vs 0 points)? ? ? ? ? ? ?) ? ? ? ? ? ? ? ? [ ](#2/ )? ? ? ? ? (? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(#3/3 points vs 4 points)? ? ? ?) ? [ ](#4/ )?(#5/paired)? ? ? ? ? [ ](# 6 

 B) Terminology (80 examples): When translating named entities, we must look up the terminologies for authorized translations/transliterations. Consider, for instance, the person name "John Paul." The most likely transliteration for it is "?" (/dZ'On p'O:l/). However, it must be transliterated into "?" (/joh2nE p2Ul@/) when it refers to the Pope. Most improper and/or inconsistent term translations (64 X7 issues) and the above untranslated entities (16 X4a issues) were caused due to a lack of a terminology. 

 C) Domain-specific knowledge (31 examples): Our documents cover diverse topics such as politics, religion, and sports. Some semantic issues required knowledge specific to each of these domains to understand the contents in the source texts and produce appropriate expressions. See, for instance, the example in Figure  2 . One must realize that this text is talking about baseball, and have knowledge about that domain, in order to perform the revisions marked (c). Some incohesive issues (five X16 issues) also require such knowledge to resolve. 

 D) Reference documents (eight examples): When translating ambiguous expressions, we need some clues to disambiguate them. If the document does not contain such information, we must find some reliable information outside the document. Because our text-to-text MT system and our segment-level minimal PE can only access the textual information, some semantic issues (seven X3 issues) and an incomplete translation with multiple options (X6 issue) were left. The X6 issue gives both "? (elder brother)" and "? (younger brother)" as multiple translation options for "brother." This ambiguity was resolved only when the worker found credible biographical information on the Web. Although we found only eight examples that were resolved in the document-level full PE stage referring to other information sources, we confirmed that our text-to-text MT sometimes correctly disambiguates such expressions by chance. 

 Remaining Issues of Text-to-Text MT The remaining 196 and 116 examples were respectively classified as (a) and (b), i.e., those that had been resolved by referring only to the given textual information. These resolutions could be attainable by algorithmic advancements in the text-to-text approach for MT. Although they are outside the focus of this paper, we make some observations relevant to our study. Segment-level issues, i.e., (a), lie at the levels 2 to 4 in the issue typology (Table  4 ). Whereas the ones at levels 2 and 3 should have been resolved through segment-level minimum PE, the ones at level 4 are not considered mandatory as long as the translations are considered comprehensible. We believe that we have successfully excluded much larger number of similar segment-level text-to-text issues by introducing the segment-level minimal PE stage (Section 4.2) and the above remaining issues are not harmful to our study. We could have reduced the examples in this class by removing our constraints for minimal edits. However, this introduces some risks, such as losing examples in our concern, i.e., (c) and (d), and being mislead by some artificial examples, such as combinations of preferential edits in both segmentlevel PE and document-level PE. Class (b) examples exhibit revisions made by referring to the textual information in the document, but no more than that. They appeared at all issue levels in the typology except level 3, grammaticality, and the majority were either X16 (incohesive) or X3 (content distortion). To translate the mentions of each entity coherently and cohesively  (Voita et al., 2019) , we need to identify the correct referent of each mention. In the literature, a matrix called the entity grid  (Barzilay and Lapata, 2008)  is used to represent the appearance of entities and segments in the given source document. Actively studied document-level text-to-text MT might be able to capture such information, for instance, by enhancing the self-attention mechanisms  (Vaswani et al., 2017; Maruf et al., 2019; Beltagy et al., 2020) . However, as we confirmed in our analysis (Section 5.1), referents are not necessarily given in the source document, and we hence must seek reliable extra-document information. 6 Discussion and Future Directions Techniques for MT have been advanced thanks to the simplified problem setting, i.e., textto-text processing, and the advent of automatic evaluation metrics, such as BLEU  (Papineni et al., 2002) , which are based on comparison with reference translations. However, considering the large gap between what text-to-text MT can ultimately attain and the needs that translation must satisfy, a fully automatic MT approach  (Hutchins and Somers, 1992)  still looks infeasible. Rather, approaches in machine-aided human translation and human-aided MT, i.e., human-machine interactions, are more promising. Indeed, "MT+PE" in Figure  1 , which has been prevalent in the translation production workflow at TSPs for a decade, lies in that direction. In this way, to reduce the cognitive load of PE, we must continue to enhance both wheels, i.e., improving MT systems and determining the best practices in using them. As confirmed in Section 4.2, segment-level text-to-text MT still has much room for improvement. Yet, as shown in recent studies, textual information within the entire source document is useful. To generate cohesive texts, we should incorporate the latest outcomes in discourse processing and natural language generation, such as discourse parsing  (Jia et al., 2018)  and generating referential expressions  (Paraboni et al., 2007) . To assess MT outputs for further improvement while reducing the human labor in PE, we also need to invent documentlevel automatic evaluation methods, preferably analytic ones rather than holistic ones. Ultimately and ideally, we should also consider going beyond text-to-text processing, seeking better ways for incorporating information indispensable for translation, such as those we described in Section 5.1, rather than indirectly representing them with text data. For instance, to enforce the use of particular expressions specified by pre-compiled terminologies and style specifications, we need to improve the decoding mechanism, such as constrained decoding  (Hasler et al., 2018; Post and Vilar, 2018; Zhang et al., 2018) . Style specifications and domain-specific knowledge might be learned from text data in a given fine-grained domain, such as the one in Figure  2 . We can see related work in adaptive data selection  (Chen et al., 2016)  and extreme adaptation  (Michel and Neubig, 2018a) . In addition to the enhancement of MT systems, we should also establish reliable and effective ways for identifying critical issues in MT outputs as well as determining translation scenarios where MT is promising or hopeless. For instance, word frequency and sentence length affect the segment-level MT quality  (Koehn and Knowles, 2017) . Such findings motivate the pre-editing of segments prior to decoding  (Pym, 1990; Miyata and Fujita, 2021) . From a general perspective, we should consider educating people (all people) so that they acquire two types of literacy: translation literacy for understanding the norms, skopos, and other specifications in their translation task  (Klitg?rd, 2018) , and MT literacy for understanding the characteristics of the intended MT service, which helps minimize potential risks  (Bowker and Ciro, 2019) . We believe that our method for clearly delineating between translation and the translation that text-to-text MT can ultimately attain as well as our case-study findings can be useful resources for such education. 

 Conclusion To analytically assess issues that cannot be resolved by text-to-text processing, such as textto-text MT, this paper presented our specific constraints incorporated into the two-stage PE pipeline originally proposed by  Scarton et al. (2015) . In a case study on the English-to-Japanese news translation task, we found that translation issues beyond text-to-text processing are caused by a lack of extra-document and/or non-linguistic information, such as fine-grained style specifications, terminology, domain-specific knowledge, and reference documents. The resulted parallel data and annotated revision examples are publicly available.  19  Our method is laborious and requires very high competence in both linguistics and translation. Nevertheless, it is applicable to other translation tasks where we can build an MT system that can produce translation of exploitable quality. We thus hope other researchers use our method to assess the limitations of text-to-text processing and the remaining issues in a wide range of translation tasks. We plan to introduce another document-level minimal PE stage in order to assess the attainable translation by document-level MT. While clarifying the limitations, we also suggested how we can enable MT systems to explicitly refer to extra-document and/or non-linguistic information. We plan to evaluate the impact of enforcing decoding with external knowledge, such as terminologies and style specifications. An important issue in present-day society was also illuminated: the need to cultivate translation literacy and MT literacy in people to avoid the risk caused by the innocent use of MT services. To tackle this, we are currently compiling educational materials to help people understand translation, MT, and their differences. We will also analyze various levels of competences required for human translators, following the Competence Framework developed by the European Master's in Translation  (Toudic and Krause, 2017) . Figure 1 : 1 Figure 1: Comparison of translation workflows: the translation process refers to any information other than the given source document (cf. text-to-text process). 
