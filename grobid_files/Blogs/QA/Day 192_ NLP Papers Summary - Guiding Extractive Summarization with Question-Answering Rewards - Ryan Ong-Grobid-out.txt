title
Data Science Natural Language Processing NLP Papers Summary

abstract
Objective and Contribution Proposed an extractive summarisation model with question-answering rewards as we believe that informative summaries should include answers to important questions. Our generated summaries yielded competitive results as measured by automatic metrics and human assessors.

To create question answer (QA) pairs, we limit our answer token to either be a salient word or named entity. We identify salient word or named entity in all the sentences in the human abstract and replace the answer token with a blank to create Cloze-style QA pair. Note that at least one QA pair should be extracted from each sentence of the abstract so that our summary includes all the useful content to answer all the questions. Overall we know have a set of QA pairs extracted from the human abstract and we can train our LSTM and attention mechanism to answer these questions using the source document. We believe that extracting summary chunks rather than sentence level is key to building a concise summary but it does makes the summarisation task more challenging as the search space is larger. We also observed that the ROOT-type QA pairs have the least number of unique answers. Our QASumm + ROOT performed the best amongst the variant in daily mail dataset and QASumm + NER performed the best in CNN dataset. We suspect that maintaining a good number of unique answers is important to maximise performance.  

 A REINFORCEMENT LEARNING FRAMEWORK 

 EXTRACTION UNITS We want to nd out whether words or chunks are better as the extraction units. We compared the performance of our LSTM and CNN encoder and found that chunks with LSTM performed the best and chunks with CNN outperformed LSTM and CNN with words.  

 HUMAN EVALUATION Each participant is given the document and three ll-in-the-blank questions. The answer tokens is chosen randomly and can be root word, the subj/obj word, or NER word. We asked the participants to rate the informativeness of the summary from 1 -5, 5 being the most informative. We evaluated the summaries from our models and PG network. The table  below  showcase the average time it takes to complete a single question, the overall accuracy, and the informativeness score. Excluding human performance, our QASumm with NER-type QA pairs was able to achieved the highest accuracy and informativeness. We found that our best performing model has a wide margin in QA accuracy despite similar level of informativeness score.  

 Conclusion and Future Work NLP Papers Summary -Guiding Extractive Summarization with Question-Answering Rewards -Ry? https://ryanong.co.uk/2020/07/10/day-192-nlp-papers-summary-guiding-extractive-summarization-with-question-answering-re? 3/10 4. Reinforcement learning EXTRACTION UNIT We experimented with words or chunks (phrases) as extraction units. We obtain text chunks using the sentence constituent parse tree and each chunk has at most 5 words. Note that we did not experiment with sentence level extraction like most existing work. Instead, we focused on ner-grained extraction units. We experimented with CNN and biLSTM to encode these extraction units. CONSTRUCTING EXTRACTIVE SUMMARY We need to identify text segments from source articles to form our extractive summary and this can be seen as a sequence labelling problem. We decided to use the framework whereby the importance of the t-th source extraction unit is determined by its informativeness, its position in the document, and the relationship with the previously selected extraction units. We have positional embeddings to encode the position of the extraction unit. At each time step, we build the vector representation of our summary up to time t -1 and used it along with positional embeddings and our encoded hidden states to determine whether we should include the new extraction unit. The architecture for this is an unidirectional LSTM as shown below. NLP Papers Summary -Guiding Extractive Summarization with Question-Answering Rewards -Ry? https://ryanong.co.uk/2020/07/10/day-192-nlp-papers-summary-guiding-extractive-summarization-with-question-answering-re? 4/10 
