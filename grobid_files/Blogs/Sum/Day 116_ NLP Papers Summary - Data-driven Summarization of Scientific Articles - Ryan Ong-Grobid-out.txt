title
Day 116: NLP Papers Summary -Data-Driven Summarization Of Scienti c Articles

abstract
gen) and applied a wide range of extractive and abstractive models to it. The title-gen dataset consists of 5 million biomedical papers whereas the abstract-gen dataset consists of 900K papers. The analysis show that scienti c papers are suitable for data-driven summarisation.

Experimental Setup and Results 

 MODELS COMPARISON NLP Papers Summary -Data-driven Summarization of Scientific Articles -Ryan Ong https://ryanong.co.uk/2020/04/25/day-116-nlp-papers-summary-data-driven-summarization-of-scientific-articles/ 2/8 WHAT IS DATA-DRIVEN SUMMARISATION? It is a way of saying the recent SOTA results of summarisation models rely heavily on large volume of training data. Datasets The two evaluation datasets are title-gen and abstract-gen. Title-gen was constructed using MEDLINE and abstract-gen was conducted using PubMed. The title-gen pairs the abstract to the title of the paper whereas the abstract-gen dataset pairs the full body (without tables and gures) to the abstract summary. The text processing pipeline is as follows: the Overlap score and Repeat score for each data pairs. The Overlap score measures the overlapping tokens between the summary (title or abstract) and the input text (abstract or full body). The Repeat score measures the average overlap of each sentence in a text with the remainder of the text. This is to measure the repetitive content that exists in the body text of a paper where the same concepts are repeated over and over again. Below are the summary statistics of both datasets. 

 8 1. 8 Papers Summary -Data-driven Summarization of Scientific Articles -Ryan Ong https://ryanong.co.uk/2020/04/25/day-116-nlp-papers-summary-data-driven-summarization-of-scientific-articles/ 3/Extractive summarisation methods. Two unsupervised baselines here: TFIDF-emb and rwmdrank. TFIDF-emb creates sentence representation by computing a weighted sum of its constituent word embeddings. Rwmd-rank ranks sentences by how similar the sentence is compared to all the other sentences in the document. Rwmd stands for Relaxed Word Mover's Distance, which it's the formula used to compute similarity and subsequently LexRank is used to rank the sentences. 2. Abstractive summarisation methods. Three baselines here: lstm, fconv, and c2c. Lstm is the common LSTM encoder-decoder model but with an attention mechanism at the word-level. Fconv is a CNN encoder-decoder on subword-level, separating words into smaller units using byte-pair encoding (BPE). Character-level models are good at dealing with rare / outof-vocabulary (OOV) words. C2c is a character-level encoder-decoder model. It builds character representations from the input using CNN and feed it into an LSTM encoderdecoder model. RESULTS The evaluation metrics are ROUGE scores, METEOR score, Overlap score and Repeat score. Despite the weaknesses of ROUGE scores, they are common in summarisaiton. METEOR score are used for machine translation and Overlap score can measure to what extent the models just copy text directly from input text as summary. Repeat score can measure how often the summary contains repeated phrases, which it's a common problem in abstractive summarisation. NLP Papers Summary -Data-driven Summarization of Scientific Articles -Ryan Ong https://ryanong.co.uk/2020/04/25/day-116-nlp-papers-summary-data-driven-summarization-of-scientific-articles/ 4/8 For title-gen results (table 2), rwmd-rank is the best extractive model, however, c2c (abstractive model) outperformed all extractive models by a large margin, including the oracle. Both c2c and fconv achieved similar results with similar high overlap scores. For abstract-gen results (table 3), lead-10 was a strong baseline and only extractive models managed to outperformed it. All extractive models achieved similar ROUGE scores with similar Repeat score. Abstractive models performed poorly based on ROUGE scores but outperformed all models in terms of METEOR score so it was dif cult to draw up conclusion. Qualitative evaluation is common and conducted on the generated summary. See below an example of the title-gen qualitative evaluation. The observations are as follow: 1. Large variation of sentence locations selected by extractive models on title-gen, with rst sentence in the abstract being the most important 2. Many abstractive generated titles tend to be of high quality, demonstrating their ability to select important information 3. Lstm tends to generate more novel words whereas c2c and fconv tend to copy more from input text 4. The generated titles occasionally make mistakes by using incorrect words, being too generic and fail to capture the main point of the paper. This could all lead to factual ? ? 21/02/2022, 21:41 Day 116: NLP Papers Summary -Data-driven Summarization of Scientific Articles -Ryan Ong https://ryanong.co.uk/2020/04/25/day-116-nlp-papers-summary-data-driven-summarization-of-scientific-articlesabstract-gen, it appears that introduction and conclusion sections are most relevant for generating abstract. However, important content are spread across sections and sometimes the reader focuses more about the methodology and results 6. Output of fconv abstractive model is of bad quality where it lacks coherent and content ow. There is also the common problem of repeated sentence or phrases in the summary ? 21/02/2022, 21:41 Day 116: NLP Papers Summary -Data-driven Summarization of Scientific Articles -Ryan Ong https://ryanong.co.uk/2020/04/25/day-116-nlp-papers-summary-data-driven-summarization-of-scientific-articles/ 6
