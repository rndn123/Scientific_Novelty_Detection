title


abstract


NMT directly models the conditional probability p(y/x) of translating a source (x1,x2?.xn) sentence into a target sentence (y1,y2?.yn). NMT consist of two components: 1. An encoder which computes a representation S for each source sentence 2. A decoder which generates translation one word at a time and hence decomposes the conditional probability as: A probability of translation y given the source sentence x One could parametrize the probability of decoding each word y(j) as where h(j) could be modeled as 

 RNN hidden unit definition (h) where g: a transformative function that outputs a vocabulary size vector h: RNN hidden unit f: computes the current hidden state given the previously hidden state. The training objective for the translation process could be framed as 

 Loss Function What makes NMT so popular? 1. NMT has achieved the state of the art performances in large scale translation tasks like English to French/German. 2. NMT requires minimal domain knowledge and is conceptually very simple. 3. NMT has a small memory footprint as it does not store gigantic phase tables and language models. 4. NMT has the ability to generalize well to very long word sentences. 

 Difference between attention and non-attention based networks In most of the non-attention based RNN architecture source representation, S is used only once to initialize the decoder hidden state. [In Figure  1     Both the attention based methods have the following common steps: 1. Both approaches first take as input the hidden state h(t) at the top layer of a stacking LSTM. (The brown cell / The target state of the decoder) 2. Derive c(t) to capture relevant source side information to help predict y(t) (Top blue cell). c(t) is basically the context that you have built for every word depending upon its alignment weights and hidden state of encoders. 

 Compute h_bar(t) from a simple concatenation of h(t) and c(t) (Top grey cell). In contrast to the non-attention based architectures where only the final output of the encoder is provided to the decoder, h_bar(t) has access to all the states of hidden states of the encoder which provides an informative view of the source sentence. 4. The attentional vector is transformed using the softmax layer to produce the predictive distribution. We are using the softmax layer as we have to found the most probable word from all the available words in our vocabulary. The above para explains a barebone architecture of the attention based networks. In the following para, we will understand how is  

 Global Attention Global attention takes into consideration all encoder hidden states to derive the context vector (c(t)). In order to calculate c(t), we compute a(t) which is a variable length alignment vector. The alignment vector is derived by computing a similarity measure between h(t) and h_bar(s) where h(t) is the source hidden state while h_bar(s) is the target hidden state. Similar states in encoder and decoder are actually referring to the same meaning. Alignment Vector (a(t)) The alignment vector (a(t,s))is defined as The score is a content-based function for which any of the following alternatives could have been used: The score function Through score function, we are trying to calculate the similarity between the hidden states of the target and the source. Intuitively similar states in hidden and source refer to the same meaning but in different languages.  The connecting lines in Figure  4  represent the interdependent variables. For example 1. a(t) is dependent on h(t) and h_bar(s) 2. c(t) is dependent on a(t) and h_bar(s) 

 h_bar(t) is dependent on c(t) and h(t) 2. Local Attention As Global attention focus on all source side words for all target words, it is computationally very expensive and is impractical when translating for long sentences. To overcome this deficiency local attention chooses to focus only on a small subset of the hidden states of the encoder per target word. Local attention has the following steps which are different from what is present in global attention: 1. The model first generates an aligned position p(t) for each target word at time t. In contrast to the global attention model where we assume monotonic alignment, we learn aligned positions in local attention. In other words apart from learning translations you also learn if the order of translation is different from the source sentence (word 1 of the source could be word 4 in the translated sentence, hence we need to calculate this otherwise our similarity score will be all wrong as our attention will be focussed on a word in the source sentence which is not related to word 1 of source sentence). 2. The context vector (c(t)) is derived as a weighted average over the set of source hidden states within the window [p(t) -D, p(t)+D]; D is empirically selected. As compared to the global alignment vector local alignment vector a(t) is now fixed dimensional. Until now we have assumed that both the translated and source sentence are monotonically aligned. On the basis of this, we have a further differentiation of the local attention which is as follows : To favor alignment position p(t), we place a Gaussian distribution centered around p(t). This gives more weight to the position p(t). We modify our alignment weights as assumed to be the same) and local-p (where we calculate the p(t)). 

 Input-feeding Approach In the proposed attention mechanisms the attention decisions are made independently (previously predicted alignments does not influence next alignment) which is suboptimal. In order to make sure that future alignment decisions take into consideration past alignment information h_bar(t) is concatenated with inputs at the next time steps as illustrated. This is done so as to: Neural Machine Translation | by Abhishek Sharma | Towards Data Science https://towardsdatascience.com/attention-based-neural-machine-translation-b5d129742e2c 2/7 

 the decoder has access only to the last layer of the encoder] On the other hand, attention-based networks refer to a set of source hidden states S throughout the translation process. [In Figure 2the decoder has access to all the hidden states of the encoder] Types of attention mechanism Open in app 07/02/2022, 17:32 Attention-based Neural Machine Translation | by Abhishek Sharma | Towards Data Science https://towardsdatascience.com/attention-based-neural-machine-translation-b5d129742e2c 3/7 

 Figure 2 : 2 Figure 2: NMT with attention and input-feeding approach 

 Figure 3 : 3 Figure 3: Hidden state of NMT architecture with global attention 

 the context vector c(t) calculated differently in local and global attention and what are the repercussions of it. 

 Neural Machine Translation | by Abhishek Sharma | Towards Data Science https://towardsdatascience.com/attention-based-neural-machine-translation-b5d129742e2c 5/7 

 Figure 4 : 4 Figure 4: Global attentional model: At each time step t, the model infers a variable-length alignment weight vector a(t) based on the current target state h(t) and all source states h_bar(s). A global context vector,c(t) is then computed asthe weighted average, according to a(t), over all the source states. 

 1. Monotonic Alignment( local-m ) Set p(t)=t, which means that we are assuming that source and target sequences are roughly monotonically aligned. Alignment vector is the same as the global alignment Open in app 07/02/2022, 17:32 Attention-based Neural Machine Translation | by Abhishek Sharma | Towards Data Science https://towardsdatascience.com/attention-based-neural-machine-translation-b5d129742e2c 6/7 Local alignment is the same as that of global alignment 2. Predictive alignment ( local-p ) Instead of assuming monotonic alignments, our model predicts an aligned position as follows: Alignment Position for local-p model W(p) and v(p) are models parameters which will be learned to predict positions. S is the source sentence length p(t): [0,S] 

 Alignment vector for local-p model to capture the same. To summarise, global attention is computationally more expensive and is useless for long sentences while local attention focusses on D hidden states on both sides of p(t) to overcome this. Local attention has 2 flavors local-m (the source and target alignment are
