title
GWLAN : General Word-Level AutocompletioN for Computer -Aided Translation
abstract
Computer-aided translation ( CAT ) , the use of software to assist a human translator in the translation process , has been proven to be useful in enhancing the productivity of human translators .
Autocompletion , which suggests translation results according to the text pieces provided by human translators , is a core function of CAT .
There are two limitations in previous research in this line .
First , most research works on this topic focus on sentence - level autocompletion ( i.e. , generating the whole translation as a sentence based on human input ) , but word - level autocompletion is under-explored so far .
Second , almost no public benchmarks are available for the autocompletion task of CAT .
This might be among the reasons why research progress in CAT is much slower compared to automatic MT .
In this paper , we propose the task of general word- level autocompletion ( GWLAN ) from a real-world CAT scenario , and construct the first public benchmark 1 to facilitate research in this topic .
In addition , we propose an effective method for GWLAN and compare it with several strong baselines .
Experiments demonstrate that our proposed method can give significantly more accurate predictions than the baseline methods on our benchmark datasets .
Introduction Machine translation ( MT ) has witnessed great advancements with the emergence of neural machine translation ( NMT ) ( Sutskever et al. , 2014 ; Bahdanau et al. , 2015 ; Wu et al. , 2016 ; Gehring et al. , 2017 ; Vaswani et al. , 2017 ) , which is able to produce much higher quality translation results than statistical machine translation ( SMT ) models ( Koehn et al. , 2003 ; Chiang , 2005 ; Koehn , 1 The information of benchmark datasets is in https : //github.com/ghrua/gwlan
We asked two sp Wir haben die Meinung von zwei Fach?rzten eingeholt .
We asked two experts for their opinion .
We sp their opinion . 2009 ) .
In spite of this , MT systems cannot replace human translators , especially in the scenarios with rigorous translation quality requirements ( e.g. , translating product manuals , patent documents , government policies , and other official documents ) .
Therefore , how to leverage the pros of MT systems to help human translators , namely , Computer-aided translation ( CAT ) , attracts the attention of researchers ( Barrachina et al. , 2009 ; Green et al. , 2014 ; Knowles and Koehn , 2016 ; Santy et al. , 2019 ) .
Among all CAT technologies ( such as translation memory , terminology management , sample sentence search , etc. ) , autocompletion plays an important role in a CAT system in enhancing translation efficiency .
Autocompletion suggests translation results according to the text pieces provided by human translators .
We note two limitations in previous research on the topic of autocompletion for CAT .
First , most of previous studies aim to save human efforts by sentence - level autocompletion ( Figure 1 a ) .
Nevertheless , word- level autocompletion ( Figure 1 b and c ) has not been systematically studied .
Second , almost no public benchmarks are available for the autocompletion task of CAT .
Although some achievements have been made , research progress in CAT is more sluggish than that in automatic MT .
The lack of benchmarks has hindered researchers from making continuous progress in this area .
In this work , we propose a General Word -Level AutocompletioN ( GWLAN ) task , and construct a benchmark with automatic evaluation to facilitate further research progress in CAT .
Specifically , the GWLAN task aims to complete the target word for human translators based on a source sentence , translation context as well as human typed characters .
Compared with previous work , GWLAN considers four most general types of translation context : prefix , suffix , zero context , and bidirectional context .
Besides , as in most real world scenarios , we only know the relative position between input words and the spans of translation context in the GWLAN task .
We construct a benchmark for the task , with the goal of supporting automatic evaluation and ensuring a convenient and fair comparison among different methods .
The benchmark is built by extracting triples of source sentences , translation contexts , and human typed characters from standard parallel datasets .
Accuracy is adopted as the evaluation metric in the benchmark .
To address the variety of context types and weak position information issue , we propose a neural model to complete a word in different types of context as well as a joint training strategy to optimize its parameters .
Our model can learn the representation of potential target words in translation and then choose the most possible word based on the human input .
Our contributions are two -fold : ?
We propose the task of general word-level autocompletion for CAT , and construct the first public benchmark to facilitate research in this topic . ?
We propose a joint training strategy to optimize the model parameters on different types of contexts together .
2
Related Work Computer-aided translation ( CAT ) is a widely used practice when using MT technology in the industry .
As the the MT systems advanced and improved , various efficient interaction ways of CAT have emerged ( Vasconcellos and Le?n , 1985 ; Green et al. , 2014 ; Hokamp and Liu , 2017 ; Weng et al. , 2019 ; Wang et al. , 2020 ) .
Among those different methods , the autocompletion is the most related to our work .
Therefore , we will first describe previous works in both sentence - level and word-level autocompletion , then show the relation to other tasks and scenarios .
Sentence-level Autocompletion
Most of previous work in autocompletion for CAT focus on sentence - level completion .
A common use case in this line is interactive machine translation ( IMT ) ( Green et al. , 2014 ; Cheng et al. , 2016 ; Peris et al. , 2017 ; Knowles and Koehn , 2016 ; Santy et al. , 2019 ) . IMT systems utilize MT systems to complete the rest of a translation after human translators editing a prefix translation ( Alabau et al. , 2014 ; Zhao et al. , 2020 ) .
For most IMT systems , the core to achieve this completion is prefix -constrained decoding ( Wuebker et al. , 2016 ) .
Another sentence - level autocompletion method , lexically constrained decoding ( LCD ) ( Hokamp and Liu , 2017 ; Post and Vilar , 2018 ) , recently attracts lots of attention ( Hasler et al. , 2018 ; Susanto et al. , 2020 ; Kajiwara , 2019 ) .
Compared with IMT , LCD relaxes the constraints provided by human translators from prefixes to general forms : LCD completes a translation based on some unordered words ( i.e. , lexical constraints ) , which are not necessary to be continuous ( Hokamp and Liu , 2017 ; Hu et al. , 2019 ; Dinu et al. , 2019 ; Song et al. , 2019 ) .
Although it does not need additional training , its inference is typically less efficient compared with the standard NMT .
Therefore , other works propose efficient methods Song et al. , 2019 ) by using lexical constraints in a soft manner rather than a hard manner as in LCD .
Word-level Autocompletion Word-level autocompletion for CAT is less studied than sentencelevel autocompletion .
Langlais et al . ( 2000 ) ; Santy et al. ( 2019 ) consider to complete a target word based on human typed characters and a translation prefix .
But they require the target word to be the next word of the translation prefix , which limits its application .
In contrast , in our work the proposed word- level autocompletion is more general and can be applied to real-world scenarios such as post-editing ( Vasconcellos and Le?n , 1985 ; Green et al. , 2013 ) and LCD , where human translators need to input some words ( corrections or constraints ) .
Huang et al. ( 2015 ) propose a method to predict a target word based on human typed characters , however , this method only uses the source side information and does not consider translation context , leading to limited performance compared with our work .
Others
Our work may also be related to previous works in input method editors ( IME ) ( Huang et al. , 2018 ; Lee et al. , 2007 ) .
However , they are in the monolingual setting and not capable of using the useful multilingual information .
Task and Benchmark
In this section , we first describe why we need wordlevel autocompletion in real-world CAT scenarios .
We then present the details of the GWLAN task and the construction of benchmark .
Why GWLAN ?
Word level autocompletion is beneficial for improving input efficiency ( Langlais et al. , 2000 ) .
Previous works assume that the translation context should be a prefix and the desired word is next to the prefix as shown in Figure 1 ( b ) , where the context is " We asked two " and the desired word is " specialists " .
However , in some real- world CAT scenarios such as post-editing and lexically constrained decoding , translation context may be discontinuous and the input words ( corrections or lexical constraints ) are not necessarily conjunct to the translation context .
As shown in Figure 1 ( c ) , the context is " We ? ? ? their opinion " and the human typed characters " sp " is conjunct to neither " We " nor " their " in the context .
Therefore , existing methods can not perform well on such a general scenario .
This motivates us to propose a general word-level autocompletion task for CAT .
Task Definition Suppose x = ( x 1 , x 2 , . . . , x m ) is a source sequence , s = ( s 1 , s 2 , . . . , s k ) is a sequence of human typed characters , and a translation context is denoted by c = ( c l , c r ) , where c l = ( c l,1 , c l,2 , . . . , c l , i ) , c r = ( c r,1 , c r,2 , . . . , c r , j ) .
The translation pieces c l and c r are on the left and right hand side of s , respectively .
Formally , given a source sequence x , typed character sequence s and a context c , the general word- level autocompletion ( GWLAN ) task aims to predict a target word w which is to be placed in the middle be-tween c l and c r to constitute a partial translation .
Note that in the partial translation consisting of c l , w and c r , w is not necessary to be consecutive to c l, i or c r,1 .
For example , in Figure 1 ( c ) , c l = ( " We " , ) , c r = ( " their " , " option " , " . " ) , s = ( " sp " , ) , the GWLAN task is expected to predict w = " specialists " to constitute a partial translation " We ? ? ? specialists ? ? ? their opinion . " , where " ?
? ? " represents zero , one , or more words ( i.e. , the two words before and after it are not necessarily consecutive ) .
To make our task more general in real-world scenarios , we assume that the left context c l and right context c r can be empty , which leads to the following four types of context : ?
Zero-context : both c l and c r are empty ; ? Suffix : c l is empty ; ? Prefix : c r is empty ; ?
Bi-context : neither c l nor c r is empty .
With the tuple ( x , s , c ) , the GWLAN task is to predict the human desired word w .
Relation to most similar tasks Some similar techniques have been explored in CAT .
Green et al. ( 2014 ) and Knowles and Koehn ( 2016 ) studied a autocompletion scenario called translation prediction ( TP ) , which provides suggestions of the next word ( or phrase ) given a prefix .
Besides the strict assumption of translation context ( i.e. , prefix here ) , compared with GWLAN , another difference is that the information of human typed characters is ignored in their setting .
There also exist some works that consider the human typed sequences ( Huang et al. , 2015 ; Santy et al. , 2019 ) , but they only consider a specific type of translation contexts .
Huang et al. ( 2015 ) propose to complete a target word based on the zero-context assumption .
Despite its flexibility , this method is unable to explore translation contexts to improve the autocompletion performance .
The word-level autocompletion methods in Langlais et al . ( 2000 ) ; Santy et al. ( 2019 ) have the same assumption as TP , which impedes the use of their methods under the scenarios like post editing and lexically constrained decoding , where human inputs are not necessarily conjunct to the variety of translation contexts .
Benchmark Construction
To set up a benchmark , firstly we should create a large scale dataset including tuples of ( x , s , c , w ) for training and evaluating GWLAN models .
Ideally , we may hire professional translators to man-ually annotate such a dataset , but it is too costly in practice .
Therefore , in this work , we propose to automatically construct the dataset from parallel datasets which is originally used in automatic machine translation tasks .
The procedure for constructing our data is the same for train , validation , and test sets .
And we construct a dataset for each type of translation context .
Assume we are given a parallel dataset {( x i , y i ) } , where y i is the reference translation of x i .
Then , we can automatically construct the data c i and s i by randomly sampling from y i .
We first sample a word w = y i k and then demonstrate how to extract c i for different translation contexts : ?
Zero-context : both c l and c r are empty ; ?
Suffix : randomly sample a translation piece c r = y p r,1 :p r,2 from y , where k < p r,1 < p r,2 .
The c l is empty here ; ?
Prefix : randomly sample a translation piece c l = y p l,1 :p l,2 from y , where p l,1 < p l,2 < k .
The c r is empty here ; ?
Bi-context : sample c l as in prefix , and sample c r as in suffix .
Then we have to simulate the human typed characters s based on w .
For languages like English and German , we sample a position p from the character sequence and the human input s = w 1 :p , where 1 ? p < L w .
For languages like Chinese , the human input is the phonetic symbols of the word , since the word cannot be directly typed into the computer .
Therefore , we have to convert w to phonetic symbols that are characters in alphabet and sample s from phonetic symbols like we did on English .
Evaluation Metric
To evaluate the performance of the well - trained models , we choose accuracy as the evaluation metric : Acc = N match N all , ( 1 ) where N match is the number of words that are correctly predicted and N all is the number of testing examples .
Proposed Approach Given a tuple ( x , c , s ) , our approach decomposes the whole word autocompletion process into two parts : model the distribution of the target word w based on the source sequence x and the translation context c , and find the most possible word w based on the distribution and human typed sequence s.
Therefore , in the following subsections , we firstly propose a word prediction model ( WPM ) to define the distribution p( w|x , c ) of the target word w ( ?4.1 ) .
Then we can treat the human input sequence s as soft constraints or hard constraints to complete s and obtain the target word w ( ?4.2 ) .
Finally , we present two strategies for training and inference ( ?4.3 ) .
Word Prediction Model
The purpose of WPM is to model the distribution p( w|x , c ) .
More concretely , we will use a single placeholder [ MASK ] to represent the unknown target word w , and use the representation of [ MASK ] learned from WPM to predict it .
Formally , given the source sequence x , and the translation context c = ( c l , c r ) , the possibility of the target word w is : P ( w|x , c l , c r ; ? ) = softmax ( ?( h ) ) [ w ] ( 2 ) where h is the representation of [ MASK ] , ? is a linear network that projects the hidden representation h to a vector with dimension of target vocabulary size V , and softmax ( d ) [ w ] takes the component regarding to w after the softmax operation over a vector d ?
R V . Inspired by the attention - based architectures ( Vaswani et al. , 2017 ; Devlin et al. , 2019 ) 3 , we < l a t e x i t s h a 1 _ b a s e 6 4 = " D + T g s s L d 7 use a dual-encoder architecture to learn the representation h based on source sequence x and translation context c.
Our model has a source encoder and a cross-lingual encoder .
The source encoder of WPM is the same as the Transformer encoder , which is used to encode the source sequence x .
As shown in Figure 2 , the output of source encoder will be passed to the cross-lingual encoder later .
The cross-lingual encoder is similar to the Transformer decoder , while the only difference is that we replace the auto-regressive attention ( ARA ) layer by a bidirectional masked attention ( BMA ) module , due to that the ARA layer cannot use the leftward information flow ( i.e. , c r ) .
Specifically , the BMA module is built by a multiple - layer self attention network .
As shown in Figure 3 , in each layer of BMA , each token in the attention query can attend to all words in translation context c l and c r .
In addition , the input consists of three parts , the [ MASK ] token , and translation contexts c l and c r , as illustrated in Figure 3 .
Note that its position embeddings E are only used to represent the relative position relationship between tokens .
Taking the sentence in Figure 3 as an example , E 3 does not precisely specify the position of the target word w but roughly indicates that w is on the right - hand - side of c l and on the left- hand - side of c r .
Finally , the representation of [ MASK ] as learnt by BMA will be passed to Add & Norm layer as shown in Figure 2 . E the E 1 the E aircraft E 2 aircraft E [ MASK ] E 3 [ MASK ]
E rapidly E 4 rapidly E [ EOS ] E 5 [ EOS ] E [ SOS ] E 0 [ SOS ] < l a t e x i t s h a 1 _ b a s e 6 4 = " c X N t n B I N X c m w h k w K N 8 r h F M u 8 C H E = " > A A A B 7 X i c b V D L S s N A F L 3 x W e u r 6 t L N Y B F c l U Q U X R b d u K x g H 9 C G M p l O 2 r G T S Z i 5 E U r o P 7 h x o Y h b / 8 e d f + O k z U J b D w w c z r m H u f c E i R Q G X f f b W V l d W 9 / Y L G 2 V t 3 d 2 9 / Y r B 4 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 N v f b T 1 w b E a s H n C T c j + h Q i V A w i l Z q 9 Q Y x m n K / U n V r 7 g x k m X g F q U K B R r / y Z Y M s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 7 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P Z t l N y a p U B C W N t n 0 I y U 3 8 n M h o Z M 4 k C O x l R H J l F L x f / 8 7 o p h t d +
J l S S I l d s / l G Y S o I x y U 8 n A 6 E 5 Q z m x h D I t 7 K 6 E j a i m D G 1 B e Q n e 4 s n L p H V e 8 y 5 r 7 v 1 F t X 5 T 1 F G C Y z i B M / D g C u p w B w 1 o A o N H e I Z X e H N i 5 8 V 5 d z 7 m o y t O k T m C P 3 A + f w A o 8 4 7 a < / l a t e x i t > . . . aircraft [ MASK ] < l a t e x i t s h a 1 _ b a s e 6 4 = " c X N t n B I N X c m w h k w K N 8 r h F M u 8 C H E = " > A A A B 7 X i c b V D L S s N A F L 3 x W e u r 6 t L N Y B F c l U Q U X R b d u K x g H 9 C G M p l O 2 r G T S Z i 5 E U r o P 7 h x o Y h b / 8 e d f + O k z U J b D w w c z r m H u f c E i R Q G X f f b W V l d W 9 / Y L G 2 V t 3 d 2 9 / Y r B 4 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 N v f b T 1 w b E a s H n C T c j + h Q i V A w i l Z q 9 Q Y x m n K / U n V r 7 g x k m X g F q U K B R r / y Z Y M s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 7 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P Z t l N y a p U B C W N t n 0 I y U 3 8 n M h o Z M 4 k C O x l R H J l F L x f / 8 7 o p h t d +
J l S S I l d s / l G Y S o I x y U 8 n A 6 E 5 Q z m x h D I t 7 K 6 E j a i m D G 1 B e Q n e 4 s n L p H V e 8 y 5 r 7 v 1 F t X 5 T 1 F G C Y z i B M / D g C u p w B w 1 o A o N H e I Z X 3 3 / B o E 2 H y i H b 5 f O J z Y = " > A A A B + X i c b V D L S g M x F L 1 T X 7 W + R l 2 6 C R b B V Z k R R Z d F N y 4 r 2 A e 0 w 5 D J p G 1 o J h m S T K E M / R M 3 L h R x 6 5 + 4 8 2 / M t L P Q 6 o G Q w z n 3 k p M T p Z x p 4 3 l f T m V t f W N z q 7 p d 2 9 n d 2 z 9 w D 4 8 6 W m a K 0 D a R X K p e h D X l T N C 2 Y Y b T X q o o T i J O u 9 H k r v C 7 U 6 o 0 k + L R z F I a J H g k 2 J A R b K w U u u 4 g k j z W s 8 R e O Z m H P H T r X s N b A P 0 l f k n q U K I V u p + D W J I s o c I Q j r X u +
1 5 q g h w r w w i n 8 9 o g 0 z T F Z I J H t G + p w A n V Q b 5 I P k d n V o n R U C p 7 h E E L 9 e d G j h N d h L O T C T Z j v e o V 4 n 9 e P z P D m y B n I s 0 M F W T 5 0 D D j y E h U 1 I B i p i g x f G Y J J o r Z r I i M s c L E 2 L J q t g R / 9 c t / S e e i 4 V 8 1 v I f L e v O 2 r K M K J 3 A K 5 + D D N T T h H l r Q B g J T e I I X e H V y 5 9 l 5 c 9 6 X o x W n 3 D m G X 3 A + v g E 2 j J Q I < / l a t e x i t > c l < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 H S M d S V D z V Y I d s c r q x Y h O 4 B 4 R y U = " > A A A B + X i c b V D L S g M x F L 1 T X 7 W + R l 2 6 C R b B V Z k R R Z d F N y 4 r 2 A e 0 w 5 D J p G 1 o J h m S T K E M / R M 3 L h R x 6 5 + 4 8 2 / M t L P Q 6 o G Q w z n 3 k p M T p Z x p 4 3 l f T m V t f W N z q 7 p d 2 9 n d 2 z 9 w D 4 8 6 W m a K 0 D a R X K p e h D X l T N C 2 Y Y b T X q o o T i J O u 9 H k r v C 7 U 6 o 0 k + L R z F I a J H g k 2 J A R b K w U u u 4 g k j z W s 8 R e O Z m H K n T r X s N b A P 0 l f k n q U K I V u p + D W J I s o c I Q j r X u +
1 5 q g h w r w w i n 8 9 o g 0 z T F Z I J H t G + p w A n V Q b 5 I P k d n V o n R U C p 7 h E E L 9 e d G j h N d h L O T C T Z j v e o V 4 n 9 e P z P D m y B n I s 0 M F W T 5 0 D D j y E h U 1 I B i p i g x f G Y J J o r Z r I i M s c L E 2 L J q t g R / 9 c t / S e e i 4 V 8 1 v I f L e v O 2 r K M K J 3 A K 5 + D D N T T h H l r Q B g J T e I I X e H V y 5 9 l 5 c 9 6 X o x W n 3 D m G X 3 A + v g E / p J Q O < / l a t e x i t > c r
Human Input Autocompletion
After learning the representation h of the [ MASK ] token , there are two ways to use the human input sequence s to determinate the human desired word .
Firstly , we can learn the representation of s and use it as a soft constraint while predicting word w .
Taking the sentence in Figure 3 as an example , supposing the human typed sequence is s = " des " , we can use an RNN network to learn the representation of des and concatenate it with h to predict the word descending .
Alternatively , we can use des as a hard constraint : P s [ w ] = P ( w| x , c ; ? )
Z , if w starts with s 0 , otherwise .
where P ( ?|? ) is the probability distribution defined in Eq. ( 2 ) and Z is the normalization term independent on w .
Then we pick w * = arg max w P s [ w ] as the most possible word .
In our preliminary experiments , the performances of these two methods are comparable , and there is no significant gain when we use them together .
One main reason is that the model can already learn the starts - with action precisely in the soft constraint method .
Therefore , we propose to use the human inputs as hard constraints in our later experiments , because of the method 's efficiency and simplicity .
Training and Inference Strategy Suppose D denotes the training data for GWLAN , i.e. , a set of tuples ( x , c , s , w ) .
Since there are four different types of context in D as presented in ?3 , we can split D into four subsets D zero , D prefix , D suffix and D bi .
To yield good performances on those four types of translation context , we also propose two training strategies .
The inference strategy differs accordingly .
Strategy 1 : One Context Type One Model
For this strategy , we will train a model for each translation context , respectively .
Specifically , for each type of context t ?
{zero , prefix , suffix , bi} , we independently train one model ?
t by minimizing the following loss L( D t , ? ) : L( D t ; ? ) = 1 | D t | ( x , c , s , w ) ?
Dt log P ( w|x , c ; ? ) , ( 3 ) where P ( w|x , c ; ? ) is the WPM model defined in Eq. 2 , | D t | is the size of training dataset D t , and t can be any type of translation context .
In this way , we actually obtain four models in total after training .
In the inference process , for each testing instance ( x , c l , c r , s ) , we decide its context type t in terms of c l and c r and then use ?t to predict the word w .
Strategy 2 : Joint Model
The separate training strategy is straightforward .
However , it may also make the models struck in the local optimal .
To address these issues , we also propose a joint training strategy , which has the ability to stretch the model out of the local optimal once the parameters is over-fitting on one particular translation context .
Therefore , using the joint training strategy , we train a single model for all types of translation context by minimizing the following objective : L( D ; ? ) = L( D zero ; ? ) + L( D prefix ; ? ) +
L( D suffix ; ? ) + L( D bi ; ? ) where each L( D t ; ? ) is as defined in Eq. 3 .
In this way , we actually obtain a single model ? after training .
In the inference process , for each testing instance ( x , c l , c r , s ) we always use ? to predict the target word w .
Experiments
Datasets
We carry out experiments on four GWLAN tasks including bidirectional Chinese -English tasks and German-English tasks .
The benchmarks for our experiments are based on the public translation datasets .
The training set for two directional Chinese -English tasks consists of 1.25 M bilingual sentence pairs from LDC corpora .
The toolkit we used to convert Chinese word w to phonetic symbols is pypinyin 4 . As discussed in ( ?3.2 ) , the training data for GWLAN is extracted from 1.25 M sentence pairs .
The validation data for GWLAN is extracted from NIST02 and the test datasets for GWLAN are constructed from NIST05 and NIST06 .
For two directional German-English tasks , we use the WMT14 dataset preprocessed by Stanford 5 .
The validation and test sets for our tasks are based on newstest13 and newstest14 respectively .
For each dataset , the models are tuned and selected based on the validation set .
The main strategies we used to prepare our benchmarks are shown in ?3.2 .
However , lots of trivial instances may be included if we directly use the uniform distribution for sampling , e.g. , predicting word " the " given " th " .
Therefore , we apply some intuitive rules to reduce the probability of trivial instances .
For example , we assign higher probability for words with more than 4 characters in English and 2 characters in Chinese , and we require that the lengths of input character sequence s and translation contexts c should not be too long .
Systems for Comparison
In the experiments , we evaluate and compare the performance of our methods ( WPM - Sep and WPM - Joint ) and a few baselines .
They are illustrated below , WPM - SEP is our approach with the " one context one model " training and inference strategy in Section ?4.3 .
In other words , we train our model for each translation context separately .
WPM - JOINT is our approach with the " joint model " strategy in Section ?4.3 .
TRANSTABLE : We train an alignment model 6 on the training set and build a word-level translation table .
While testing , we can find the translations of all source words based on this table , and select out valid translations based on the human input .
The word with highest frequency among all candidates is regarded as the prediction .
This baseline is inspired by Huang et al . ( 2015 )
TRANS -PE : We train a vanilla NMT model using the Transformer - base model .
During the inference process , we use the context on the left hand side of human input as the model input , and return the most possible words based on the probability of valid words selected out by the human input .
This baseline is inspired by Langlais et al . ( 2000 ) ; Santy et al. ( 2019 ) .
TRANS - NPE : As another baseline , we also train an NMT model based on Transformer , but without position encoding on the target side .
While testing , we use the averaged hidden vectors of all the target words outputted by the last decoder layer to predict the potential candidates .
Main Results
Table 1 shows the main results of our methods and three baselines on the test sets of Chinese -English and German - English datasets .
It is clear from the results that our methods WPM - SEP and WPM - JOINT significantly outperform the three baseline methods .
Results on Row 4 and Row 5 of Table 1 also show that the WPM - JOINT method , which uses a joint training strategy to optimize a single model , achieves better overall performance than WPM - SEP , which trains four models for different translation contexts respectively .
In - depth analysis about the two training strategies is presented in the next section .
The method TRANS - PE , which assumes the human input is the next word of the given context , behaves poorly under the more general setting .
As the results of TRANS - NPE show , when we use the same model as TRANS - PE and relax the constraint of position by removing the position encoding , the accuracy of the model improves .
One interesting finding is that the TRANSTABLE method , which is only capable of leveraging the zero-context , achieves good results on the Chinese - English task when the target language is English .
However , when the target language is Chinese , the performance of TRANSTABLE drops significantly .
6 Experimental Analysis
Effects on Different Translation Context
In this section , we presents more detailed results on the four translation contexts and analyze the features of GWLAN .
These analyses can help us to better understand the task and propose effective approaches in the future .
Separate Training VS .
Joint Training Compared with WPM - SEP , WPM - JOINT shows two advantages .
On one hand , even there is only one model , WPM - JOINT yields better performances than WPM - SEP , enabling simpler deployment .
This may be caused by that training on multiple related tasks can force the model learn more expressive representations , avoiding over-fitting .
On the other hand , the variance of results on different translation contexts of WPM - JOINT is smaller , which can provide an more steady autocompletion service .
From the viewpoint of joint training , the lower variance may be caused by that WPM - JOINT spends more efforts to minimize the one with maximal risk ( i.e. , zero-context ) , although sometimes it may slightly sacrifice the task with minimal risk ( i.e. , bi-context ) .
The results of WPM - SEP and WPM - JOINT also have some shared patterns .
Firstly , the performances of the two methods on prefix and suffix translation contexts are nearly the same .
Although the prefix and suffix may play different roles in the SVO language structure , they have little impact on the the autocompletion accuracy using our method .
Moreover , among the results on four translation contexts , the performances on bi-context are better than prefix and suffix , and prefix and suffix are better than zero-context .
This finding shows that more context information can help to reduce the uncertainty of human desired words .
Comparison with baselines
The TRANS - PE method in previous works is more sensitive to the position of human input .
The statistical results shows that the averaged distances in the original sentence between the prediction words and translation contexts are various for different translation contexts , which are 7.4 , 6.5 , 14.1 , and 3.2 for prefix , suffix , zero-context , and bi-context , respectively .
When the desired words are much closer to the context , TRANS - PE can achieve better performances .
Moreover , TRANS - PE can achieve more than 80 accuracy scores when the prediction word is the next word of the given prefix , however , its performance drops significantly when the word is not necessarily conjunct to the prefix .
We can also find that TRANS - NPE , which removes the position information of target words , achieves better overall performances compared with TRANS - PE .
In contrast , the performance of TRANSTABLE is less affected by the position of the prediction words , which is demonstrated by the low variances on both tasks in Table 2 .
The results of TRANSTA - BLE have also surprised us , which achieves more than 41 accuracy scores on the Zh?En task .
This observation shows the importance of alignment and the potential of statistical models .
Compared with the results on the Zh?En task , the overall accu- racy on En? Zh task is much lower , likely due to that the number of valid words after filtered by the human input on Chinese is much more than that on English .
Therefore , it is easier for TRANSTABLE to determine the human desired words in English .
Robustness on Noisy Contexts
In this work , the translation contexts are simulated using the references .
However , in real-world scenarios , translation contexts may not be perfect , i.e. , some words in the translation contexts may be incorrect .
In this section , we evaluate the robustness of our model on noisy contexts .
We first use the translation table constructed by TRANSTABLE to find some target words that share the same source words with the original target words , and then use those found words as noise tokens .
The robustness results are shown in Figure 4 .
For all the translation context types except for zerocontext , the performance drops slowly when the percentage of noise tokens increases .
However , even with 80 % words in the context , the performance of WPM - JOINT outperforms the case of zero-context , which shows that our WPM - JOINT method is noise tolerant .
Discussion
In this work , we formalize the task as a classification problem .
However , the generation formalization also deserves to be explored in the future .
For example , the generation may happen in two circumstances : word- level completion based on subwords , and phrase -level completion .
In the first case , although the autocompletion service provided for human translators is word-level , in the internal system we can generate a sequence of subwords ( Sennrich et al. , 2015 ) that satisfy the human typed characters , and provide human translators with the merged subwords .
This subword sequence generation can significantly alleviate the OOV issue in the word-level autocompletion .
In the phrase-level autocompletion case , if we can predict more than one desired words , the translation efficiency and experience may be improved further .
We would like to leave it as future work .
It is also worth noting that we did not conduct human studies in this work .
We think evidences in previous work can already prove the effectiveness of word-level autocompletion when assisting human translators .
For example , TransType ( Langlais et al. , 2000 ) is a simple rule- based tool that only considers the prefix context , but the majority of translators said that TransType improved their typing speed a lot .
Huang et al. ( 2015 ) hired 12 professional translators and systematically evaluate their word autocompletion tool based on zero-context .
Experiments show that the more keystrokes are reduced , the more time can be saved for translators .
Since the prediction accuracy is highly correlated with the keystrokes , we think higher accuracy will make translators more productive .
That is the main reason that we use accuracy to automatically evaluate the model performance .
Besides , the automatic evaluation metric also makes the GWLAN task easier to follow .
Conclusion
We propose a General Word-Level Autocomple-tioN ( GWLAN ) task for computer - aided translation ( CAT ) .
In our setting , we relax the strict constraints on the translation contexts in previous work , and abstract four most general translation contexts used in real- world CAT scenarios .
We propose two approaches to address the variety of context types and weak position information issues in GWLAN .
To support automatic and to ensure a convenient and fair comparison among different methods , we construct a benchmark for the task .
Experiments on this benchmark show that our method outperforms baseline methods by a large margin on four datasets .
We believe that this benchmark to be released will push forward future research in CAT .
Figure 1 : 1 Figure 1 : Illustration of Different Autocompletion Methods .
The translation context is in red .
Sub-figure in ( a ) is the sentence - level autocompletion , where the gray part is the completion generated by MT system .
Both ( b ) and ( c ) are word - level autocompletion , underlined text " sp " is the human typed characters and the words in the rounded rectangles are word-level autocompletion candidates .
