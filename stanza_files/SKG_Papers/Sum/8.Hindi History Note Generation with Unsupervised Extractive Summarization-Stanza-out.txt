title
Hindi History Note Generation with Unsupervised Extractive Summarization
abstract
In this work , the task of extractive single document summarization applied to an education setting to generate summaries of chapters from grade 10 Hindi history textbooks is undertaken .
Unsupervised approaches to extract summaries are employed and evaluated .
Tex -tRank , LexRank , Luhn and KLSum are used to extract summaries .
When evaluated intrinsically , Luhn and TextRank summaries have the highest ROUGE scores .
When evaluated extrinsically , the effective measure of a summary in answering exam questions , TextRank summaries performs the best .
Introduction
Our task is to apply text summarization to generate notes for school students where the medium of instruction is Hindi .
The motivation for this work is that students studying under the Indian Central Board of Secondary Education ( CBSE ) have a lack of additional resources given their medium of instruction .
Online resources are limited , with most reference guide material being published in English .
Given the vast quantities of information that students are made to memorize , we believe that our tool will help provide students with an outline , a text summary , that could serve as both a big picture introduction and a pre-exam study guide .
We focus on this task as each year over 18 million students give the grade ten exam .
As Hindi is a low resource language , we believe that such a tool could help students learn better .
From prior research ( Verma et al. , 2019 ) on comparative text summarization in English and Hindi , we see that summarization results vary drastically for different languages and subject matters .
While extensive research has been done for summarization techniques in English ( Luhn , 1958 ; Edmundson , 1969 ; Carbonell and Goldstein , 1998 ; Pal and *
These authors contributed equally to this work .
Saha , 2014 ; Erkan and Radev , 2004 ) , directly applying said methods to Hindi text performs poorly ( Verma et al. , 2019 ) .
Frequency , graph and feature based approaches have been investigated previously to extract summaries from Hindi text and have shown to perform well on news documents ( Vijay et al. , 2017 ) .
Rule based methods ( Gupta and Garg , 2016 ) , and improvements to graph based methods incorporating semantic information from the text ( Kumar et al. , 2015 ) perform well for Hindi documents from various domains .
We wish to address the task of extractive text summarization in Hindi as it applies to learning history in an education setting for school students using unsupervised algorithms .
The main reason behind choosing unsupervised methods for this task is that these algorithms do not require a dedicated training set annotated by individuals with subject specific knowledge .
Secondly , employing a supervised approach for a particular domain constrains the portability of the trained model to be applied on different domains .
Furthermore , the efficiency or goodness of the generated summaries for a particular task rely on accurate and reliable human annotated summaries used for training .
To the best of our knowledge , there exists no work that addresses Hindi text summarization in the academic domain as a note generating tool for students .
This made it difficult to compare our approaches with existing work that deals with different domains of text data .
In this work , we investigate unsupervised graph , term frequency and probability based single document summarization methods .
Our work will build on previous linguistic analyses ( for instance , no direct way to identify proper nouns ) in Hindi ( Paul et al. , 2013 ) to deal with the nuances of summarizing history written in Hindi ( Garg et al. , 2012 ) .
Our code is publicly available on GitHub 1 .
Materials
We used the grade 10 Hindi history textbook ( NCERT , 2018 ( NCERT , - 2019 prescribed by the CBSE and published by the National Council of Educational Research and Training ( NCERT ) as the dataset .
The Textbook is available in PDF format and is about 200 pages in length .
There are 8 chapters ( articles ) in the book .
Each chapter contains around 400 sentences comprising about 18 words each .
This amounts to approximately 7200 words per chapter .
To evaluate generated summaries , reference summaries of length 75 sentences are manually created for each chapter using the exact sentences from the textbook ( extractive summarization ) .
The annotators drafting the reference summaries are proficient in Hindi , have studied history at a high school level and are familiar with the course content and exam structure .
In order to perform an extrinsic evaluation , we considered questions from the three most recent exam papers , from 2017 - 2019 , and their corresponding rubrics 2 .
The exams contain 3 types of questions - very short answer questions ( 1 mark each ) , short answer questions ( 3 marks each ) and long answer questions ( 5 marks each ) requiring 1 , 3 and 5 sentences from the text respectively .
There are a total of 35 questions in these exam papers .
A sample very short question from the 2017 examination is as follows :
A student 's response that would score one full point is as follows :
Methodology
The basic idea behind the task of extractive summarization is that individual sentences in the source document are scored and ranked to extract the top n sentences as a summary .
In this work , four unsupervised methods are investigated to score and rank the input document sentences .
The methods used here are KLSum ( Aria and Vanderwende , 2009 ) , Luhn Summarization ( Luhn , 1958 ) , TextRank ( Mihalcea and Tarau , 2004 and LexRank ( Erkan and Radev , 2004 ) .
The summaries generated by these methods are evaluated and compared against each other intrinsically and extrinsically .
TextRank and LexRank are graph based approaches .
KLSum utilizes a probabilistic approach .
Luhn uses a naive ranking algorithm based on word significance .
KLSum Kullback - Leibler summarization ( KLSum ) ( Aria and Vanderwende , 2009 ) is a probabilistic take on the extractive summarization problem .
The basic idea here is to extract a summary , a set of sentences from the source document , whose unigram distribution is as close to the unigram distribution of the source document as possible .
The closeness between the source and summary document distributions is determined by the KL divergence ( Kullback and Leibler . , 1951 ) KL ( D| |S ) , where D ( w ) and S ( w ) are the unigram distributions of the word w in the source D and summary S document respectively . KL ( D| |S ) = w D ( w ) ( log ( D ( w ) ) ? log ( S ( w ) ) ( 1 )
The empirical unigram distribution of a document is the term frequency of words in the given document which is computed as :
Here , L is the maximum number of words in the summary S. Since optimizing the above objective is exponential in the number of sentences in the source document , a greedy approach is taken .
Starting with an empty summary , the summary is extracted iteratively .
At each iteration , the sentence which results in minimum KL ( D | |S ) is added to the summary until the intended number of sentences is reached .
Luhn Summarization Luhn summarization ( Luhn , 1958 ) is a simple and naive summarization algorithm where the relative significance of each sentence in the source document is considered for selection in the summary .
The basic idea exploited in this method is that an author of a document writing about a concept tends to repeat the same words to represent a specific notion .
When such significantly repeating words are positioned relatively closer in a document , within a sentence for example , the sentence as a whole becomes significant enough to be considered in a summary .
The relative significance of each sentence is captured with the number of significant words and their physical proximity within a sentence .
Each sentence is grouped into clusters beginning and ending with significant words .
These first and last significant words of clusters are significantly related if the physical distance between them , intervened by insignificant words , is under a threshold .
If more than one such cluster is found in a sentence , the cluster with the highest significance factor is assigned to the sentence .
The sentences are then ranked relative to the other to generate the summary .
Numerically , a word is considered significant if its term frequency is more than a specified threshold .
The significance factor of a cluster C in a sentence is computed as follows : Signif icance ( C ) = # of significant words in C # of words in C ( 4 )
TextRank TextRank ( Mihalcea and Tarau , 2004 ) is a graph based approach which scores sentences in the given document based on the PageRank ( Page et al. , 1999 ) algorithm .
The basic principle here is that sentences within the document recommend each other and the sentences with the highest recommendation scores are considered to be in the generated summary .
This involves constructing a graphical representation of the document , G ( V , E ) , where each sentence in the document is a vertex V linked to all other vertices through edges E in the undirected graph .
The edge between two vertices i and j are weighted by a similarity metric w ij to capture the recommendation between sentences s i and s j which is calculated as follows : wij = # of w k | w k si , sj log ( | si | ) + log ( | s j | ) ( 5 ) Here , w k are shared tokens between sentences s i and s j .
The PageRank algorithm is run on this constructed graph until convergence to find the importance of each vertex as per the update equation below .
W S( vi ) = ( 1 ? d ) + d v j ?In( v i ) wji v k ? Out ( v j ) w jk W S( vj ) ( 6 ) In the above equation , the importance score W S of vertex v i is a function of damping factor d , incoming edge weights to a given vertex v i , w ji , and importance score W S( v j ) of neighbouring vertex v j .
The vertices are ranked based on importance and the top n sentences from the document are taken as the summary .
LexRank Like TextRank , LexRank ( Erkan and Radev , 2004 ) is a graph based sentence scoring algorithm based on the PageRank algorithm .
However , LexRank differs in the way recommendations between sentences are computed .
wij = w s i , s j tfw , s i * tfw , s j * idf 2 w w s i ( tfw , s i idfw ) 2 w s j ( tfw , s j idfw ) 2 ( 7 ) tfw , s i = # of times the word w occurs in sentence si # of words in sentence si ( 8 ) idfw = log # of sentences in the document ( 1 + # of sentences with term w )
The similarity metric w ij , between sentences s i and s j , is the idf-modified -cosine similarity ( Erkan and Radev , 2004 ) computed between N dimensional vector representation of sentences .
N is the number of unique terms in the document .
For each word present in a sentence , the corresponding dimension in the N dimensional vector is set to the idf value of the word to construct the vector mapping of the sentence .
Results
The machine generated summaries are evaluated using intrinsic and extrinsic measures .
Intrinsic ( quantitative ) evaluation uses ROUGE score ( Lin , 2004 ) which is a recall based metric that compares similar n-grams in generated summaries against the handmade summaries .
It is found that ROUGE based evaluation correlates with human based evaluation in comparing machine generated summaries with ideal summaries ( Lin and Hovy , 2003 ) .
Hence , we consider ROUGE - 1 and ROUGE - 2 scores for this evaluation , which is the percentage of overlapping unigrams and bigrams respectively between the generated and handmade summaries .
The main idea of this work is to create a study / revision guide for students to help them understand the study material and do well on exams .
Hence , the ability to answer exam questions is an indicator of a good summary .
The Extrinsic ( qualitative ) evaluation measures how good the summary is in helping students perform well in the history exam .
This is carried out by going through the summaries generated by the above mentioned algorithms and making a decision on how many points can be scored on very short and short answer questions given only the sentences in the summary .
The scoring is done manually by human evaluators who refer to the examination grading rubric which is available online .
Length of the summary is an important factor to be considered when generating summaries .
The challenge is to balance recall and precision , i.e. to capture as much important information as possible from the whole document while avoiding the inclusion of superfluous information .
Such a summary with the right length should make for a faster and better learning experience for students .
Fig. 1 shows the relationship between the length of summary , in sentences , with respect to the shared unigrams with the reference summary .
While longer summaries have more overlap , the decrease in slope indicates that a decreasing percentage of added sentences match the reference .
Thus , 75 sentences was selected as the model summary length .
Intrinsic Evaluation Results
Table 1 describes the ROUGE scores of different algorithm generated summaries when compared to the human generated reference summaries .
We see Luhn based summaries have the highest ROUGE - 1 and ROUGE - 2 scores of 0.74 and 0.45 when compared to other algorithms .
In this case , ROUGE - 1 and ROUGE - 2 follow a similar distribution .
Extrinsic Evaluation Results
The generated summaries were evaluated based on their ability to answer questions on three years ' ( 2017 - 2019 ) history exam papers in Hindi .
We compare their exam scores with the baseline , the exam scores of the hand generated reference summaries .
This comparison is done by evaluators who have studied Hindi and history at a high school level while referring to the grading rubric provided by the CBSE board .
It is important to note that the full text is sufficient to answer all of the exam questions scoring 100 % .
The reference summaries scored 67.3 % outperforming summaries of Tex -tRank scoring 53.1 % , LexRank scoring 40.8 % , Luhn scoring 38.8 % and KLSum scoring 46.9 % as shown in Table 2 .
Discussion
When evaluated extrinsically on question answering ability , we see that human generated reference summaries are able to score better on exam questions when compared to machine generated summaries .
Among the unsupervised approaches , Tex -tRank scores the most on exam questions , 53.1 % .
Since TextRank is able to answer approximately 80 % of exam questions that the reference summaries answer , we believe that note generation by TextRank provides a good supplementary study tool for students .
We observed the impact of Hindi on the ROUGE metric .
The presence of stop words , ambiguous pronouns and other commonly used connecting terms in Hindi artificially raise the n-gram overlap without adding useful information .
For example , consider the two sentences below :
The two sentences have completely different meanings , sharing only subject , Gandhi in common .
The English sentences have two unigrams in common , ' Gandhi ' and ' the ' out of a total of thirteen unique unigrams , approximately a 15 % overlap .
On the other hand , the Hindi sentences have a total of five unigrams in common out of a total of fourteen unique unigrams , approximately a 36 % overlap .
This aspect of the Hindi language , with an abundance of connecting terms , would also raise the ROUGE metric of sentences which need not convey useful information .
We reevaluated the importance of the ROUGE score for the chosen task .
We notice that a good ROUGE score is not a good indicator of a summary 's ability to serve as a study aid .
This is evident from the extrinsic evaluation .
Luhn summarization , which has the highest ROUGE - 1 score ( 0.74 ) , performs poorly on the question answering task scoring only 38.8 % .
Conversely , KLSum having the lowest ROUGE - 1 score ( 0.39 ) performs better than Luhn summarization extrinsically , obtaining approximately 47 % .
This relationship between the ROUGE and exam scores of the summaries can be confirmed by the Spearman 's rho and Kendall 's tau coefficients ( Yue et al. , 2002 ) , which are - 0.4 and - 0.33 respectively .
The negative coefficients indicate a weak correlation between the summary 's ROUGE score and its question answering ability .
This shows that , in addition to ROUGE , it is important to formulate evaluation mechanisms that align with chosen application to evaluate machine generated summaries .
We noticed that machine generated summaries have sentences with ambiguous subjects .
While the algorithms may identify an important fact , it cannot attribute it to a subject .
Consider the following sentence :
When the machine generated summary contains only the second sentence it is able to answer the question " What caused the school rebellion ? " ( expelling the girl from school ) but cannot identify the subject ( school 's principal ) who carried out the action without the preceding sentence .
This is a structure we see often in Hindi where one sentence in English corresponds to two in Hindi .
In the English version of the text , the fact is stated as " The principal , also a colon , expelled her .
"
As the input text documents to the models were not pre-processed , we observed models treating the same entity differently .
For instance , the tokens Gandhi and Gandhi- ji .
The addition of an honorific suffix ' ji ' results in both terms being treated as different .
Since the rule of removing the suffix ' ji ' applies only to proper nouns , we cannot generalize this as a stemmer rule .
We believe that a TextRank based summarization tool would prove effective for other subjects whose exam questions test factual knowledge like Geography or Biology .
However , further testing is required before its portability can be validated .
Also , we believe the project would benefit from an Entity Recognizer , as a pre-processing step , to solve both ambiguous subjects problems and the ambiguity caused by the honorific suffixes in the summaries .
Nevertheless , we believe that this project represents a step in the right direction towards providing a note generation tool for students in Hindi medium schools .
tf t , d = # of times the term t occurs in document d Total # of terms in document d ( 2 ) Here , tf t ,d represents term t frequency in text document d .
The term frequencies are smoothened to ensure non-zero values .
Mathematically , the optimization problem is defined as below : S * = min S:words ( S ) ? L KL ( D | |S ) ( 3 )
Figure 1 : 1 Figure 1 : Overlapping unigrams vs summary length of generated summary .
Table 1 : 1 Intrinsic Evaluation : Comparison of ROUGE scores for LexRank , TextRank , Luhn and KLSum summaries compared against the reference summaries .
Algorithms ROUGE -1 ROUGE -2 LexRank 0.56 0.25 TextRank 0.72 0.44 Luhn 0.74 0.45 KLSum 0.39 0.17 Algorithms Exam scores LexRank 40.8 % TextRank 53.1 % Luhn 38.8 % KLSum 46.9 % Reference Summaries 67.3 %
Table 2 : 2 Extrinsic Evaluation : Comparison of exam scores for reference summaries , LexRank , TextRank , Luhn , and KLSum summaries .
Code : https://github.com/dhineshkumar-r/Unsupervised-Extractive-Summarization-Hindi-Note-Generation
NCERT Solutions : https://byjus.com/ncert-solutions/
