title
SWATAC : A Sentiment Analyzer using One-Vs-Rest Logistic Regression
abstract
This paper describes SWATAC , a system built for SemEval - 2015 's
Task 10 Subtask B , namely the Message Polarity Classification Task .
Given a tweet , the system classifies the sentiment as either positive , negative , or neutral .
Several preprocessing tasks such as negation detection , spell checking , and tokenization are performed to enhance lexical information .
The features are then augmented with external sentiment lexicons .
Classification is done with Logistic Regression using a one-vsrest configuration .
For the test runs , the system was trained using only the provided training tweets .
The classifier was successful , with an F1 score of 58.43 on the official 2015 test data , and an F1 score of 66.64 on the Twitter 2014 progress data .
Introduction Since 2006 , Twitter has grown into a ubiquitous global social platform .
Millions of users compose Twitter messages , which are known as " tweets " , to express their opinions and sentiments about the world around them .
These tweets turn into valuable resources for sentiment analysis , a field that focuses on analyzing the attitude of speakers or writers towards a certain topic .
Working with this informal text genre opens up a new realm of challenges in the natural language processing world .
This paper describes a tweet sentiment classifier which has been applied to Subtask B of SemEval - 2015 Task 10 ( Rosenthal et al. , 2015 .
The tweets generated by users contain Internet slang , unconventional punctu-ation and spelling , and typos , which require a different set of preprocessing tools than traditional genres like newswire text .
After preprocessing the tweets , classifying them into categories of positive , negative , and neutral presents another challenge .
Many sentiment applications make use of lexicons to supply features to the system , populating a list of positive and negative types .
Some publicly available sources include the MPQA Subjectivity Lexicon ( Wilson et al. , 2005 ) , the Opinion Lexicon ( Liu et al. , 2005 ) , and the Sentiment140 Lexicon ( Mohammad et al. , 2013 ) .
While some of these lexicons do not target tweets as their analysis subject , they each provide a mapping from n-grams to sentiment labels , which proves to be helpful in building our tweet sentiment analyzer .
After preprocessing , the system performs the classification task .
The classifier we use is a onevs-rest logistic regression classifier , so the system uses three binary classifiers : positive / notpositive , negative / not -negative , and neutral / notneutral .
The classifier also over-samples the lowfrequency classes , learning from the same number of examples of each class overall .
The accompanying sections of the papers are organized as follows : Section 2 describes resources such as the lexicons used in the system .
It also outlines the system design and the APIs that the system adopts .
Section 3 describes the test runs and evaluates the system .
Section 4 concludes the paper .
System Details
The main objective of our system is to determine if a tweet conveys a positive , negative , or neutral sentiment .
To achieve this goal , the system first employs some preprocessing tools to enhance the lexical information .
Then it relies on various sentiment lexicons to help with the classification of sentiments .
For preprocessing , the system performs casefolding , detects negation , optionally uses a spell checker , performs tokenization , and makes use of unigrams , bigrams , and pairs of n-grams .
In addition to features extracted from the tweets , the system relies on four external sentiment lexicons .
Three of them are pre-existing resources : the MPQA Subjectivity Lexicon ( Wilson et al. , 2005 ) , the Opinion Lexicon ( Liu et al. , 2005 ) , and the Sen-timent140 Lexicon ( Mohammad et al. , 2013 ) .
The final lexicon is a manually created Emoji lexicon compiled by the authors .
After extracting features , a Logistics Regression classifier using a one- vs- rest setup is used to label each of the tweets .
Preprocessing
Case Folding
We use case folding to make every letter of every word in both the training and the test data lowercase .
This helps in dimensionality reduction .
Negation Detector
The system includes a negation detector .
Similar to ( Pang et al. , 2002 ) , in this detector , we append a negation suffix to words that occur within a negation window between a negation key word and some punctuation .
For example , the word " great " , which is considered a positive word , is treated and learned as a different token if it is preceded by " not " as in " this pasta is not very great " .
This sentence would become " this pasta is not NOT_very NOT_great " .
Jazzy Jazzy is the Java Open Source Spell Checker 1 . Previous work had shown Jazzy to be effective ( Miura et al. , 2014 ) .
Though this was used during the development of the system , time constraints did n't allow its use in the final submission .
Using five - fold crossvalidation , including Jazzy improved performance slightly , from an F1 score of 63.8 to 64.75 .
Twokenizer
Twokenizer is a tokenizer designed specifically for tweets ( Gimpel et al. , 2011 ) .
Twokenizer properly handles the tokenization of tweets without mangling URLs , mentions , or hashtags .
Sentiment Lexicons
MPQA
We make use of the MPQA Subjectivity Lexicon ( Wilson et al. , 2005 ) .
The lexicon is generated from the MPQA Opinion Corpus , which incorporates a wide range of news articles manually annotated for opinions and other private states .
Although the MPQA lexicon list mainly targets news articles , it improved our system 's classifications .
The MPQA subjectivity lexicon provides a list of words with both their polarity ( positive , negative , and neutral ) and their strength ( strong subjective , weak subjective ) .
Our system made use of the polarity , but not the strength .
Opinion Lexicon
The Opinion Lexicon provided by Liu et al . ( 2005 ) consists of a list of positive words and a list of negative words .
Because the lexicon is automatically generated from social media content , it contains misspelled lemmas , which could be beneficial to tweet analysis as tweets tend to include erroneous spellings and Internet slang ( Liu , 2010 ) .
For example , we can find both words " awesome " and " awsome " in the list of positive words .
In the negative list , we find " awful " as well as " aweful " .
Sentiment140 Lexicon
The Sentiment140 - Lexicon is a list of features with associations to positive and negative sentiments ( Mohammad et al. , 2013 ) .
The lexicon was created from the automatically - labeled senti-ment 140 corpus of 1.6 million tweets .
The labeled features are unigrams , bigrams , and pairs of n-grams ( unigrams - unigrams , unigrams - bigrams , bigrams - unigrams , and bigrams - bigrams ) .
For example , some of the features we could see in the list are : the unigrams " @jeffery_donovan " and " xoxoxo " , the bigrams " yeh yeh " and " praise ! " , and the pairs " done-had " , " i- , drinking " , " thank youlovely " , and " good morning - can be " .
Each feature has a score that reflects how positive or negative the feature is .
If the word was seen in more positive contexts than negative contexts , it 's score is positive .
The magnitude of the score is highest when the distribution is overwhelmingly positive , and the magnitude is closest to zero when the word appears equally in both positive and negative contexts .
Negative words are scored similarly using negative values instead of positive values .
Emoji Lexicon
Our system uses a hand-created Emoji dictionary comprised of 16 positive 2 and 7 negative 3 emoticons .
Only the most common Emoji in the training set were added to the lexicon .
However , we chose to some exclude some emoticons because they portray a wide range of sentiments .
For example , emoticons like " :-| " and " :| " were seen in both neutral and negative tweets .
Using this specific set of emoticons improved the results when using cross-validation from an F1 score of around 62.5 to 64.8 .
A more extensive list might improve results , but given the time constraints , these 23 emoticons covered the test set adequately .
Classifier
Our system uses a one- vs-rest logistic regression classifier to analyze the sentiment of each tweet .
Before the tweets get passed to the classifier , an oversampling process takes place to ensure equal numbers of each sentiment class during training .
The classifier uses a one- vs-rest scheme , breaking down the classification process into three tasks : positive , negative , and neutral .
Our classification task assumes that each sample is assigned to one and only one label .
One-Vs-Rest
We use a one- vs-rest strategy , building a classifier for each sentiment label ( Hong and Cho , 2008 ) .
This means our system is comprised of three classifiers : positive / not -positive , negative / not - negative , and neutral / not-neutral .
For each classifier , the class is compared against all the other classes .
In other words , the features are screened to determine if they are positive , negative , or neutral in three separate stages : positive vs. non-positive , negative vs. nonnegative , and neutral vs. non-neutral .
During testing , each instance is labeled by each of the three classifiers .
When determining the label for a test instance , we would ideally like to have only one of the binary classifiers find a match .
This usually happens when a tweet has many features expressing the same sentiment .
However , when a tweet has contradicting features , the classifiers may contradict each either , either finding no matching class , or having multiple classifiers match a class .
In cases of uncertainty , we use the labeling returned by the classifier with the highest confidence .
Removing the one- vs- rest strategy decreases the score on crossvalidation from 64.8 to 64.0 .
Oversampling
In our classifier , we over-sample classes according to the number of examples we have in the training data .
This means no matter what the distribution of our underlying training data is , the system learns from an equal number of examples of each class label .
For example , if we have 100 negative instances in the training data and 200 non-negative instances , the negative instances would be sampled twice , whereas every non-negative example would be sampled only once .
This way , a negative feature that is seen once is twice as strong or informative to our system as a non-negative feature that is seen once , and it would have the same weight as a non-negative feature that had been seen twice .
This method decreased the system 's bias towards positive features .
Removing oversampling decreases the score on cross-validation from 64.8 to 62.3 .
Logistic Regression Model
The system uses the scikit-learn ( Pedregosa et al. , 2011 ) implementation of a Logistic Regression classifier .
In this system , we use a simple logistic regression , where the model has one nominal variable ( a class or non-class ) , and the features are used as measurement variables .
rithm , with a C value ( the inverse of regularization strength ) set to 1 , and the tolerance for stopping criteria set to 0.0001 , which are the default values provided by the scikit-learn library ( Pedregosa et al. , 2011 ) .
This system is stochastic and returns slightly different labellings on each run .
Using fivefold cross-validation , the final classifier had an F1 score between 64.0 and 65.0 .
The official results for our system are in Table 1 .
Our system has successfully scored a better than average F1 in all of the test sets , except for Twitter 2014 Sarcasm dataset .
The table compares our system to two other submitted systems :
Webis , the best scoring system on the Twitter 2015 dataset , Splusplus , the best scoring system on the Twitter 2014 progress test data , as well as the average scores of all submitted systems in each test data set .
Conclusion
This paper describes our submission to SemEval - 2015 's
Task 10 subtask B . Our system uses several preprocessing tools , which includes case folding , negation , and tokenization .
Several sentiment lexicons and a manually created Emoji lexicon are employed to help with classifying message polarities .
The system uses a logistic regression classifier along with a one- vs-rest scheme to perform a threestage classification .
The results indicate that our system generally performs well , with an F1 score of 58.43 on the 2015 test data .
Table 1 : 1 Official results comparing the SWATAC system to the best performing systems on the Twitter 2015 and Twitter 2014 datasets , as well as the average performance on each dataset .
Live
