title
Toward Comprehensive Understanding of a Sentiment Based on Human Motives
abstract
In sentiment detection , the natural language processing community has focused on determining holders , facets , and valences , but has paid little attention to the reasons for sentiment decisions .
Our work considers human motives as the driver for human sentiments and addresses the problem of motive detection as the first step .
Following a study in psychology , we define six basic motives that cover a wide range of topics appearing in review texts , annotate 1,600 texts in restaurant and laptop domains with the motives , and report the performance of baseline methods on this new dataset .
We also show that crossdomain transfer learning boosts detection performance , which indicates that these universal motives exist across different domains .
Introduction
Understanding a person 's sentiment based on text has practical implications for improving product / service quality , along with scientific implications for psychology and other fields .
Despite a rich body of sentiment analysis research , a sentiment is often simply assumed to be expressed by uni-dimensional binary or ternary labels ( positive , neutral , and negative ) , and relatively little attention has been paid to the reason for holding a particular sentiment value .
Aspect - based sentiment analysis ( ABSA ) , which considers finegrained categories ( a.k.a. aspects ) that may cause sentiment , partially tackles this problem .
However , aspects are typically limited to properties of entities such as the price of food and design of a product ( e.g. , ( Pontiki et al. , 2016 ) ) and do not really show why such aspects matter and how they cause human sentiments .
For example , some people desire cheap and quick meals for saving time and money , and others desire high - grade food for enjoying the dining experience itself .
Following Li and Hovy ( 2017 ) , we consider a sentiment as a realization of an individual 's mental state that relates to his / her satisfaction toward a specific event or entity .
While a sentiment can be driven by a sentiment holder 's emotional , nonlogical preference ( like " I just do n't enjoy that kind of food " ) and also conditioned by long-term plans and resources that the holder has , a sentiment is largely triggered by whether one of the holder 's goals is satisfied or not .
As Figure 1 illustrates , one will have a negative sentiment toward a restaurant if the service is terrible because one 's basic motive for social behavior is not met .
What and how many motives do we have ?
Decades of effort have been devoted to this question in research areas such as psychology , for example , ( Maslow , 1943 ) .
A recent study by Talevich et al . ( 2017 ) defines a taxonomy of motives , including SELF - FULFILLMENT , APPRECIATING BEAUTY , SOCIAL RELATION , HEALTH , AMBI-TION&ABILITY , and FINANCE .
We use their comprehensive taxonomy for understanding sentiments .
Our work is in line with studies attempting to identify relevant motives in texts ( Ding and Riloff , 2018 ; Rashkin et al. , 2018 ) , aiming to equip machines with the ability to understand a more complete description of a situation and justify human decisions and actions .
While Ding and Riloff ( 2018 ) and Rashkin et al . ( 2018 ) specifically focus on predicate - argument tuples and artificial texts , respectively , our work analyzes real review sentences .
As an initial step , we conduct a task of human motive detection .
We manually annotate 1,600 review texts in restaurant and laptop domains from existing ABSA datasets with the six motives .
The annotation results reveal that people are driven by different motives in different domains .
Finally , we report the performance of baseline methods on this new dataset .
The results indicate a substantial space to improve automatic detection methods .
Following research on human motivation , we hypothesize that underlying drivers of human behavior are universal across domains , though distributions can vary .
With this assumption , we leverage out - of- domain data to improve a human motive detector in the target domain .
Our experiment indeed shows that transfer learning across restaurant and laptop domains is effective in motive detection .
Representation of Human Motives
Our aim is to justify a sentiment using human motives .
To this end , we require a taxonomy of human motives .
Motives are defined as reasons people hold for initiating and performing voluntary behavior ( Reiss , 2004 ) .
A study of human motives dates back to Aristotle ( 384 - 322BC ) , who proposed a distinction between ends and means .
1 Ends , for which there are several theories , are believed to be a closed class ( e.g. ( Maslow , 1943 ) ) .
The aforementioned motives are drawn from a taxonomy of 161 motives ( Talevich et al. , 2017 ) .
Talevich et al. derived basic motives based on an extensive literature survey and grouped them hierarchically based on similarity judgments collected from human subjects .
The hierarchical structure of their taxonomy embodies conceptual relationships between motives .
Higher - level motives in the hierarchy are more abstract .
The motives we picked are intermediate categories in the taxonomy that cover a wide range of topics appearing in our review texts ( Table 1 ) .
These intermediate categories represent 55 % of the taxonomy .
Annotation of Human Motives
We use Amazon Mechanical Turk to annotate review texts .
We assign three crowd annotators to 1 In his book " Nicomachean Ethics " each text and aggregate their responses to obtain the final results .
Setup Data :
We annotate restaurant and laptop review texts from the SemEval 2016 datasets ( Pontiki et al. , 2016 ) .
We extract sentences with fewer than 25 tokens , 2 and sample 800 sentences from each domain .
Quality Control :
We first collect annotations on 200 sentences in each domain without any filtering of workers .
We then evaluate the workers on the 400 sentences : one of the authors examine the responses and made the gold -standard label set , and we calculate the F1 - score of each worker against the gold-standard .
We only use the workers whose scores are ?
0.5 in the remaining annotation tasks .
Results Annotation Agreement :
Our crowd workers agreed moderately on annotations : Krippendorffs ? was 0.48 and 0.59 in the restaurant and laptop domains , respectively .
We found that SELF - FULFILLMENT and EMBRACE & EXPLORE LIFE are often hard to distinguish .
We , therefore , collapsed these categories , and Krippendorffs ? increased to 0.51 and 0.61 .
For reference , three graduate students studying language technology annotated 150 sentences in the restaurant domain .
Their Krippendorffs ? was 0.72 on the original annotation scheme and 0.74 on the collapsed scheme .
Analysis :
We next aggregated crowd workers responses using MACE ( Hovy et al. , 2013 ) , where a response was regarded as a binary value of a combination of a text and a human motive .
We set the prior probability of a positive class to 1/6 ( i.e. , one text is likely to have one of the six motives ) .
This prior fits the responses better than a uniform prior .
Table 2 shows the distributions of human motive labels .
There is a clear difference between domains : the restaurant domain has a variety of motives relevant to hedonic motives ( i.e. pleasure seeking ) like SELF - FULFILLMENT ( SF ) and SO - CIAL RELATION ( SR ) , while the laptop domain tends to have utilitarian motives ( i.e. practical needs ) such as AMBITION&ABILITY ( AA ) and FINANCE ( F ) .
SELF - FULFILLMENT ( SF ) Finding meaning in life .
Human Motive Detection
We propose the task of motive detection .
This is a multi-label sentence classification task , where for a given sentence a system detects relevant human motives .
One text can have multiple labels .
Baseline Models
SVM
We run a linear SVM classifier on bag of ngrams ( BoNG ) of sentences .
We count 1 - , 2 - , and 3 - grams of words in each sentence to construct a BoNG vector .
To avoid overfitting to rare words , we discard n-grams that occur only once in a training set .
We also apply TF - IDF scaling to BoNG vectors to emphasize topic words ( BoNG tfidf ) .
Multi-layer Perceptron ( MLP )
We build an MLP classifier with one hidden layer on top of word embedding - based sentence representations .
We compress a variable -sized sequence of word embeddings into a fixed - sized sentence embedding before feeding them into MLPs using three standard encoders below .
Simple word-embeddings model ( SWEM ) :
We calculate element- wise average and max-pooling of word embeddings in a sequence and concatenate them ( Shen et al. , 2018 ) . CNN : A CNN aggregates adjacent word units in a hierarchical manner .
We follow Kim ( 2014 ) and use filter windows of 3 , 4 , and 5 .
Bidirectional LSTM ( BiLSTM ) :
A bidirectional LSTM encodes the whole word order in a sentence .
We concatenate hidden states at the final time steps from both directions to obtain a sentence vector .
We set the number of layers to two .
Training
We simply treat our multi-label classification task as a set of binary classification tasks , where MLP classifiers share parameters except for those of an output layer over motive categories .
To handle highly skewed class distributions , we minimize a weighted loss function to train a model .
For example , MLP classifier minimizes a weighted crossentropy loss : L = ? ( x, y ) ?
D c?C [ w c y c log MLP c ( x ) +( 1 ? y c ) log ( 1 ? MLP c ( x ) ) ] , ( 1 ) where ( x , y ) is a pair of a sentence and a label in dataset D , C is a set of categories , and MLP c is an output function w.r.t. category c.
We use the following class weight ( Morik et al. , 1999 ) . w c = ( x, y ) ? D ( 1 ? y c ) ( x, y ) ?
D y c ( c ? C ) ( 2 )
Transfer Learning Across Domains
In contrast to entity aspects that must be defined for each domain , underlying human motives will be universal across domains although distributions can be different .
If this hypothesis is true , we can leverage out - of- domain data to improve motive detectors .
We conduct transfer learning across Table 3 : Results of human motive detection .
Macro-precision , recall , and F1 - measure scores are averaged over three folds in cross-validation ( except for the performance of crowd workers in row Human ) .
The higher numbers in each metric are denoted in bold face .
domains by minimizing the loss function below .
L = L in + ?L out , ( 3 ) where L in and L out are loss functions defined on in- domain and out - of- domain data , and ? is a hyperparameter to discount the out-of- domain loss .
Experiments
Setup
We use macro- averaging of F1 measures over motive categories as the primary evaluation metrics .
We conduct three - fold cross-validation , where the dataset is divided evenly into training , validation , and test sets .
In each fold , we conduct a grid search of hyperparameters based on the validation set .
We then use a training and validation set to train a model and test on a test split .
We report the average scores over test splits as the final score .
We use pretrained 100 - D GloVe embeddings trained on 6 billion tokens from Wikipedia and Gigaword corpus ( Pennington et al. , 2014 ) .
3
We provide the implementation details in the appendix .
Results
Table 3 shows that the MLP classifiers performed better or on par with the SVM classifier in terms of F1 measure .
The low recall scores of SVM classifiers indicate that surface - level features are insufficient to detect various realizations of human motives .
Interestingly , adding out - of- domain data improved F1 of all classifiers except SVM - BoNG tfidf .
Particularly , the precision of the MLP classifiers increased by transfer learning .
For the MLP - CNN classifier , the boost from laptop domain instances was as high as 0.059 of F1 measure .
This fact indicates the universality of underlying motives across domains .
We also report on human performance by comparing individual responses of crowd workers against aggregated , gold - standard labels .
We generated 100 sets of human responses by repeatedly sampling one of three workers for each sentence .
We can see a large gap between the classifiers ( 0.5 F1 ) and human ( 0.8 F1 ) in this task .
Discussion
We analyzed two domains , restaurants and laptops .
In the restaurant domain , people are driven by hedonic motives in many cases and utilitarian motives in some cases .
The laptop is a domain where people are driven by utilitarian motives in the majority cases .
Of course , there are many domains other than these domains .
For example , people would watch only for enjoying it .
Exploring other domains would be an interesting direction for future research .
Another important direction is to develop a method that bridges between motives and sentiment valence .
Li and Hovy ( 2017 ) gives concrete procedures to account for semantics behind the scene : we identify which goals are aimed at to fulfil a given motive , which plans are taken to achieve the goals , which actions and conditions appear in the plans , and how well they are actually performed .
These intermediate components would relate what we call aspects in aspect-based sentiment analysis .
Although we focused on sentiment analysis in this study , detection of motives can benefit other NLP applications such as in - depth machine reading .
For example , underlying motives will be a strong clue for modeling a sequence of actions that share the same actor ( a.k. a narrative chains ( Chambers and Jurafsky , 2008 ) ) .
Conclusion
We aimed at understanding why a writer of a text holds a particular sentiment and proposed a task of human motive detection as an essential building block to this end .
We presented a taxonomy of motives derived from a psychology study and annotated 1,600 restaurant and laptop reviews with six motives .
We evaluated the performance of baseline predictive models on this dataset .
4
One interesting property is that the same underlying motives can appear in different domains even though their distribution may differ .
We empirically verified this by transferring learned parameters across domains .
The result showed that predictive models can strongly benefit from outof-domain instances .
Nevertheless , there is still a substantial performance gap between humans and automatic detectors .
Figure 1 : 1 Figure 1 : Restaurant review texts and human motives of interest ( rectangles ) .
