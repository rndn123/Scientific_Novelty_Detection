title
Learning Sentiment -Specific Word Embedding for Twitter Sentiment Classification *
abstract
We present a method that learns word embedding for Twitter sentiment classification in this paper .
Most existing algorithms for learning continuous word representations typically only model the syntactic context of words but ignore the sentiment of text .
This is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity , such as good and bad , to neighboring word vectors .
We address this issue by learning sentimentspecific word embedding ( SSWE ) , which encodes sentiment information in the continuous representation of words .
Specifically , we develop three neural networks to effectively incorporate the supervision from sentiment polarity of text ( e.g. sentences or tweets ) in their loss functions .
To obtain large scale training corpora , we learn the sentiment -specific word embedding from massive distant - supervised tweets collected by positive and negative emoticons .
Experiments on applying SS - WE to a benchmark Twitter sentiment classification dataset in SemEval 2013 show that ( 1 ) the SSWE feature performs comparably with hand -crafted features in the top-performed system ; ( 2 ) the performance is further improved by concatenating SSWE with existing feature set .
Introduction
Twitter sentiment classification has attracted increasing research interest in recent years ( Jiang et al. , 2011 ; Hu et al. , 2013 ) .
The objective is to classify the sentiment polarity of a tweet as positive , negative or neutral .
The majority of existing approaches follow Pang et al . ( 2002 ) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity .
Under this direction , most studies focus on designing effective features to obtain better classification performance .
For example , Mohammad et al . ( 2013 ) build the top-performed system in the Twitter sentiment classification track of SemEval 2013 ( Nakov et al. , 2013 ) , using diverse sentiment lexicons and a variety of hand -crafted features .
Feature engineering is important but laborintensive .
It is therefore desirable to discover explanatory factors from the data and make the learning algorithms less dependent on extensive feature engineering ( Bengio , 2013 ) .
For the task of sentiment classification , an effective feature learning method is to compose the representation of a sentence ( or document ) from the representations of the words or phrases it contains ( Socher et al. , 2013 b ; Yessenalina and Cardie , 2011 ) .
Accordingly , it is a crucial step to learn the word representation ( or word embedding ) , which is a dense , low-dimensional and real-valued vector for a word .
Although existing word embedding learning algorithms ( Collobert et al. , 2011 ; Mikolov et al. , 2013 ) are intuitive choices , they are not effective enough if directly used for sentiment classification .
The most serious problem is that traditional methods typically model the syntactic context of words but ignore the sentiment information of text .
As a result , words with opposite polarity , such as good and bad , are mapped into close vectors .
It is meaningful for some tasks such as pos-tagging ( Zheng et al. , 2013 ) as the two words have similar usages and grammatical roles , but it becomes a disaster for sentiment analysis as they have the opposite sentiment polarity .
In this paper , we propose learning sentimentspecific word embedding ( SSWE ) for sentiment analysis .
We encode the sentiment information in - to the continuous representation of words , so that it is able to separate good and bad to opposite ends of the spectrum .
To this end , we extend the existing word embedding learning algorithm ( Collobert et al. , 2011 ) and develop three neural networks to effectively incorporate the supervision from sentiment polarity of text ( e.g. sentences or tweets ) in their loss functions .
We learn the sentiment -specific word embedding from tweets , leveraging massive tweets with emoticons as distant - supervised corpora without any manual annotations .
These automatically collected tweets contain noises so they cannot be directly used as gold training data to build sentiment classifiers , but they are effective enough to provide weakly supervised signals for training the sentimentspecific word embedding .
We apply SSWE as features in a supervised learning framework for Twitter sentiment classification , and evaluate it on the benchmark dataset in SemEval 2013 .
In the task of predicting positive / negative polarity of tweets , our method yields 84.89 % in macro - F1 by only using SSWE as feature , which is comparable to the top-performed system based on hand -crafted features ( 84.70 % ) .
After concatenating the SSWE feature with existing feature set , we push the state - of- the- art to 86.58 % in macro - F1 .
The quality of SSWE is also directly evaluated by measuring the word similarity in the embedding space for sentiment lexicons .
In the accuracy of polarity consistency between each sentiment word and its top N closest words , SSWE outperforms existing word embedding learning algorithms .
The major contributions of the work presented in this paper are as follows .
?
We develop three neural networks to learn sentiment -specific word embedding ( SSWE ) from massive distant - supervised tweets without any manual annotations ; ?
To our knowledge , this is the first work that exploits word embedding for Twitter sentiment classification .
We report the results that the SSWE feature performs comparably with hand -crafted features in the top-performed system in SemEval 2013 ; ?
We release the sentiment -specific word embedding learned from 10 million tweets , which can be adopted off - the-shell in other sentiment analysis tasks .
Related Work
In this section , we present a brief review of the related work from two perspectives , Twitter sentiment classification and learning continuous representations for sentiment classification .
Twitter Sentiment Classification
Twitter sentiment classification , which identifies the sentiment polarity of short , informal tweets , has attracted increasing research interest ( Jiang et al. , 2011 ; Hu et al. , 2013 ) in recent years .
Generally , the methods employed in Twitter sentiment classification follow traditional sentiment classification approaches .
The lexicon- based approaches ( Turney , 2002 ; Ding et al. , 2008 ; Taboada et al. , 2011 ; Thelwall et al. , 2012 ) mostly use a dictionary of sentiment words with their associated sentiment polarity , and incorporate negation and intensification to compute the sentiment polarity for each sentence ( or document ) .
The learning based methods for Twitter sentiment classification follow Pang et al . ( 2002 ) 's work , which treat sentiment classification of texts as a special case of text categorization issue .
Many studies on Twitter sentiment classification ( Pak and Paroubek , 2010 ; Davidov et al. , 2010 ; Barbosa and Feng , 2010 ; Kouloumpis et al. , 2011 ; Zhao et al. , 2012 ) leverage massive noisy - labeled tweets selected by positive and negative emoticons as training set and build sentiment classifiers directly , which is called distant supervision ( Go et al. , 2009 ) .
Instead of directly using the distantsupervised data as training set , adopt the tweets with emoticons to smooth the language model and Hu et al . ( 2013 ) incorporate the emotional signals into an unsupervised learning framework for Twitter sentiment classification .
Many existing learning based methods on Twitter sentiment classification focus on feature engineering .
The reason is that the performance of sentiment classifier being heavily dependent on the choice of feature representation of tweets .
The most representative system is introduced by Mohammad et al . ( 2013 ) , which is the state- of- theart system ( the top-performed system in SemEval 2013 Twitter Sentiment Classification Track ) by implementing a number of hand -crafted features .
Unlike the previous studies , we focus on learning discriminative features automatically from massive distant - supervised tweets .
Learning Continuous Representations for Sentiment Classification Pang et al. ( 2002 ) pioneer this field by using bagof-word representation , representing each word as a one-hot vector .
It has the same length as the size of the vocabulary , and only one dimension is 1 , with all others being 0 .
Under this assumption , many feature learning algorithms are proposed to obtain better classification performance ( Pang and Lee , 2008 ; Liu , 2012 ; Feldman , 2013 ) .
However , the one-hot word representation cannot sufficiently capture the complex linguistic characteristics of words .
With the revival of interest in deep learning , incorporating the continuous representation of a word as features has been proving effective in a variety of NLP tasks , such as parsing ( Socher et al. , 2013a ) , language modeling ( Bengio et al. , 2003 ; Mnih and Hinton , 2009 ) and NER ( Turian et al. , 2010 ) .
In the field of sentiment analysis , Bespalov et al . ( 2011 ; 2012 ) initialize the word embedding by Latent Semantic Analysis and further represent each document as the linear weighted of ngram vectors for sentiment classification .
Yessenalina and Cardie ( 2011 ) model each word as a matrix and combine words using iterated matrix multiplication .
Glorot et al . ( 2011 )
The representation of words heavily relies on the applications or tasks in which it is used ( Labutov and Lipson , 2013 ) .
This paper focuses on learning sentiment -specific word embedding , which is tailored for sentiment analysis .
Unlike Maas et al. ( 2011 ) that follow the probabilistic document model ( Blei et al. , 2003 ) and give an sentiment predictor function to each word , we develop neural networks and map each ngram to the sentiment polarity of sentence .
Unlike Socher et al. ( 2011 c ) that utilize manually labeled texts to learn the meaning of phrase ( or sentence ) through compositionality , we focus on learning the meaning of word , namely word embedding , from massive distant - supervised tweets .
Unlike Labutov and Lipson ( 2013 ) that produce task -specific embedding from an existing word embedding , we learn sentiment -specific word embedding from scratch .
3 Sentiment -Specific Word Embedding for Twitter Sentiment Classification
In this section , we present the details of learning sentiment -specific word embedding ( SSWE ) for Twitter sentiment classification .
We propose incorporating the sentiment information of sentences to learn continuous representations for words and phrases .
We extend the existing word embedding learning algorithm ( Collobert et al. , 2011 ) and develop three neural networks to learn SSWE .
In the following sections , we introduce the traditional method before presenting the details of SSWE learning algorithms .
We then describe the use of SSWE in a supervised learning framework for Twitter sentiment classification .
C&W Model Collobert et al. ( 2011 ) introduce C&W model to learn word embedding based on the syntactic contexts of words .
Given an ngram " cat chills on a mat " , C&W replaces the center word with a random word w r and derives a corrupted ngram " cat chills w r a mat " .
The training objective is that the original ngram is expected to obtain a higher language model score than the corrupted ngram by a margin of 1 .
The ranking objective function can be optimized by a hinge loss , loss cw ( t , t r ) = max ( 0 , 1 ? f cw ( t ) + f cw ( t r ) ) ( 1 ) where t is the original ngram , t r is the corrupted ngram , f cw ( ? ) is a one-dimensional scalar representing the language model score of the input ngram .
Figure 1 ( a ) illustrates the neural architecture of C&W , which consists of four layers , namely lookup ? linear ?
hT anh ? linear ( from bottom to top ) .
The original and corrupted ngrams are treated as inputs of the feed -forward neural network , respectively .
The output f cw is the language model score of the input , which is calculated as given in Equation 2 , where L is the lookup table of word embedding , w 1 , w 2 , b 1 , b 2 are the parameters of linear layers .
f cw ( t ) = w 2 ( a ) + b 2 ( 2 ) a = hT anh ( w 1 L t + b 1 ) ( 3 ) hT anh ( x ) = ? ? ? ? ? ?1 if x < ?1 x if ? 1 ? x ? 1 1 if x > 1 ( 4 )
Sentiment -Specific Word Embedding Following the traditional C&W model ( Collobert et al. , 2011 ) , we incorporate the sentiment information into the neural network to learn sentimentspecific word embedding .
We develop three neural networks with different strategies to integrate the sentiment information of tweets .
Basic Model 1 ( SSWE h ) .
As an unsupervised approach , C&W model does not explicitly capture the sentiment information of texts .
An intuitive solution to integrate the sentiment information is predicting the sentiment distribution of text based on input ngram .
We do not utilize the entire sentence as input because the length of different sentences might be variant .
We therefore slide the window of ngram across a sentence , and then predict the sentiment polarity based on each ngram with a shared neural network .
In the neural network , the distributed representation of higher layer are interpreted as features describing the input .
Thus , we utilize the continuous vector of top layer to predict the sentiment distribution of text .
Assuming there are K labels , we modify the dimension of top layer in C&W model as K and add a sof tmax layer upon the top layer .
The neural network ( SSWE h ) is given in Figure 1 ( b ) .
Sof tmax layer is suitable for this scenario because its outputs are interpreted as conditional probabilities .
Unlike C&W , SSWE h does not gen-erate any corrupted ngram .
Let f g ( t ) , where K denotes the number of sentiment polarity labels , be the gold K-dimensional multinomial distribution of input t and k f g k ( t ) = 1 .
For positive / negative classification , the distribution is of the form [ 1,0 ] for positive and [ 0,1 ] for negative .
The cross-entropy error of the sof tmax layer is : loss h ( t ) = ?
k= { 0,1 } f g k ( t ) ? log ( f h k ( t ) ) ( 5 ) where f g ( t ) is the gold sentiment distribution and f h ( t ) is the predicted sentiment distribution .
Basic Model 2 ( SSWE r ) .
SSWE h is trained by predicting the positive ngram as [ 1,0 ] and the negative ngram as [ 0,1 ] .
However , the constraint of SSWE h is too strict .
The distribution of [ 0.7,0.3 ] can also be interpreted as a positive label because the positive score is larger than the negative score .
Similarly , the distribution of [ 0.2,0.8 ] indicates negative polarity .
Based on the above observation , the hard constraints in SSWE h should be relaxed .
If the sentiment polarity of a tweet is positive , the predicted positive score is expected to be larger than the predicted negative score , and the exact reverse if the tweet has negative polarity .
We model the relaxed constraint with a ranking objective function and borrow the bottom four layers from SSWE h , namely lookup ? linear ?
hT anh ? linear in Figure 1 ( b ) , to build the relaxed neural network ( SSWE r ) .
Compared with SSWE h , the sof tmax layer is removed because SSWE r does not require probabilistic interpretation .
The hinge loss of SSWE r is modeled as de-scribed below .
loss r ( t ) = max ( 0 , 1 ? ? s ( t ) f r 0 ( t ) + ? s ( t ) f r 1 ( t ) ) ( 6 ) where f r 0 is the predicted positive score , f r 1 is the predicted negative score , ? s ( t ) is an indicator function reflecting the sentiment polarity of a sentence , ? s ( t ) = 1 if f g ( t ) = [ 1 , 0 ] ?1 if f g ( t ) = [ 0 , 1 ] ( 7 ) Similar with SSWE h , SSWE r also does not generate the corrupted ngram .
Unified Model ( SSWE u ) .
The C&W model learns word embedding by modeling syntactic contexts of words but ignoring sentiment information .
By contrast , SSWE h and SSWE r learn sentiment -specific word embedding by integrating the sentiment polarity of sentences but leaving out the syntactic contexts of words .
We develop a unified model ( SSWE u ) in this part , which captures the sentiment information of sentences as well as the syntactic contexts of words .
SSWE u is illustrated in Figure 1 ( c ) .
Given an original ( or corrupted ) ngram and the sentiment polarity of a sentence as the input , SSWE u predicts a two -dimensional vector for each input ngram .
The two scalars ( f u 0 , f u 1 ) stand for language model score and sentiment score of the input ngram , respectively .
The training objectives of SSWE u are that ( 1 ) the original ngram should obtain a higher language model score f u 0 ( t ) than the corrupted ngram f u 0 ( t r ) , and ( 2 ) the sentiment score of original ngram f u 1 ( t ) should be more consistent with the gold polarity annotation of sentence than corrupted ngram f u 1 ( t r ) .
The loss function of SSWE u is the linear combination of two hinge losses , loss u ( t , t r ) = ? ? loss cw ( t , t r ) + ( 1 ? ? ) ? loss us ( t , t r ) ( 8 ) where loss cw ( t , t r ) is the syntactic loss as given in Equation 1 , loss us ( t , t r ) is the sentiment loss as described in Equation 9 .
The hyper-parameter ? weighs the two parts .
loss us ( t , t r ) = max ( 0 , 1 ? ? s ( t ) f u 1 ( t ) + ? s ( t ) f u 1 ( t r ) ) ( 9 ) Model Training .
We train sentiment -specific word embedding from massive distant - supervised tweets collected with positive and negative emoticons 1 . We crawl tweets from April 1st , 2013 to April 30th , 2013 with TwitterAPI .
We tokenize each tweet with TwitterNLP ( Gimpel et al. , 2011 ) , remove the @user and URLs of each tweet , and filter the tweets that are too short ( < 7 words ) .
Finally , we collect 10 M tweets , selected by 5 M tweets with positive emoticons and 5 M tweets with negative emoticons .
We train SSWE h , SSWE r and SSWE u by taking the derivative of the loss through backpropagation with respect to the whole set of parameters ( Collobert et al. , 2011 ) , and use Ada-Grad ( Duchi et al. , 2011 ) to update the parameters .
We empirically set the window size as 3 , the embedding length as 50 , the length of hidden layer as 20 and the learning rate of AdaGrad as 0.1 for all baseline and our models .
We learn embedding for unigrams , bigrams and trigrams separately with same neural network and same parameter setting .
The contexts of unigram ( bigram / trigram ) are the surrounding unigrams ( bigrams / trigrams ) , respectively .
Twitter Sentiment Classification
We apply sentiment -specific word embedding for Twitter sentiment classification under a supervised learning framework as in previous work ( Pang et al. , 2002 ) .
Instead of hand -crafting features , we incorporate the continuous representation of words and phrases as the feature of a tweet .
The sentiment classifier is built from tweets with manually annotated sentiment polarity .
We explore min , average and max convolutional layers ( Collobert et al. , 2011 ; Socher et al. , 2011a ) , which have been used as simple and effective methods for compositionality learning in vector-based semantics ( Mitchell and Lapata , 2010 ) , to obtain the tweet representation .
The result is the concatenation of vectors derived from different convolutional layers . z( tw ) = [ z max ( tw ) , z min ( tw ) , z average ( tw ) ] where z ( tw ) is the representation of tweet tw and z x ( tw ) is the results of the convolutional layer x ? { min , max , average} .
Each convolutional layer z x employs the embedding of unigrams , bigrams and trigrams separately and conducts the matrixvector operation of x on the sequence represented by columns in each lookup table .
The output of z x is the concatenation of results obtained from different lookup tables .
z x ( tw ) = [ w x L uni tw , w x L bi tw , w x L tri tw ] where w x is the convolutional function of z x , L tw is the concatenated column vectors of the words in the tweet .
L uni , L bi and L tri are the lookup tables of the unigram , bigram and trigram embedding , respectively .
Experiment
We conduct experiments to evaluate SSWE by incorporating it into a supervised learning framework for Twitter sentiment classification .
We also directly evaluate the effectiveness of the SSWE by measuring the word similarity in the embedding space for sentiment lexicons .
Twitter Sentiment Classification Experiment Setup and Datasets .
We conduct experiments on the latest Twitter sentiment classification benchmark dataset in SemEval 2013 ( Nakov et al. , 2013 ) .
The training and development sets were completely in full to task participants .
However , we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status .
The test set is directly provided to the participants .
The distribution of our dataset is given in Table 1 .
We train sentiment classifier with LibLinear ( Fan et al. , 2008 ) Baseline Methods .
We compare our method with the following sentiment classification algorithms : ( 1 ) DistSuper :
We use the 10 million tweets selected by positive and negative emoticons as training data , and build sentiment classifier with Lib-Linear and ngram features ( Go et al. , 2009 ) . ( 2 ) SVM : The ngram features and Support Vector Machine are widely used baseline methods to build sentiment classifiers ( Pang et al. , 2002 ) . Li-bLinear is used to train the SVM classifier .
( 3 ) NBSVM : NBSVM ( Wang and Manning , 2012 ) is a state - of - the - art performer on many sentiment classification datasets , which trades - off between Naive Bayes and NB - enhanced SVM .
( 4 ) RAE : Recursive Autoencoder ( Socher et al. , 2011 c ) has been proven effective in many sentiment analysis tasks by learning compositionality automatically .
We run RAE with randomly initialized word embedding .
( 5 ) NRC : NRC builds the top-performed system in SemEval 2013
Twitter sentiment classification track which incorporates diverse sentiment lexicons and many manually designed features .
We re-implement this system because the codes are not publicly available 3 . NRC - ngram refers to the feature set of NRC leaving out ngram features .
Except for DistSuper , other baseline methods are conducted in a supervised manner .
We do not compare with RNTN ( Socher et al. , 2013 b ) because we cannot efficiently train the RNTN model .
The reason lies in that the tweets in our dataset do not have accurately parsed results or fine grained sentiment labels for phrases .
Another reason is that the RNTN model trained on movie reviews cannot be directly applied on tweets due to the differences between domains ( Blitzer et al. , 2007 ) . NRC implements a variety of features and reaches 84.73 % in macro - F1 , verifying the importance of a better feature representation for Twitter sentiment classification .
We achieve 84.98 % by using only SSWE u as features without borrowing any sentiment lexicons or hand -crafted rules .
The results indicate that SSWE u automatically learns discriminative features from massive tweets and performs comparable with the state - of - the - art manually designed features .
After concatenating SSWE u with the feature set of NRC , the performance is further improved to 86.58 % .
We also compare SSWE u with the ngram feature by integrating SSWE into NRC - ngram .
The concatenated features SSWE u + NRC - ngram ( 86.48 % ) outperform the original feature set of NRC ( 84.73 % ) .
Results and Analysis .
As a reference , we apply SSWE u on subjective classification of tweets , and obtain 72.17 % in macro - F1 by using only SSWE u as feature .
After combining SSWE u with the feature set of NR - C , we improve NRC from 74.86 % to 75.39 % for subjective classification .
Comparision between Different Word Embedding .
We compare sentiment -specific word embedding ( SSWE h , SSWE r , SSWE u ) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classification .
We use the embedding of unigrams , bigrams and trigrams in the experimen-t .
The embeddings of C&W ( Collobert et al. , 2011 ) , word2vec 4 , WVSA ( Maas et al. , 2011 ) and our models are trained with the same dataset and same parameter setting .
We compare with C&W and word2vec as they have been proved effective in many NLP tasks .
The trade- off parameter of ReEmb ( Labutov and Lipson , 2013 ) is tuned on the development set of SemEval 2013 .
Table 3 shows the performance on the positive / negative classification of tweets 5 . ReEmb ( C&W ) and ReEmb ( w2v ) stand for the use of embeddings learned from 10 million distantsupervised tweets with C&W and word2vec , respectively .
Each row of Table 3 From the first column of Table 3 , we can see that the performance of C&W and word2vec are obviously lower than sentiment -specific word embeddings by only using unigram embedding as features .
The reason is that C&W and word2vec do not explicitly exploit the sentiment information of the text , resulting in that the words with opposite polarity such as good and bad are mapped to close word vectors .
When such word embeddings are fed as features to a Twitter sentiment classifier , the discriminative ability of sentiment words are weakened thus the classification performance is affected .
Sentiment -specific word em-beddings ( SSWE h , SSWE r , SSWE u ) effectively distinguish words with opposite sentiment polarity and perform best in three settings .
SSWE outperforms MVSA by exploiting more contextual information in the sentiment predictor function .
SSWE outperforms ReEmb by leveraging more sentiment information from massive distant - supervised tweets .
Among three sentiment -specific word embeddings , SSWE u captures more context information and yields best performance .
SSWE h and SSWE r obtain comparative results .
From each row of Table 3 , we can see that the bigram and trigram embeddings consistently improve the performance of Twitter sentiment classification .
The underlying reason is that a phrase , which cannot be accurately represented by unigram embedding , is directly encoded into the ngram embedding as an idiomatic unit .
A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains , such as not [ bad ] and [ great ] deal of ( the word in the bracket has different sentiment polarity with the ngram ) .
A very recent study by Mikolov et al . ( 2013 ) also verified the effectiveness of phrase embedding for analogically reasoning phrases .
Effect of ? in SSWE u
We tune the hyperparameter ? of SSWE u on the development set by using unigram embedding as features .
As given in Equation 8 , ? is the weighting score of syntactic loss of SSWE u and trades - off the syntactic and sentiment losses .
SSWE u is trained from 10 million distant - supervised tweets .
Figure 2 shows the macro- F1 of SSWE u on positive / negative classification of tweets with different ? on our development set .
We can see that SSWE u performs better when ? is in the range of [ 0.5 , 0.6 ] , which balances the syntactic context and sentiment information .
The model with ?=1 stands for C&W model , which only encodes the syntactic contexts of words .
The sharp decline at ?=1 reflects the importance of sentiment information in learning word embedding for Twitter sentiment classification .
Effect of Distant-supervised Data in SSWE u
We investigate how the size of the distantsupervised data affects the performance of SSWE u feature for Twitter sentiment classification .
We vary the number of distant - supervised tweets from 1 million to 12 million , increased by 1 million .
We set the ? of SSWE u as 0.5 , according to the experiments shown in Figure 2 . Results of positive / negative classification of tweets on our development set are given in Figure 3 .
We can see that when more distant - supervised tweets are added , the accuracy of SSWE u consistently improves .
The underlying reason is that when more tweets are incorporated , the word embedding is better estimated as the vocabulary size is larger and the context and sentiment information are richer .
When we have 10 million distantsupervised tweets , the SSWE u feature increases the macro - F1 of positive / negative classification of tweets to 82.94 % on our development set .
When we have more than 10 million tweets , the performance remains stable as the contexts of words have been mostly covered .
Word Similarity of Sentiment Lexicons
The quality of SSWE has been implicitly evaluated when applied in Twitter sentiment classification in the previous subsection .
We explicitly evaluate it in this section through word similarity in the em-bedding space for sentiment lexicons .
The evaluation metric is the accuracy of polarity consistency between each sentiment word and its top N closest words in the sentiment lexicon , Accuracy = # Lex i=1 N j=1 ?( w
i , c ij ) # Lex ? N ( 10 ) where # Lex is the number of words in the sentiment lexicon , w i is the i-th word in the lexicon , c ij is the j-th closest word to w i in the lexicon with cosine similarity , ?( w
i , c ij ) is an indicator function that is equal to 1 if w i and c ij have the same sentiment polarity and 0 for the opposite case .
The higher accuracy refers to a better polarity consistency of words in the sentiment lexicon .
We set N as 100 in our experiment .
Experiment Setup and Datasets
We utilize the widely - used sentiment lexicons , namely M-PQA ( Wilson et al. , 2005 ) and HL ( Hu and Liu , 2004 ) , to evaluate the quality of word embedding .
For each lexicon , we remove the words that do not appear in the lookup table of word embedding .
We only use unigram embedding in this section because these sentiment lexicons do not contain phrases .
The distribution of the lexicons used in this paper is listed in Table 4 .
Conclusion
In this paper , we propose learning continuous word representations as features for Twitter sentiment classification under a supervised learning framework .
We show that the word embedding learned by traditional neural networks are not effective enough for Twitter sentiment classification .
These methods typically only model the context information of words so that they cannot distinguish words with similar context but opposite sentiment polarity ( e.g. good and bad ) .
We learn sentiment -specific word embedding ( SSWE ) by integrating the sentiment information into the loss functions of three neural networks .
We train SS - WE with massive distant - supervised tweets selected by positive and negative emoticons .
The effectiveness of SSWE has been implicitly evaluated by using it as features in sentiment classification on the benchmark dataset in SemEval 2013 , and explicitly verified by measuring word similarity in the embedding space for sentiment lexicons .
Our unified model combining syntactic context of words and sentiment information of sentences yields the best performance in both experiments .
Figure 1 : 1 Figure1 : The traditional C&W model and our neural networks ( SSWE h and SSWE u ) for learning sentiment -specific word embedding .
