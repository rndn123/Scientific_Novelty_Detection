title
Learning with Noisy Labels for Sentence-level Sentiment Classification
abstract
Deep neural networks ( DNNs ) can fit ( or even over - fit ) the training data very well .
If a DNN model is trained using data with noisy labels and tested on data with clean labels , the model may perform poorly .
This paper studies the problem of learning with noisy labels for sentence - level sentiment classification .
We propose a novel DNN model called NETAB ( as shorthand for convolutional neural NETworks with AB - networks ) to handle noisy labels during training .
NETAB consists of two convolutional neural networks , one with a noise transition layer for dealing with the input noisy labels and the other for predicting ' clean ' labels .
We train the two networks using their respective loss functions in a mutual reinforcement manner .
Experimental results demonstrate the effectiveness of the proposed model .
Introduction
It is well known that sentiment annotation or labeling is subjective ( Liu , 2012 ) .
Annotators often have many disagreements .
This is especially so for crowd-workers who are not well trained .
That is why one always feels that there are many errors in an annotated dataset .
In this paper , we study whether it is possible to build accurate sentiment classifiers even with noisy - labeled training data .
Sentiment classification aims to classify a piece of text according to the polarity of the sentiment expressed in the text , e.g. , positive or negative ( Pang and Lee , 2008 ; Liu , 2012 ; .
In this work , we focus on sentence - level sentiment classification ( SSC ) with labeling errors .
As we will see in the experiment section , noisy labels in the training data can be highly damaging , especially for DNNs because they easily fit the training data and memorize their labels even when training data are corrupted with noisy labels * Corresponding author .
Collecting datasets annotated with clean labels is costly and time - consuming as DNN based models usually require a large number of training examples .
Researchers and practitioners typically have to resort to crowdsourcing .
However , as mentioned above , the crowdsourced annotations can be quite noisy .
Research on learning with noisy labels dates back to 1980s ( Angluin and Laird , 1988 ) .
It is still vibrant today ( Mnih and Hinton , 2012 ; Natarajan et al. , 2013 Natarajan et al. , , 2018 Menon et al. , 2015 ; Gao et al. , 2016 ; Liu and Tao , 2016 ; Khetan et al. , 2018 ; Zhan et al. , 2019 ) as it is highly challenging .
We will discuss the related work in the next section .
This paper studies the problem of learning with noisy labels for SSC .
Formally , we study the following problem .
Problem Definition : Given noisy labeled training sentences S = {( x 1 , y 1 ) , ... , ( x n , y n ) } , where x i | n i=1 is the i-th sentence and y i ? { 1 , ... , c} is the sentiment label of this sentence , the noisy labeled sentences are used to train a DNN model for a SSC task .
The trained model is then used to classify sentences with clean labels to one of the c sentiment labels .
In this paper , we propose a convolutional neural NETwork with AB - networks ( NETAB ) to deal with noisy labels during training , as shown in Figure 1 .
We will introduce the details in the subsequent sections .
Basically , NETAB consists of two convolutional neural networks ( CNNs ) ( see Figure 1 ) , one for learning sentiment scores to predict ' clean ' 1 labels and the other for learning a noise transition matrix to handle input noisy labels .
We call the two CNNs A-network and AB - network , respectively .
The fundamental here is that ( 1 ) DNNs memorize easy instances first and gradu-ally adapt to hard instances as training epochs increase Arpit et al. , 2017 ) ; and ( 2 ) noisy labels are theoretically flipped from the clean / true labels by a noise transition matrix ( Sukhbaatar et al. , 2015 ; Goldberger and Ben-Reuven , 2017 ; Han et al. , 2018 a , b) .
We motivate and propose a CNN model with a transition layer to estimate the noise transition matrix for the input noisy labels , while exploiting another CNN to predict ' clean ' labels for the input training ( and test ) sentences .
In training , we pre-train A-network in early epochs and then train AB - network and Anetwork with their own loss functions in an alternating manner .
To our knowledge , this is the first work that addresses the noisy label problem in sentence - level sentiment analysis .
Our experimental results show that the proposed model outperforms the state - of - the - art methods .
Related Work
Our work is related to sentence sentiment classification ( SSC ) .
SSC has been studied extensively ( Hu and Liu , 2004 ; Pang and Lee , 2005 ; Zhao et al. , 2008 ; Narayanan et al. , 2009 ; T?ckstr? m and McDonald , 2011 ; Wang and Manning , 2012 ; Yang and Cardie , 2014 ; Kim , 2014 ; Tang et al. , 2015 ; Wu et al. , 2017 ; . None of them can handle noisy labels .
Since many social media datasets are noisy , researchers have tried to build robust models ( Gamon , 2004 ; Barbosa and Feng , 2010 ; .
However , they treat noisy data as additional information and do n't specifically handle noisy labels .
A noiseaware classification model in ( Zhan et al. , 2019 ) trains using data annotated with multiple labels .
exploited the connection of users and noisy labels of sentiments in social networks .
Since the two works use multiple - labeled data or users ' information ( we only use singlelabeled data , and we do not use any additional information ) , they have different settings than ours .
Our work is closely related to DNNs based approaches to learning with noisy labels .
DNNs based approaches explored three main directions : ( 1 ) training DNNs on selected samples ( Malach and Shalev-Shwartz , 2017 ; Jiang et al. , 2018 ; Ren et al. , 2018 ; Han et al. , 2018 b ) , ( 2 ) modifying the loss function of DNNs with regularization biases ( Mnih and Hinton , 2012 ; Jindal et al. , 2016 ; Patrini et al. , 2017 ; Ghosh et al. , 2017 ; Ma et al. , 2018 ; Zhang and Sabuncu , 2018 ) , and ( 3 ) plug-ging an extra layer into DNNs ( Sukhbaatar et al. , 2015 ; Bekker and Goldberger , 2016 ; Goldberger and Ben-Reuven , 2017 ; Han et al. , 2018a ) .
All these approaches were proposed for image classification where training images were corrupted with noisy labels .
Some of them require noise rate to be known a priori in order to tune their models during training ( Patrini et al. , 2017 ; Han et al. , 2018 b ) .
Our approach combines direction ( 1 ) and direction ( 3 ) , and trains two networks jointly without knowing the noise rate .
We have used five latest existing methods in our experiments for SSC .
The experimental results show that they are inferior to our proposed method .
In addition , Xiao et al . ( 2015 ) , Reed et al. ( 2015 ) , Guan et al. ( 2016 ) , Li et al. ( 2017 ) , Veit et al. ( 2017 ) , and Vahdat ( 2017 ) studied weaklysupervised DNNs or semi-supervised DNNs .
But they still need some clean-labeled training data .
We use no clean-labeled data .
Proposed Model
Our model builds on CNN ( Kim , 2014 ) .
The key idea is to train two CNNs alternately , one for addressing the input noisy labels and the other for predicting ' clean ' labels .
The overall architecture of the proposed model is given in Figure 1 .
Before going further , we first introduce a proposition , a property , and an assumption below .
Proposition
1 Noisy labels are flipped from clean labels by an unknown noise transition matrix .
Proposition 1 is reformulated from ( Han et al. , 2018a ) and has been investigated in ( Sukhbaatar et al. , 2015 ; Goldberger and Ben-Reuven , 2017 ; Bekker and Goldberger , 2016 ) .
This proposition shows that if we know the noise transition matrix , we can use it to recover the clean labels .
In other words , we can put noise transition matrix on clean labels to deal with noisy labels .
Given these , we ask the following question :
How to estimate such an unknown noise transition matrix ?
Below we give a solution to this question based on the following property of DNNs .
Property 1 DNNs tend to prioritize memorization of simple instances first and then gradually memorize hard instances .
Arpit et al. ( 2017 ) further investigated this property of DNNs .
Our setting is that simple instances are sentences of clean labels and hard instances are those with noisy labels .
We also have the following assumption .
This assumption is usually satisfied in practice because without it , it is hard to tackle the input noisy labels during training .
Based on the above preliminaries , we need to estimate the noisy transition matrix Q ? R c?c ( c = 2 in our case , i.e. , positive and negative ) , and train two classifiers ? ? P ( ?|x , ? ) and y ? P ( y|x , ? ) , where x is an input sentence , ? is its noisy label , y is its ' clean ' label , ? and ? are the parameters of two classifiers .
Note that both ? and y here are the prediction results from our model , not the input labels .
We propose to formulate the probability of the sentence x labeled as j with P ( ? = j|x , ? ) = i P ( ? = j| y = i ) P ( y = i|x , ? ) ( 1 ) where P ( ? = j| y = i ) is an item ( the ji-th item ) in the noisy transition matrix Q . We can see that the noisy transition matrix Q is exploited on the ' clean ' scores P ( y|x , ? ) to tackle noisy labels .
We now present our model NETAB and introduce how NETAB performs Eq. ( 1 ) .
As shown in Figure 1 , NETAB consists of two CNNs .
The intuition here is that we use one CNN to perform P ( y = i|x , ? ) and use another CNN to perform P ( ? = j|x , ? ) .
Meanwhile , the CNN performing P ( ? = j|x , ? ) estimates the noise transition matrix Q to deal with noisy labels .
Thus we add a transition layer into this CNN .
More precisely , in Figure 1 , the CNN with a clean loss performs P ( y = i| x , ? ) .
We call this CNN the A-network .
The other CNN with a noisy loss performs P ( ? = j|x , ? ) .
We call this CNN the AB - network .
AB - network shares all the parameters of A-network except the parameters from the Gate unit and the clean loss .
In addition , ABnetwork has a transition layer to estimate the noisy transition matrix Q . In such a way , A- network predict ' clean ' labels , and AB - network handles the input noisy labels .
We use cross-entropy with the predicted labels ? and the input labels y ( given in the dataset ) to compute the noisy loss , formulated as below L noisy = ?
1 | S| x ? S i I(y = i | x ) log P ( ? = i| x ) ( 2 ) where I is the indicator function ( if y == i , I = 1 ; otherwise , I = 0 ) , and | S| is the number of sentences to train AB - network in each batch .
Similarly , we use cross-entropy with the predicted labels y and the input labels y to compute the clean loss , formulated as L clean = ?
1 | S| x ? S i I(y = i | x ) log P ( y = i| x ) ( 3 ) where | S| is the number of sentences to train Anetwork in each batch .
Next we introduce how our model learns the parameters ( ? , ? and Q ) .
An embedding matrix v is produced for each sentence x by looking up a pre-trained word embedding database ( e.g. , GloVe.840B ( Pennington et al. , 2014 ) ) .
Then an encoding vector h = CN N ( v ) ( and u = CN N ( v ) ) is produced for each embedding matrix v in Anetwork ( and AB - network ) .
A sofmax classifier gives us P ( ? = i| x , ? ) ( i.e. , ' clean ' sentiment scores ) on the learned encoding vector h .
As the noise transition matrix Q indicates the transition values from clean labels to noisy labels , we com- pute Q as follows Q = [ q 1 ; q 2 ] ( 4 ) q i = sof tmax ( g i f i ) , i = 1 , 2 ( 5 ) g i = tanh ( W i u + b i ) ( 6 ) where W i is a trainable parameter matrix , b i and f i are two trainable parameter vectors .
They are trained in the AB - network .
Finally , P ( ? = j|x , ? ) is computed by Eq. ( 1 ) .
In training , NETAB is trained end-to-end .
Based on Proposition 1 and Property 1 , we pretrain A-network in early epochs ( e.g. , 5 epochs ) .
Then we train AB - network and A-network in an alternating manner .
The two networks are trained using their respective cross-entropy loss .
Given a batch of sentences , we first train ABnetwork .
Then we use the scores predicted from A-network to select some possibly clean sentences from this batch and train A-network on the selected sentences .
Specifically speaking , we use the predicted scores to compute sentiment labels by arg max i {? = i|? ? P ( ?|x , ? ) }.
Then we select the sentences whose resulting sentiment label equals to the input label .
The selection process is marked by a Gate unit in Figure 1 .
When testing a sentence , we use A-network to produce the final classification result .
Experiments
In this section , we evaluate the performance of the proposed NETAB model .
we conduct two types of experiments .
( 1 ) We corrupt clean-labeled datasets to produce noisy - labeled datasets to show the impact of noises on sentiment classification accuracy .
( 2 ) We collect some real noisy data and use them to train models to evaluate the performance of NETAB .
Clean-labeled Datasets .
We use three clean labeled datasets .
The first one is the movie sentence polarity dataset from ( Pang and Lee , 2005 ) .
The other two datasets are laptop and restaurant datasets collected from SemEval - 2016 2 .
The former consists of laptop review sentences and the latter consists of restaurant review sentences .
The original datasets ( i.e. , Laptop and Restaurant ) were annotated with aspect polarity in each sentence .
We used all sentences with only one polarity ( positive or negative ) for their aspects .
That is , we only used sentences with aspects having the same sentiment label in each sentence .
Thus , the sentiment of each aspect gives the ground -truth as the sentiments of all aspects are the same .
For each clean-labeled dataset , the sentences are randomly partitioned into training set and test set with 80 % and 20 % , respectively .
Following ( Kim , 2014 ) ,
We also randomly select 10 % of the test data for validation to check the model during training .
Summary statistics of the training , validation , and test data are shown in Table 1 . Noisy - labeled Training Datasets .
For the above three domains ( movie , laptop , and restaurant ) , we collected 2,000 reviews for each domain from the same review source .
We extracted sentences from each review and assigned review 's label to its sentences .
Like previous work , we treat 4 or 5 stars as positive and 1 or 2 stars as negative .
The data is noisy because a positive ( negative ) review can contain negative ( positive ) sentences , and there are also neutral sentences .
This gives us three noisy - labeled training datasets .
We still use the same test sets as those for the clean-labeled datasets .
Summary statistics of all the datasets are shown in Table 1 . Experiment 1 : Here we use the clean-labeled data ( i.e. , the last three columns in Table 1 ) .
We corrupt the clean training data by switching the labels of some random instances based on a noise rate parameter .
Then we use the corrupted data to train NETAB and CNN ( Kim , 2014 ) .
The test accuracy curves with the noise rates [ 0 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 ] are shown in Figure 2 .
Methods Movie Laptop Restaurant ACC F1 pos F1 neg ACC F1 pos F1 neg ACC F1 pos F1 neg NBSVM - uni ( Wang and Manning , 2012 ) 0.6791 0.6663 0.6910 0.7637 0.8216 0.6500 0.7949 0.8478 0.6858 NBSVM - bi ( Wang and Manning , 2012 ) 0.6416 0.6438 0.6394 0.7784 0.8320 0.6749 0.7154 0.7834 0.5853 CNN ( Kim , 2014 ) 0.6667 0.6467 0.6844 0.7737 0.8381 0.6245 0.8329 0.8841 0.7007 Adaptation ( Goldberger and Ben-Reuven , 2017 ) 0.6682 0.6708 0.6656 0.7272 0.7936 0.5981 0.8285 0.8872 0.6422 Forward ( Patrini et al. , 2017 ) 0.6864 0.6753 0.6969 0.7547 0.8170 0.6282 0.8329 0.8882 0.6695
Backward ( Patrini et al. , 2017 )
From the figure , we can see that the test accuracy drops from around 0.8 to 0.5 when the noise rate increases from 0 to 0.5 , but our NETAB outperforms CNN .
The results clearly show that the performance of the CNN drops quite a lot with the noise rate increasing .
Experiment 2 : Here we use the real noisylabeled training data to train our model and the baselines , and then test on the test data in Table 1 .
Our goal is two fold .
First , we want to evaluate NETAB using real noisy data .
Second , we want to see whether sentences with review level labels can be used to build effective SSC models .
Baselines .
We use one strong non-DNN baseline , NBSVM ( with unigrams or bigrams features ) ( Wang and Manning , 2012 ) and six DNN baselines .
The first DNN baseline is CNN ( Kim , 2014 ) , which does not handle noisy labels .
The other five were designed to handle noisy labels .
The comparison results are shown in Table 2 .
From the results , we can make the following observations .
( 1 ) Our NETAB model achieves the best ACC and F1 on all datasets except for F1 of negative class on Laptop .
The results demonstrate the superiority of NETAB .
( 2 ) NETAB outperforms the baselines designed for learning with noisy labels .
These baselines are inferior to ours as they were tailored for image classification .
Note that we found no existing method to deal with noisy labels for SSC .
Training Details .
We use the publicly available pre-trained embedding GloVe.840B ( Pennington et al. , 2014 ) to initialize the word vectors and the embedding dimension is 300 .
For each baseline , we obtain the system from its author and use its default parameters .
As the DNN baselines ( except CNN ) were proposed for image classification , we change the input channels from 3 to 1 .
For our NETAB , we follow Kim ( 2014 ) to use window sizes of 3 , 4 and 5 words with 100 feature maps per window size , resulting in 300 dimensional encoding vectors .
The input length of sentence is set to 40 .
The network parameters are updated using the Adam optimizer ( Kingma and Ba , 2014 ) with a learning rate of 0.001 .
The learning rate is clipped gradually using a norm of 0.96 in performing the Adam optimization .
The dropout rate is 0.5 in the input layer .
The number of epochs is 200 and batch size is 50 .
Conclusions
This paper proposed a novel CNN based model for sentence - level sentiment classification learning for data with noisy labels .
The proposed model learns to handle noisy labels during training by training two networks alternately .
The learned noisy transition matrices are used to tackle noisy labels .
Experimental results showed that the proposed model outperforms a wide range of baselines markedly .
We believe that learning with noisy labels is a promising direction as it is often easy to collect noisy - labeled training data .
Figure 1 : 1 Figure 1 : The proposed NETAB model ( left ) and its training method ( right ) .
Components in light gray color denote that these components are deactivated during training in that stage .
( Color online )
Table 1 : 1 Summary statistics of the datasets .
Number of positive ( P ) and negative ( N ) sentences in ( noisy and clean ) training data , validation data , and test data .
The second column shows the statistics of sentences extracted from the 2,000 reviews of each dataset .
The last three columns show the statistics of the sentences in three clean-labeled datasets , see " Clean-labeled Datasets " .
# Noisy Training Data # Clean Training Data # Validation Data # Test Data Movie 13539P , 13350N 4265P , 4265N 105P , 106N 960P , 957N Laptop 9702P , 7876N 1064P , 490N 33P , 20N 298P , 175N Restaurant 8094P , 10299N 1087P , 823N 39P , 14N 339P , 116N
Here we use clean with single quotes as it is not completely clean .
In practice , models can hardly produce completely clean labels .
http://alt.qcri.org/semeval2016/ task5 /
