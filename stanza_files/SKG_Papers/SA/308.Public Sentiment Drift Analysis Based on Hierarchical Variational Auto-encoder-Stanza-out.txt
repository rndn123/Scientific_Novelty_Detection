title
Public Sentiment Drift Analysis Based on Hierarchical Variational Auto-encoder
abstract
Detecting public sentiment drift is a challenging task due to sentiment change over time .
Existing methods first build a classification model using historical data and subsequently detect drift if the model performs much worse on new data .
In this paper , we focus on distribution learning by proposing a novel Hierarchical Variational Auto-Encoder ( HVAE ) model to learn better distribution representation , and design a new drift measure to directly evaluate distribution changes between historical data and new data .
Our experimental results demonstrate that our proposed model achieves better results than three existing state - of- theart methods .
Introduction Public sentiments , whose information hidden in a temporal sequence of documents , become increasingly valuable for real-world applications .
Especially , identifying when public drifts occur is of great importance to different stakeholders , such as government agencies , companies and news agencies , where they can take proactive actions to avoid damages and pay close attentions to new topics / sentiments etc ( Hu et al. , 2017 ) .
However , the dynamic nature of drifts / changes makes it a challenging problem , although concept drift analysis can be applied to focus on detecting variation of data distributions over time .
Given historical data and new incoming data , how to accurately detect drift based on distributional change is a critical issue .
While existing methods are proposed for sentiment analysis
Wu et al . ( 2019 ) ; Fu et al . ( 2019 ) ; Kong et al . ( 2019 ) ; Hoang et al. ( 2019 ) ; , etc. , many of them are not designed for sentiment drift detection task .
Xia et al. ( 2016 ) focuses on polarity shift detection , but it is at document - level instead of multi-document ( or public ) level .
Recently , some research have been conducted for stream sentiment classification Iosifidis et al . ( 2017 ) .
In particular , statistic processing control ( SPC ) Ross et al . ( 2012 ) ; Raza et al. ( 2015 ) built a detection mechanism which accumulates statistic information of drift indications , and Zhou et al . ( 2018 ) applied the mechanism in sentiment drift detection .
In addition , Bifet and Gavalda ( 2007 ) proposed ADWIN method , which used the upper bound of Hoeffding 's inequality to mark drifts .
Additionally , Nguyen et al. ( 2018 ) combined ADWIN with variational inference and built an online classification system .
Wang et al. ( 2013 ) proposed an opinion drift detection method which is thresholdbased , restricting its applications .
A novel framework , proposed by Liu et al . ( 2016 ) , contains an opinion shift detector based on KL - divergence , while its detection performance is affected by its labeling results .
Tsytsarau and Palpanas ( 2016 ) defined a novel concept of opinion contradictions and used it in a sentiment change detection experiment .
However , the pair-wise method does not involve much history information .
We observe most of the above methods indirectly detect drifts instead of directly evaluate distribution difference , leading to less effective results .
The Variational Auto-Encoder ( VAE ) model , proposed by Kingma and Welling ( 2014 ) , is capable to learn latent distributions of inputs , and has better generalization performance ( Zhao et al. , 2018 ) .
As such , we propose a novel Hierarchical Variational Auto-Encoder ( HVAE ) model to tackle sentiment drift problem .
In particular , we take sentiment distribution changes as the drifts .
Practically , sentiments are represented into a 2D vector , whose dimensions and values correspond to polarities ( positive or negative ) and corresponding intensities respectively .
Our main contributions can be summarized as follows : 1 . We propose a HVAE model , which designs 3 - level meta-distributions to extend VAE over hierarchical structure , enabling effective learning latent distribution representations of input sentiments .
2 . We propose a new drift detection measure to compare historical and new data distributions learned by the proposed HVAE .
3 . Extensive experimental results on real-world data demonstrate our proposed model is significantly better than state - of - the -arts for sentiment drift detection .
Methodology
We now introduce our proposed methodology , including HVAE model and drift measure .
HVAE Model Fig .
1 shows a novel three - level hierarchical structure , where W is a length N moving window , each time period i in W contains a set of historical documents s ( i ) 1:L i , and s 1 : Lnew contains a set of newly incoming documents .
More detailed annotations are described in Tab .
1 . In the bottom level of Fig. 1 , each document s is viewed as a sample from the middle level distribution of z ;
On the same principle , each z distribution is sampled from its corresponding top level meta-distribution z .
The HVAE is composed of an encoder and a decoder , where the encoder infers latent distributions from inputs .
In Eq. 1 and 2 , the meta-distribution among input sentiments s ( i ) 1:L i from i th time period are learned by EncodeM odel .
Similarly , the meta-distribution among all period distributions are achieved as 3 and 4 show .
On the other hand , the decoder module is applied to generate inputs by making use of the learned latent variables .
In Eq. 5 and 7 , z and z i are sampled Latent meta-distributions of period and window , respectively .
? , ?
Parameters of decoder and encoder .
dash / solid line Decode / Encode process .
(? ? , ? ? ) = DecoderModel ? ( z ) ( ? ? i , ? ? i ) = EncoderModel ? ( s ( i ) 1:L i ) ( 1 ) z |s ( i ) 1:L i ? N (? ? i , ? 2 ? i ) ( 2 ) ( ? ? , ? ? ) = EncoderModel ? ( z 1:N ) ( 3 ) z|z 1:N ? N (? ? , ? 2 ? ) ( 4 ) from ( ? ? , ? ? ) and ( ? ? i , ? ? i ) , ( 5 ) z i |z ? N (? ? , ? 2 ? ) ( 6 ) ( ? ? i , ? ? i ) = DecoderModel ? ( z i ) ( 7 ) s ( i ) j | z i ? N (? ? i , ? 2 ? i ) ( 8 ) Note at the bottom level of HVAE , input information of each time period are compressed to a less noisy condensed representation in middle level distribution form .
In the same spirit , information from middle level time periods of a window are also compressed into a concise meta-distribution .
Through training , the representativeness of all metadistributions are increased .
As such , the follow - logp ( S ) ?
E q ? ( z 1:N , z|S ) ? ? ? ? ? ? Decode logp ( z ) + logp ? ( z 1:N |z ) + logp ? ( S| z 1:N ) ?logq ? ( z|z 1:N ) ? logq ? ( z 1:N | S ) Encode ? ? ? ? ? ? ( 9 ) up drift comparison step can benefit significantly from the better learned distribution representations , where certain level of data chaotic issue that frequently occurs in sentiment drift will be more tolerated than existing methods .
Drift Measure
The drift measure evaluates the distributional difference between historical and newly arrived data .
Note this is different from existing methods which are typically based on classifier performance degradation ; here we directly compare data distribution and thus more effective .
In particular , we choose two distributions , namely z |z and z new | S new , for drift measuring .
Difference between two distributions are illustrated as shading area in Fig.
2 .
Obviously , the bigger the size of shading area , the smaller the similarity between the new and history data distribution , which has become a part of built - in drift detection algorithm of HVAE model .
Mathematically , the irregular shading area can be computed as the integration of distribution difference .
Correspondingly , we propose a new measure , namely , Accumulation of Distribution Differences ( ADD ) as Eq. 10 .
The parameters of latent distribution over newly arrived z new are ( ?
? new , ? ?new ) , and the parameters of latent distribution within latest historical data window z | z are ( ? ? , ? ? ) .
The p is the drift indicator , whose value is larger when the drift is more significant and vice versa .
p = N ( x ; ? ?new , ? 2 ?new ) ? N ( x ; ? ? , ? 2 ? ) dx ( 10 )
More specifically , we compute the intersections of the two distribution curves , which are named as x 1 and x 2 ( x 1 = x 2 when there is only one intersection , i.e. both distributions are same , and make x 1 ? x 2 valid ) .
The intersections split the curves into segments whose probability difference accumulations are normalized to [ 0,1 ] as our final drift score .
p = | F 1 ( x 1 ) ? F 2 ( x 1 ) |+ | F 1 ( x 2 ) ? F 1 ( x 1 ) ? [ F 2 ( x 2 ) ? F 2 ( x 1 ) ] | +| F 1 ( x 2 ) ? F 2 ( x 2 ) | 2 ( 11 ) Figure 2 : The difference between two gaussian distributions , which is represented as the shading area , the x 1 and x 2 are intersections of distributions .
The reason of gaussian distribution assumption is that mean sentiment of across multiple documents is more likely to perform as gaussian according to the Central Limit Theorem .
Under the condition of processing extremely unstable inputs ( big drifts ) , many of the values will be very close to 1 , which decreases system performance .
Hence , for increasing sparsity , the score can be squared to be the final drift score , i.e. , p 2 from Eq. 11 , named as ADD 2 .
Through the ADD , all sentiment drifts of each time period is collected to current window W .
Whether to update the HVAE with new data in the window can be viewed as a Bernoulli experiment , which applies the parameter pi = mean( p 1 , p 2 , ? ? ? , p N ) and deviation ?
i = pi ( 1 ? pi ) / i.
The parameters are inputted to SPC method ( Bouchachia , 2011 ) for drift detection , and retrain / update model with next window once it alarms for drift occurring .
If SPC does not incur alarm , the window moves one time period and meanwhile obtains new parameters as new data arrives .
Experiments
We have conducted extensive experiments to evaluate our proposed HVAE model .
Datasets & Baselines
We employ two datasets for our experiments , including Twitter data and CIRCLES data .
Twitter Sentiment 1 , containing 1.6 m tweets created from 2009-04-06 to 2009-06 - 25 .
The dataset is split by hours ( time periods ) , and we delete those periods with empty categories , resulting in 432 periods .
Note inputs of tweets are sentiment labels whose format is one-hot .
The second dataset is CIRCLES , which is taken from Gama et al . ( 2004 ) and sampled from a uniform distribution in which x ? [ 0 , 1.2 ] , y ? [ 0 , 1 ] .
It contains 40 data blocks , each of them contains 10 time periods which apply one of four kind category boundaries ( in Tab . 2 ) .
Each time period contains 100 2 - dimensions numeric vectors .
The CIRCLES data is noise-free and used for simulating gradual drift scenario .
Both datasets are used to validate model performance , representing both noise-free ( ideal ) and real-world scenario .
We compared with three state - of- the - art systems , including :
1 ) Nguyen et al. ( 2018 ) , the VAE cooperated with a built - in drift detection method , 2 ) Zhou et al . ( 2018 ) , an improved EWMA algorithm ( Raza et al. , 2015 ) based on statistic chart , 3 ) Iosifidis et al . ( 2017 ) , stream sentiment classification based method .
Experimental Settings
Given a sequence of tweets , we will detect sentiment drifts across different time periods ( cutting points ) .
As such , drift detection is treated as sequence segmentation task , and the better segmentations , the higher the overall accuracy .
Therefore , experiment results of our model and all baselines are compared with the same metric , i.e. , overall accuracy .
For running Nguyen et al . ( 2018 ) and Zhou et al . ( 2018 ) on the two datasets , their drift detection components are implemented and tested .
Our experimental settings are the same with existing methods Iosifidis et al . ( 2017 ) .
Accumulative multinomial Naive Bayes ( Accumulative MNB ) is employed as the sentiment classifier .
Data is processed from a new time period according to the principle of prequential evaluation , and drift adaption is done in an rebuild way .
Specifically , if drift does not occur when a new period arrives , labels of data are predicted and then appended to the training set to retrain the classifier .
Otherwise , the 1 http://help.sentiment140.com/ current training set is abandoned , and the classifier is updated with a new window .
In the case of the CIRCLES , each detected drift is viewed as a category boundary switch and data before the drift are evaluated by the previous boundary .
For ablation experiment , several variations of HVAE models are generated : N o D does not apply decoder module , while N o E does not apply encoder module .
Finally P lain has only one level meta-distribution .
Experimental Results & Analysis
Table 3 shows HVAE with ADD 2 setting achieves the best accuracy , i.e. 0.55 % better than HVAE with ADD .
In addition , HVAE is 3.97 % , 4.33 % , 8.75 % better than Nguyen et al . ( 2018 ) , Zhou et al . ( 2018 ) and Iosifidis et al . ( 2017 ) respectively , indicating it is extremely effective for sentiment drift detection .
4 shows HVAE with ADD 2 once again achieves best result and is 10.5 % and 13.5 % better than two existing methods .
Note we did not compare with Iosifidis et al . ( 2017 ) , as it cannot be applied to numeric data .
For ablation study , we can clearly see the importance of our proposed 3 - level hierarchical structure for meta-distribution learning , encoder and decode modules respectively .
According to results , HVAE achieves better performance than all baselines and ablation models , which validate the effectiveness of several novelties in our proposed model .
It is obvious that all models have much better results on tweets than CIRCLES , as gradual drift detection is more difficult .
Generally , the resutls of ADD 2 measure algorithm is superior than the ADD , except for results which apply Plain model with the Twitter dataset .
Since the sentiment fluctuation of tweets are stable in most of time periods , the disadvantage of ADD may not be so obvious .
Moreover , the Plain manner without latent meta-distributions is lack of generalization capability , which performs much worse than the superior ADD 2 .
In the ablation experiment on CIRCLES , different from results with Twitter data , N o E performance worst and Plain is best .
This is because the CIRCLES data are sampled from uniform distribution , but the N o E model is based on Gaussian distribution assumption and it lacks of Encoder part for input fitting .
The Plain suffers less performance loss from distribution assumption since it has no meta-distribution structure .
The results indicate the importance of HVAE 's all innovative components where we need to extract latent distributions from inputs ( encoder ) as well as fit them with the distributions ( decoder ) .
Conclusions
To tackle challenges in sentiment drift detection , we have proposed a novel HVAE model , which is 3 - level meta-distributions to extend VAE over hierarchical structure , leading to effective learning latent distribution representations of input sentiments .
In addition , a new drift measure is designed to effectively measure distribution difference between historical and newly arrived data .
Different from existing classifier and threshold based models , the proposed method directly measures the distribution differences and thus is more effective .
Finally , extensive experimental results demonstrate that HVAE performs significantly better than three state - of - the - art techniques across two benchmark datasets , indicating that it can be effectively used for real-world public sentiment drift analysis .
Figure 1 : 1 Figure 1 : The illustration of HVAE model .
respectively .
Both EncodeM odel and DecodeM odel are neural networks .
During the model training , two modules keep interacting and all parameters are updated through gradient descent , until inputs are well fitted and latent distributions are finally obtained .
The object function is shown in Eq. 9 , where S = {s N } are historical data in window , and logp ( S ) is the log-likelihood for fitting inputs .
The Evidence Lower Bound ( ELBO ) of the log-likelihood is increased through training , and latent meta-distribution are learned at the same time .
Table 1 : 1 Annotations of our method W N length slide window .
s
A sentiment document , with it - s superscript indicating its time period .
L i Data quantity in i'th period .
z , z
Table 2 : 2 The four circles category boundaries Center [ 0.2,0.5 ] [ 0.4,0.5 ] [ 0.6,0.5 ] [ 0.8,0.5 ]
Radius 0.15 0.2 0.25 0.3
Table 3 : 3 Accuracy comparison on Twitter data .
Mod . Mea. ADD ADD 2 HVAE 0.827 0.833
Nguyen et al. ( 2018 ) 0.793
Zhou et al . ( 2018 ) 0.789 Iosifidis et al . ( 2017 ) 0.745 HVAE Ablation Plain 0.798 No D 0.8011 0.800 0.769 No E 0.826 0.829
Table
Table 4 : 4 Accuracy comparison on CIRCLES data .
Mod. Mea. ADD ADD 2 HVAE 0.315 0.350 Nguyen et al. ( 2018 ) 0.245
Zhou et al . ( 2018 ) 0.215 HVAE Ablation Plain 0.265 No D 0.262 0.310 0.270 No E 0.207 0.235
