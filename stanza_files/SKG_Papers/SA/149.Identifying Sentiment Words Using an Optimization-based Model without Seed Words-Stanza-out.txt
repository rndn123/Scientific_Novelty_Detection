title
Identifying Sentiment Words Using an Optimization - based Model without Seed Words
abstract
Sentiment Word Identification ( SWI ) is a basic technique in many sentiment analysis applications .
Most existing researches exploit seed words , and lead to low robustness .
In this paper , we propose a novel optimization - based model for SWI .
Unlike previous approaches , our model exploits the sentiment labels of documents instead of seed words .
Several experiments on real datasets show that WEED is effective and outperforms the state - of - the - art methods with seed words .
Introduction
In recent years , sentiment analysis ( Pang et al. , 2002 ) has become a hotspot in opinion mining and attracted much attention .
Sentiment analysis is to classify a text span into different sentiment polarities , i.e. positive , negative or neutral .
Sentiment Word Identification ( SWI ) is a basic technique in sentiment analysis .
According to ( Ku et al. , 2006 ) ( Chen et al. , 2012 ) ( Fan et al. , 2011 ) , SWI can be applied to many fields , such as determining critics opinions about a given product , tweeter classification , summarization of reviews , and message filtering , etc .
Thus in this paper , we focus on SWI .
Here is a simple example of how SWI is applied to comment analysis .
The sentence below is an movie review in IMDB database : ?
Bored performers and a lackluster plot and script , do not make a good action movie .
In order to judge the sentence polarity ( thus we can learn about the preference of this user ) , one must recognize which words are able to express sentiment .
In this sentence , " bored " and " lackluster " are negative while " good " should be positive , yet its polarity is reversed by " not " .
By such analysis , we then conclude such movie review is a negative comment .
But how do we recognize sentiment words ?
To achieve this , previous supervised approaches need labeled polarity words , also called seed words , usually manually selected .
The words to be classified by their sentiment polarities are called candidate words .
Prior works study the relations between labeled seed words and unlabeled candidate words , and then obtain sentiment polarities of candidate words by these relations .
There are many ways to generate word relations .
The authors of ( Turney and Littman , 2003 ) and ( Kaji and Kitsuregawa , 2007 ) use statistical measures , such as point wise mutual information ( PMI ) , to compute similarities in words or phrases .
Kanayama and Nasukawa ( 2006 ) assume sentiment words successively appear in the text , so one could find sentiment words in the context of seed words ( Kanayama and Nasukawa , 2006 ) .
In ( Hassan and Radev , 2010 ) and ( Hassan et al. , 2011 ) , a Markov random walk model is applied to a large word relatedness graph , constructed according to the synonyms and hypernyms in WordNet ( Miller , 1995 ) .
However , approaches based on seed words has obvious shortcomings .
First , polarities of seed words are not reliable for various domains .
As a simple example , " rise " is a neutral word most often , but becomes positive in stock market .
Second , manually selection of seed words can be very subjective even if the application domain is determined .
Third , algorithms using seed words have low robustness .
Any missing key word in the set of seed words could lead to poor performance .
Therefore , the seed word set of such algorithms demands high completeness ( by containing common polarity words as many as possible ) .
Unlike the previous research work , we identify sentiment words without any seed words in this paper .
Instead , the documents ' bag-of-words in -formation and their polarity labels are exploited in the identification process .
Intuitively , polarities of the document and its most component sentiment words are the same .
We call such phenomenon as " sentiment matching " .
Moreover , if a word is found mostly in positive documents , it is very likely a positive word , and vice versa .
We present an optimization - based model , called WEED , to exploit the phenomenon of " sentiment matching " .
We first measure the importance of the component words in the labeled documents semantically .
Here , the basic assumption is that important words are more sentiment related to the document than those less important .
Then , we estimate the polarity of each document using its component words ' importance along with their sentiment values , and compare the estimation to the real polarity .
After that , we construct an optimization model for the whole corpus to weigh the overall estimation error , which is minimized by the best sentiment values of candidate words .
Finally , several experiments demonstrate the effectiveness of our approach .
To the best of our knowledge , this paper is the first work that identifies sentiment words without seed words .
The Proposed Approach
Preliminary
We formulate the sentiment word identification problem as follows .
Let D = {d 1 , . . . , d n } denote document set .
Vector ? l = ? ? ? l 1 . . . l n ? ? ? represents their labels .
If document d i is a positive sample , then l i = 1 ; if d i is negative , then l i = ?1 .
We use the notation C = {c 1 , . . . , c V } to represent candidate word set , and V is the number of candidate words .
Each document is formed by consecutive words in C .
Our task is to predict the sentiment polarity of each word c j ? C .
Word Importance
We assume each document d i ?
D is presented by a bag-of-words feature vector ?
f i = ? ? ? f i1 . . . f iV ? ? ? , where f ij describes the importance of c j to d i .
A high value of f ij indicates word c j contributes a lot to document d i in semantic view , and vice versa .
Note that f ij > 0 if c j appears in d i , while f ij = 0 if not .
For simplicity , every ?
f i is normalized to a unit vector , such that features of different documents are relatively comparable .
There are several ways to define the word importance , and we choose normalized TF -IDF ( Jones , 1972 ) .
Therefore , we have f ij ?
T F ?IDF ( d i , c j ) , and ? ? f i ? = 1 .
Polarity Value
In the above description , the sentiment polarity has only two states , positive or negative .
We extend both word and document polarities to polarity values in this section .
Definition 1 Word Polarity Value : For each word c j ?
C , we denote its word polarity value as w( c j ) . w( c j ) > 0 indicates c j is a positive word , while w( c j ) < 0 indicates c j is a negative word . | w ( c j ) | indicates the strength of the belief of c j 's polarity .
Denote w( c j ) as w j , and the word polar - ity value vector ?
w = ? ? ? w 1 . . . w V ? ? ?. For example , if w ( " bad " ) < w (" greedy " ) < 0 , we can say " bad " is more likely to be a negative word than " greedy " .
Definition 2 Document Polarity Value :
For each document d i , document polarity value is y(d i ) = cosine ( ? f i , ? w ) = ? f i T ? ? w ? ? w ? . ( 1 ) We denote y(d i ) as y i for short .
Here , we can regard y i as a polarity estimate for d i based on ? w .
To explain this , Table 1 shows an example . " MR1 " , " MR2 " and " MR3 " are three movie review documents , and " compelling " and " boring " are polarity words in the vocabulary .
we simply use TF to construct the document feature vectors without normalization .
In the table , these three vectors , ? f 1 , ? f 2 and ? f 3 , are ( 3 , 1 ) , ( 2 , 1 ) and ( 1 , 3 ) respectively .
Similarly , we can get ? w = ( 1 , ?1 ) , indicating " compelling " is a positive word while " boring " is negative .
After normalizing ?
f 1 , ? f 2 and ? f 3 , and calculating their cosine similarities with ? w , we obtain y 1 > y 2 > 0 > y 3 .
These inequalities tell us the first two reviews are positive , while the last review is negative .
Furthermore , we believe that " MR1 " is more positive than " MR2 " .
" compelling " " boring " MR1 3 1 MR2 2 1 MR3 1 3 w 1 - 1 Table 1 : Three rows in the middle shows the feature vectors of three movie reviews , and the last row shows the word polarity value vector ? w . For simplicity , we use TF value to represent the word importance feature .
Optimization Model
As mentioned above , we can regard y i as a polarity estimate for document d i .
A precise prediction makes the positive document 's estimator close to 1 , and the negative 's close to - 1 .
We define the polarity estimate error for document d i as : e i = |y i ?
l i | = | ? f i T ? ? w ? ? w ? ? l i |. ( 2 ) Our learning procedure tries to decrease e i .
We obtain ?
w by minimizing the overall estimation error of all document samples n ?
i=1 e 2 i .
Thus , the optimization problem can be described as min ?
w n ? i=1 ( ? f i T ? ? w ? ? w ? ? l i ) 2 . ( 3 ) After solving this problem , we not only obtain the polarity of each word c j according to the sign of w j , but also its polarity belief based on | w j |.
Model Solution
We use normalized vector ?
x to substitute ? w ? ? w ? , and derive an equivalent optimization problem : min ? x E ( ? x ) = n ? i=1 ( ? f i T ? ? x ? l i ) 2 s.t. ? x? = 1 . ( 4 ) The equality constraint of above model makes the problem non-convex .
We relax the equality constraint to ? x? ? 1 , then the problem becomes convex .
We can rewrite the objective function as the form of least square regression : E ( ? x ) = ?F ? ? x ? ? l? 2 , where F is the feature matrix , and equals to ? ? ? ? ? f 1 T . . . ? f n T ? ? ? ? .
Now we can solve the problem by convex optimization algorithms ( Boyd and Vandenberghe , 2004 ) , such as gradient descend method .
In each iteration step , we update ?
x by ? x = ? ? ( ?E ) = 2 ? ? ( F T ? l ? F T F ? x ) , where ? > 0 is the learning rate .
Experiment
Experimental Setup
We leverage two widely used document datasets .
The first dataset is the Cornell Movie Review Data 1 , containing 1,000 positive and 1,000 negative processed reviews .
The other is the Stanford Large Dataset 2 ( Maas et al. , 2011 ) , a collection of 50,000 comments from IMDB , evenly divided into training and test sets .
The ground - truth is generated with the help of a sentiment lexicon , MPQA subjective lexicon 3 .
We randomly select 20 % polarity words as the seed words , and the remaining are candidate ones .
Here , the seed words are provided for the baseline methods but not for ours .
In order to increase the difficulty of our task , several non-polarity words are added to the candidate word set .
In order to demonstrate the effectiveness of our model , we select two baselines , SO - PMI ( Turney and Littman , 2003 ) and COM ( Chen et al. , 2012 ) .
Both of them need seed words .
Top -K Test
In face of the long lists of recommended polarity words , people are only concerned about the topranked words with the highest sentiment value .
In this experiment we consider the accuracy of the top K polarity words .
The quality of a polarity word list is measured by p@K = N right , K K , where N right , K is the number of top - K words which are correctly recommended .
Figure 1 shows the final result of p@K , which is the average score of the positive and negative list .
We can see that in both datasets , our approach highly outperforms two baselines , and the precision is 14.4 % -33.0 % higher than the best baseline .
p@10s of WEED for Cornell and Stanford datasets reach to 93.5 % and 89.0 % , and it shows the top 10 words in our recommended list is exceptionally reliable .
As the size of K increases , the accuracy of all methods falls accordingly .
This shows three approaches rank the most probable polarity words in the front of the word list .
Compared with the small dataset , we obtain a better result with large K on the Stanford dataset .
Case Study
We conduct an experiment to illustrate the characteristics of three methods .
Table 3 shows top - 10 positive and negative words for each method , where the bold words are the ones with correct polarities .
From the first two columns , we can see the accuracy of WEED is very high , where positive words are absolutely correct and negative word list makes only one mistake , " plot " .
The other columns of this table shows the baseline methods both achieve reasonable results but do not perform as well as WEED .
Our approach is able to identify frequently used sentiment words , which are vital for the applications without prior sentiment lexicons .
The sentiment words identified by SO - PMI are not so representative as WEED and COM .
For example , " skillfully " and " giddy " are correctly classified but they are not very frequently used .
COM tends to assign wrong polarities to the sentiment words although these words are often used .
In the 5 th and 6 th columns of Table 3 , " bad " and " horror " are recognized as positive words , while " pretty " and " fun " are recognized as negative ones .
These concrete results show that WEED captures the generality of the sentiment words , and achieves a higher accuracy than the baselines .
Conclusion and Future Work
We propose an effective optimization - based model , WEED , to identify sentiment words from the corpus without seed words .
The algorithm exploits the sentiment information provided by the documents .
To the best of our knowledge , this paper is the first work that identifies sentiment words without any seed words .
Several experiments on real datasets show that WEED outperforms the stateof - the - art methods with seed words .
Our work can be considered as the first step of building a domain-specific sentiment lexicon .
Once some sentiment words are obtained in a certain domain , our future work is to improve WEED by utilizing these words .
Figure 1 : Top-K Test
