title
Auto-Dialabel : Labeling Dialogue Data with Unsupervised Learning
abstract
The lack of labeled data is one of the main challenges when building a task - oriented dialogue system .
Existing dialogue datasets usually rely on human labeling , which is expensive , limited in size , and in low coverage .
In this paper , we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots .
In this framework , we collect a set of context features , leverage an autoencoder for feature assembly , and adapt a dynamic hierarchical clustering method for intent and slot labeling .
Experimental results show that our framework can promote human labeling cost to a great extent , achieve good intent clustering accuracy ( 84.1 % ) , and provide reasonable and instructive slot labeling results .
Introduction Building a task- oriented dialogue system is challenging .
In real world , unlabeled dialogue data is usually available for companies who has interactive platform with users .
Based on these unlabeled data , the well - known sequence - to-sequence framework ( Sutskever et al. , 2014 ; Cho et al. , 2014 ) is widely used in dialogue response generation ( Vinyals and Le , 2015 ; Sordoni et al. , 2015 ; Shang et al. , 2015 ) , but it can not handle taskoriented scenario well since it needs accuracy instead of fluency .
Generally , a task - oriented dialogue system needs to realize user 's intent , which means user 's current goal in a dialogue session .
To fulfill this intent , the system usually needs several key information ( slot ) .
As shown in Figure 1 , a dialogue utterance is labeled with intent flight , and several slots such as its from location , arrive time .
Training a task- oriented dialogue system usually needs abundant such labeled data .
Existing well -known dialogue datasets are mostly human-labeled , such as ATIS ( Hemphill et al. , 1990 ) , DSTC ( Williams et al. , 2013 ) , Frames ( El Asri et al. , 2017 ) , and the Stanford dataset ( Eric et al. , 2017 ) .
Human-labeled datasets are expensive to produce , limited in size , and restricted to a specific domain , which make them difficult to extend .
Moreover , the intent and slot label sets are usually decided by human experience .
Since we usually do not know the exact intents or slots of a new unlabeled data , the assigned label names may be subjective in some extent .
To better assist the human labeling process , Wen et al . ( 2017 ) proposed an improved version of Wizard - of - Oz ( Kelley , 1984 ) data collection methods , which incorporate crowdsourcing to collect domain specific data .
Instead of humanlabeling , Cohn et al . ( 1995 ) proposed a semisupervised framework active learning , which can minimize the need for human annotation in a certain extent .
However , these approaches are still mostly or selectively human-labeled , and may be distracted by the disadvantages raised above .
Thus , in this paper , we propose an unsupervised labeling method to automatically cluster dialogue intents and corresponding slots .
Since the intent of a dialogue utterance may depend on its topic or some frequent key words , utterances in the same intent may share similar context features .
Hence , we cluster these utterances into different intents .
Given a new dialogue dataset whose number and type of intents are uncharted , the clustering process does not need any prior information and can derive a new set of intents .
We modify dynamic clustering methods to automatically decide the number of clustering classes .
The clustered intents are labeled as integer indices .
Before clustering , for better utilization of extracted features , we leverage an autoencoder to map all features into the same space .
For the slot labeling , since the phrases of same slots such as location and time may share same type of features , we leverage a similar way to cluster slots within each intent .
I want to fly one way from Chicago on 8 am this Wednesday and arrive in San Francisco 11 pm in the evening .
Experimental results on the ATIS dataset ( Hemphill et al. , 1990 ) show that our proposed methods can achieve 84.1 % intent clustering accuracy , and provide reasonable and instructive slot labeling results .
Moreover , since the whole process is unsupervised , it can be much faster and more consistent and objective than human labeling , and extended to other domains .
We think the proposed methods can be a good attempt for the automatic dialogue labeling task .
Intent : flight
Slot
Auto-Dialabel Framework Formally , we treat a multi-turn dialogue session D = { Q 1 , R 1 , ? ? ? , Q N , R N } as a sequence of N query - response pairs between two interlocutors , in which query Q * represents user 's utterance and response R * represents assistance 's utterance .
Each query utterance Q t should be labeled with an intent I t ? [ 0 , K ] , which represents the interlocutor 's purpose in current utterance .
K is the number of intent classes , and should be dynamically decided during the labeling procedure .
Since each intent has its corresponding slots , for intent I t , we set its slot as S t = { S t,1 , ? ? ? , S t, Lt } , where L t is number of slots in I t .
S t is also learned automatically and dynamically .
In detail , given a set of query utterances , the unsupervised dialogue auto-labeling system labels the intents and slots based on the following steps : feature extraction and assembly , which extracts a set of context features F from query utterance , and leverages an autoencoder to compress each extracted feature into same size , then concatenate them as the assembled feature embedding E. intent clustering , which adopt dynamic hierarchical clustering to get intents based on E. slot clustering , which leverages the same clustering methods to get slots based on word-level features and labeled intents .
The process of intent labeling is shown in Figure 2 .
Slot labeling has a similar process to intent labeling .
Features are a key to both intent labeling and slot labeling .
We first introduce the feature extraction and assembly , which involves all the features used in our model .
It is noted that we leverage all the features for intent clustering while we only use word - level features for slot labeling .
Feature Extraction and Assembly
We design a set of context features F * at different levels of granularity to model the query utterance , including word embedding , POS tag , frequent key words , and topic features .
Word Embedding Given an n-words Q = {w 1 , ? ? ? , w n } , intuitively , the feature of Q relied on each words within it .
One frequently - used way to model a sentence by words is to use a mean pooling for all word embeddings : F W = 1 n n i embedding of w i POS Tag Since the distribution of the POS tag may effect the sentence 's structure in syntactic level , we use bag-of - POS as the POS tag feature F P .
Given n p types of POS tags , F P = {p 1 , ? ? ? , p np } is a discrete vector in which each dimension p i represents the existence of a POS tag P OS i .
Frequent Key Words
In several occasions , the intent of a sentence is decided by some key words .
So we specially emphasize it by introducing the frequent key words feature F X . F X = {x 1 , ? ? ? , x c } represents the information of key words in query utterance .
To centralize the word information , we cluster all the noun words into c different classes by its word embedding , then count the occurrence frequency of each class as a discrete vector F X . Topic
The topic-level feature denotes the topic information of query utterance .
We leverage an unsupervised topic model to get the topic distribution F T ?
R t as the topic-level feature , t is the number of topics .
Since query utterance are short
The assembled feature embedding E is the combination of each F i .
Since each F i has different dimensions , which may unequally affect the clustering results , we use an autoencoder to encode all F i into same dimensions as E i , then we concatenate all the E i as E , which will be used in the clustering procedure , as shown in Figure 2 .
Intent Clustering Since given a new set of dialogue data , we do not know the number of intents it contains , thus we adapt the hierarchical clustering method to a dynamic version which can automatically decide the end of the clustering process by the cohesion of different classes .
At the beginning of clustering , each query utterance is considered as a different class .
At each steps , the cluster model chooses two classes which are the closest in distance , and cluster them into the same class .
We use radial basis function ( rbf ) as the clustering distance .
This process ends when all the distances exceed the threshold value , which is tuned on a labeled dataset , and fixed for future use .
Slot Clustering Since slots usually correspond to intents , we do slot labeling based on both the query utterance and the labeled intents .
Considering that most slots are composed of noun words , we extract all the noun words in a dialogue , and leverage the same clustering methods as in the intent clustering part to cluster them into different slot classes .
Note that the slot clustering are word-level .
So in feature extraction , it did not extract the topic-level features .
Experiments
Dataset and Baseline Systems
We conduct experiments on the widely used ATIS dataset ( Hemphill et al. , 1990 ) .
The clustering parameters are tuned on the training set of the ATIS dataset ( Hemphill et al. , 1990 ) , while the experiments are conducted on its test set .
During clustering , we tune the clustering distance limit since it may be more general than the number of classes , and can be transferred to other datasets .
The radial basis function ( rbf ) is used with sklearn default settings .
Since there is no existing systems specially designed for unsupervised dialogue labeling , we choose three well -known and widely used sentence representation methods , and leverage the results vector for clustering as our baseline systems .
The first one is the BTM topic model ( Yan et al. , 2013 ) .
We use the topic distribution for clustering .
The second one is the CDSSM model proposed by Shen et al . ( 2014 ) .
We use the clickthrough data for pre-training and get encoded sentence vector for clustering .
The third one is the sentence embedding calculated by the average of word embedding in query utterance .
For each baseline , we leverage the k-means for clustering and use the gold intent number as the cluster number of these models .
Intent Labeling
We leverage glove .6B.300d ( Pennington et al. , 2014 ) as the pre-trained word embedding in all the baseline and proposed systems .
The POS tag is labeled through NLTK toolkit ( Bird et al. , 2009 ) .
The topic number of BTM is set to 20 as default .
Each encoded feature dimension is set to 30 , then concatenated to a 120 dimension assembled vector .
We have 17 kinds of gold intents , and our system predicted 18 kinds of intents .
Since the clustering results have no label information , we sort the predicted intent classes and gold intent classes by size , and manually map them .
We leverage intent labeling accuracy as the evaluation metrics .
Overall Performance
Our auto-dialabel can reduce the tedious work of understanding the intent of each dialogue utterance and finding slot words in it .
It clusters all utterances into several intent classes , and words into slot classes , which leaves human labelers only small labors to set label names for each class .
Experimental results show that with auto-dialabel , we can label the whole ATIS dataset in less than 1 hour from end to end , compared to days we spend by human labeling .
Table 1 shows the performance comparison of our model with other baseline systems .
From Table 1 , we find that our proposed auto-dialabel achieves high intent labeling accuracy ( 84.1 % ) and outperforms other baseline systems by a large margin .
This may be because that the baseline systems are not specifically designed for intent scenario so that they can not handle the intent and slot clustering well , or are not capable of capturing complex intent relevant information .
Compared with these baseline clustering methods , our method can dynamically determine the intent number and is more practical .
Ablation
Slot Labeling
Due to the limitation of space , we just show some slot clustering result cases in Table 3 .
After manually assigning names , we find that auto-dialabel can extract about 70 % of the slots with accuracy , including city name , period of day , month name , and day name .
The labeled slots above are the main slots for this scenario and could cover a large portion of airline ticket reservation demands .
Generally , the slots clustered by auto-dialabel are reasonable and constructive .
Conclusion
In this paper , we formalize the auto- labeling task for dialogue data , and propose an unsupervised framework auto-dialabel .
We design a set of linguistics and neural - network based features , leverage an autoencoder for feature assembly , and modify a hierarchical clustering method for dialogue intents and slots labeling .
Experimental results show that our framework can achieve 84.1 % intent clustering accuracy , and provide reasonable and instructive slot labeling results .
Figure 1 : 1 Figure 1 : An example of the dialogue labeling task .
