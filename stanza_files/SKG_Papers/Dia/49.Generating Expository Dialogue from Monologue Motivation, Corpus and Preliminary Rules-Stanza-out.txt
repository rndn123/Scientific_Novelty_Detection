title
Generating Expository Dialogue from Monologue : Motivation , Corpus and Preliminary Rules
abstract
Generating expository dialogue from monologue is a task that poses an interesting and rewarding challenge for Natural Language Processing .
This short paper has three aims : firstly , to motivate the importance of this task , both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications ; secondly , to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge ; and , finally , to describe work - in- progress on semi-automatic construction of Monologueto- Dialogue ( M2D ) generation rules .
Introduction
The tasks of text generation - e.g. , Reiter et al. ( 2005 ) and Demir et al . ( 2008 ) - and generation in dialogue - e.g. , Stent ( 2002 ) and DeVault et al . ( 2008 ) - are central topics in Natural Language Generation ( NLG ) .
What sets the two tasks apart is the interactive nature of dialogue , where participants need to adapt their contributions to each other .
This paper introduces an NLG task , the generation of expository dialogue , to the Computational Linguistics community which occupies the middle ground between these two tasks .
An expository dialogue is an authored conversation between two fictive characters .
It can be presented as text , audio or film .
Although there is no real-time interactivity , in expository dialogue the contributions of the characters do need to mesh with each other .
The main purpose of expository dialogue is to present information ( a description , explanation or definition ) to the reader , hearer or viewer , in contrast with dramatic dialogue , which tells a story .
The use of expository dialogue goes back as far as Plato ( c. 470- 399 BC ) , who expressed his ideas as dialogues between Socrates and his contemporaries .
Recently , a number of empirical studies show that for some purposes expository dialogue has advantages over monologue : for learners , dialogue can be more memorable , stimulate them to formulate their own questions ( Craig et al. , 2000 ) , and get them to talk with each other ( Lee et al. , 1998 ) .
Expository dialogue has also been found to be more effective for persuasion ( Suzuki and Yamada , 2004 ) .
Additionally , dialogue lends itself very well for multimedia presentations by computer -animated agents ( Andr ?
et al. , 2000 ; van Deemter et al. , 2008 ) . Potential application domains include education , ( serious ) games and E-Health .
In education , information from textbooks could be presented in dialogue form , possibly using virtual reality platforms such as Second Life .
Automatically generating dialogue from text for non-player characters could have a tremendous impact on the gaming industry ; e.g. , ( IGDA Game Writers SIG , 2003 ) state that the amount of dialogue script for a characterdriven computer game is usually many times that for the average film .
In connection with E-health , consider patient information leaflets , which are often left unread ; presenting them as movies between a virtual pharmacist and client may help address this .
Thus instead of being presented with ( 1 ) a .
You can take aspirin , b. if you have a headache .
c.
Though aspirin does have side effects : d. it can harm circulation .
the patient could watch a movie on their mobile device of an exchange between a virtual client ( layman , L ) and pharmacist ( expert , E ) : ( 2 ) L : What if I have a headache ?
E : You can take aspirin L : But does it have side effects ?
E : Yes , it can harm circulation .
So far , research on generating expository dialogue has been firmly rooted in classical AI approaches .
Work in this area starts from knowledge representations or databases ( Andr ?
et al. , 2000 ) , and even research that does take text as input - e.g. , describe a system for generating dialogues such as Example 2 - relies on handcrafted rules .
Two challenges present themselves for NLP research : 1 ) generation of expository dialogue from text , and 2 ) use of data-driven , rather than manually authored , generation rules .
Apart from the cost of manually authoring generation rules , previous research has found that humanauthored rules can result in ' too much information [ being ] given too quickly ' ( Williams et al. , 2007 ) , which can be addressed by conversational padding .
We argue that rather than trying to invent padding rules , the best strategy is to learn rules automatically from professionally authored dialogues .
The CODA Corpus
To make inroads into data-driven dialogue generation , we first need to have the necessary resources .
We propose to view Monologue-to - Dialogue ( M2D ) generation as analogous to machine translation ; consequently we need a parallel corpus for learning mappings from the source ( monologue ) to the target ( dialogue ) texts .
In the ongoing CODA 1 project we have created such a corpus .
It consists of professionally authored dialogues 2 that have been aligned with monologues ( written by ourselves ) expressing the same information .
Since our ultimate aim is to generate dialogues that resemble those written by 1 COherent Dialogue Automatically generated from text 2 Most dialogues are from the Gutenberg library to facilitate our planned release of the corpus to the research community .
acclaimed authors , we started with professionally authored dialogues and created the corresponding monologues .
From a practical point of view , it was more feasible to use existing dialogue by acclaimed authors than to hire professional authors to write dialogue based on monologues .
We have annotated both dialogues and monologues : dialogue with dialogue acts and monologue with discourse relations .
3
We achieved 91 % agreement on segmentation and kappa= .
82 for dialogue act annotation on 11 dialogue act tags .
We developed a D2 MTranslation tool for monologue authoring , segmentation and dialogue annotation .
In January 2010 , the corpus included 500 turns from " What is man ? " , a dialogue by Mark Twain , and 88 turns from " Evolving Algebras " , an academic paper in the form of dialogue by Yuri Gurevich .
4 Both of these expository dialogues present conversation between an expert ( Old Man in Twain and Author in Gurevich ) and a layman ( Young Man in Twain and Quisani in Gurevich ) .
Table 1 shows an example of a dialogue fragment , aligned monologue and dialogue act annotations .
The discourse structure of the monologue is depicted in Figure 1 .
Table 2 shows the distribution of the dialogue acts between expert and layman .
In both dialogues , the Figure 1 : Discourse structure of the monologue in Table 1 most frequent dialogue act is Explain , where a character presents information ( as a new idea or as a response to another utterance ) .
Also , in both dialogues the layman asks more often for clarification than the expert .
The distribution over information requests ( yes / no , factoid , and complex questions ) and responses ( yes , no , factoid ) differs between the two dialogues : in Twain 's dialogue , the expert mostly requests information and the layman responds to requests , whereas in Gurevich 's dialogue it is the other way around .
The differences in style suggests that the M2D mapping rules will be author or style-specific .
By applying M2D rules obtained from two different authors ( e.g. , Twain and Gurevich ) to the same text ( e.g. , the aspirin example ) we can generate two different dialogues .
This will enable us to vary the presentation style of automatically generated dialogues .
Rules
We automatically derive M2D rules from the aligned discourse relations and dialogue acts in our parallel corpus of monologues and dialogues .
Table 3 shows three rules generated from the parallel dialoguemonologue fragment in Table 1 .
The first rule , R1 , is based on the complete discourse structure of the monologue ( i- iv ) , whereas R2 and R3 are based on only a part of it : R2 is based on i-iii , whereas R3 is based on i and ii .
By generating rules from subtrees of a discourse structure , we obtain several rules from a single dialogue fragment in the corpus .
Let us illustrate the use of such rules by applying them to Example 1 about aspirin .
The relations between the clauses of the example are depicted in Figure 2 ( 1 ) .
To generate a dialogue , we apply a matching M2D rule .
Alternatively , we can first simplify the discourse structure of the monologue by removing relation nodes as illustrated in Figure 2 ( 2 - 4 ) .
The simplified structure in Figure 2 ( 2 ) matches rule R2 from Table 3 .
By applying R2 we generate the dialogue in Table 4 : the expert asks a complex question composed of clauses a and b , which the layman answers with an explanation generated from the same set of clauses .
Then the expert offers a contradicting explanation generated from c and d .
To generate dialogue sentences for a corresponding discourse structure we are adapting the approach to paraphrasing of Barzilay and McKeown ( 2001 ) .
Conclusion
This short paper presented three angles on the Monologue-to- Dialogue ( M2D ) task .
First , as an opinion piece , it motivates the task of generating expository dialogue from monologue .
We described empirical research that provides evidence for the effectiveness of expository dialogue and discussed applications from education , gaming and E-health .
Second , we introduced the CODA corpus for addressing the task .
Finally , we reported on workin-progress on semi-automatic construction of M2D rules .
Our implemented algorithm extracts several M2D rules from the corpus that are applicable even to a relatively simple input .
Additionally , frequency analysis of dialogue tags suggests that there is scope for generating different dialogue styles .
The timeliness of this research is evidenced by the emergence of a Question Generation ( QG ) commu-ID Dialogue Structure Monologue Structure R1 E : Complex Question ( i- ii ) Contrast ( Contrast ( Condition ( i , ii ) , iii , iv ) ) L : Explain ( i- ii ) E : Explain-Contradict ( iii ) E : YNQuestion ( iv ) R2 E : Complex Question ( i- ii ) Contrast ( Condition ( i , ii ) , iii ) L : Explain ( i - ii ) E : Explain-Contradict ( iii ) R3 E : Complex Question ( i- ii ) Condition ( i , ii ) L : Explain ( i- ii ) ( Rus and Graesser , 2009 ) for 2010 .
The CODA corpus should prove to be a useful resource not only for M2D researchers , but also for the QG community .
Figure 2 : 2 Figure 2 : Discourse structures of the monologue in Example 1 . a- b and c-d indicate a concatenation of two clauses .
