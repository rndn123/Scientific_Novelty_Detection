title
Improving Multi-turn Dialogue Modelling with Utterance ReWriter
abstract
Recent research has made impressive progress in single-turn dialogue modelling .
In the multi-turn setting , however , current models are still far from satisfactory .
One major challenge is the frequently occurred coreference and information omission in our daily conversation , making it hard for machines to understand the real intention .
In this paper , we propose rewriting the human utterance as a pre-process to help multi-turn dialgoue modelling .
Each utterance is first rewritten to recover all coreferred and omitted information .
The next processing steps are then performed based on the rewritten utterance .
To properly train the utterance rewriter , we collect a new dataset with human annotations and introduce a Transformer - based utterance rewriting architecture using the pointer network .
We show the proposed architecture achieves remarkably good performance on the utterance rewriting task .
The trained utterance rewriter can be easily integrated into online chatbots and brings general improvement over different domains .
1
Introduction
Dialogue systems have made dramatic progress in recent years , especially in single- turn chit-chat and FAQ matching ( Shang et al. , 2015 ; Ghazvininejad et al. , 2018 ; Molino et al. , 2018 ; . Nonethless , multi-turn dialogue modelling still remains extremely challenging ( Vinyals and Le , 2015 ; Serban et al. , 2016 Serban et al. , , 2017
Shen et al. , 2018 a , b) .
The challenge is multi-sided .
One most important difficulty is the frequently occurred coreference and information omission in our daily conversations , especially in pro-drop languages like Chinese or Japanese .
From our preliminary study of 2,000 Chinese multi-turn con-Table 1 : An example of multi-turn dialogue .
Each utterance 3 is rewritten into Utterance 3 . Green means coreference and blue means omission .
versations , different degrees of coreference and omission exist in more than 70 % of the utterances .
Capturing the hidden intention beneath them requires deeper understanding of the dialogue context , which is difficult for current neural networkbased systems .
Table 1 shows two typical examples in multi-turn dialogues . " ? " ( he ) from Context 1 is a coreference to " ? " ( Messi ) and " ? ? " ( Why ) from Context 2 omits the further question of " ? " ( Why do you like Tatanic most ) ? .
Without expanding the coreference or omission to recover the full information , the chatbot has no idea how to continue the talk .
To address this concern , we propose simplifying the multi-turn dialogue modelling into a singleturn problem by rewriting the current utterance .
The utterance rewriter is expected to perform ( 1 ) coreference resolution and ( 2 ) information completion to recover all coreferred and omitted mentions .
In the two examples from Table 1 , each utterance 3 will be rewritten into utterance 3 . Afterwards , the system will generate a reply by only looking into the utterance 3 without considering the previous turns utterance 1 and 2 .
This simplification shortens the length of dialogue con-text while still maintaining necessary information needed to provide proper responses , which we believe will help ease the difficulty of multi-turn dialogue modelling .
Compared with other methods like memory networks ( Sukhbaatar et al. , 2015 ) or explicit belief tracking ( Mrk ?i? et al. , 2017 ) , the trained utterance rewriter is model - agnostic and can be easily integrated into other black - box dialogue systems .
It is also more memory - efficient because the dialogue history information is reflected in a single rewritten utterance .
To get supervised training data for the utterance rewriting , we construct a Chinese dialogue dataset containing 20 k multi-turn dialogues .
Each utterance is paired with corresponding manually annotated rewritings .
We model this problem as an extractive generation problem using the Pointer Network .
The rewritten utterance is generated by copying words from either the dialogue history or the current utterance based on the attention mechanism ( Bahdanau et al. , 2014 ) .
Inspired by the recently proposed Transformer architecture ( Vaswani et al. , 2017 ) in machine translation which can capture better intra-sentence word dependencies , we modify the Transformer architecture to include the pointer network mechanism .
The resulting model outperforms the recurrent neural network ( RNN ) and original Transformer models , achieving an F1 score of over 0.85 for both the coreference resolution and information completion .
Furthermore , we integrate our trained utterance rewriter into two online chatbot platforms and find it leads to more accurate intention detection and improves the user engagement .
In summary , our contributions are : 1 . We collect a high-quality annotated dataset for coreference resolution and information completion in multi-turn dialogues , which might benefit future related research .
2 . We propose a highly effective Transformerbased utterance rewriter outperforming several strong baselines .
3 . The trained utterance rewriter , when integrated into two real- life online chatbots , is shown to bring significant improvement over the original system .
In the next section , we will first go over some related work .
Afterwards , in Section 3 and 4 , our collected dataset and proposed model are introduced .
The experiment results and analysis are presented in Section 5 .
Finally , some conclusions are drawn in Section 6 .
2 Related Work
Sentence Rewriting Sentence rewriting has been widely adopted in various NLP tasks .
In machine translation , people have used it to refine the output generations from seq2seq models ( Niehues et al. , 2016 ; Junczys -Dowmunt and Grundkiewicz , 2017 ; Grangier and Auli , 2017 ; Gu et al. , 2017 ) .
In text summarization , reediting the retrieved candidates can provide more accurate and abstractive summaries ( See et al. , 2017 ; Chen and Bansal , 2018 ; Cao et al. , 2018 ) .
In dialogue modelling , Weston et al . ( 2018 ) applied it to rewrite outputs from a retrieval model , but they pay no attention to recovering the hidden information under the coreference and omission .
Concurrent with our work , Rastogi et al . ( 2019 ) adopts a similar idea on English conversations to simplify the downstream SLU task by reformulating the original utterance .
Rewriting the source input into some easy - to - process standard format has also gained significant improvements in information retrieval ( Riezler and Liu , 2010 ) , semantic parsing ( Chen et al. , 2016 ) or question answering ( Abujabal et al. , 2018 ) , but most of them adopt a simple dictionary or template based rewriting strategy .
For multi-turn dialogues , due to the complexity of human languages , designing suitable template - based rewriting rules would be timeconsuming .
Coreference Resolution Coreference resolution aims to link an antecedent for each possible mention .
Traditional approaches often adopt a pipeline structure which first identify all pronouns and entities then run clustering algorithms ( Haghighi and Klein , 2009 ; Lee et al. , 2011 ; Durrett and Klein , 2013 ; Bj?rkelund and Kuhn , 2014 ) .
At both stages , they rely heavily on complicated , fine - grained features .
Recently , several neural coreference resolution systems ( Clark and Manning , 2016 a , b) utilize distributed representations to reduce human labors .
Lee et al. ( 2017 ) reported state - of - the - art results with an end-to - end neural coreference resolution system .
However , it requires computing the scores for all possible spans , which is computationally inefficient on online dialogue systems .
The recently proposed Transformer adopted the self-attention mechanism which could implicitly capture inter-word dependencies in an unsupervised way ( Vaswani et al. , 2017 ) .
However , when multiple coreferences occur , it has problems properly distinguishing them .
Our proposed architecture is built upon the Transformer architecture , but perform coreference resolution in a supervised setting to help deal with ambiguous mentions .
Dataset
To get parallel training data for the sentence rewriting , we crawled 200k candidate multi-turn conversational data from several popular Chinese social media platforms for human annotators to work on .
Sensitive information is filtered beforehand for later processing .
Before starting the annotation , we randomly sample 2,000 conversational data and analyze how often coreference and omission occurs in multi-turn dialogues .
In the annotation process , human annotators need to identify these two situations then rewrite the utterance to cover all hidden information .
An example is shown in Table 1 . Annotators are required to provide the rewritten utterance 3 given the original conversation [ utterance 1,2 and 3 ] .
To ensure the annotation quality , 10 % of the annotations from each annotator are daily examined by a project manager and feedbacks are provided .
The annotation is considered valid only when the accuracy of examined results surpasses 95 % .
Apart from the accuracy examination , the project manage is also required to ( 1 ) select topics that are more likely to be talked about in daily conversations , ( 2 ) try to cover broader domains and ( 3 ) balance the proportion of different coreference and omission patterns .
The whole annotation takes 4 months to finish .
In the end , we get 40 k high-quality parallel samples .
Half of them are negative samples which do not need any rewriting .
The other half are positive samples where rewriting is needed .
Table 3
Model
Problem Formalization
We denote each training sample as ( H , U n ? R ) .
H = { U 1 , U 2 , . . . , U n?1 } represents the dialogue history containing the first n ?
1 turn of utterances .
U n is the nth turn of utterance , the one that needs to be rewritten .
R is the rewritten utterance after recovering all corefernced and omitted information in U n .
R could be identical to U n if no coreference or omission is detected ( negative sample ) .
Our goal is to learn a mapping function p( R | ( H , U n ) ) that can automatically rewrite U n based on the history information H .
The process is to first encode ( H , U n ) into s sequence of vectors , then decode R using the pointer network .
The next section will explain the steps in order .
Encoder
We unfold all tokens in ( H , U n ) into ( w 1 , w 2 , . . . , w m ) .
m is the number of tokens in the whole dialogue .
An end-of-turn delimiter is inserted between each two turns .
The unfolded sequence of tokens are then encoded with Transformer .
We concatenate all tokens in ( H , U n ) as the input , in hope that the Transformer can learn rudimentary coreference information within them by means of the self-attention mechanism .
For each token w i , the input embedding is the sum of its word embedding , position embedding and turn embedding : I ( w i ) = W E( w i ) + P E( w i ) + T E( w i )
The word embedding W E(w i ) and position embedding P E(w i ) are the same as in normal Transformer architectures ( Vaswani et al. , 2017 ) .
We add an additional turn embedding T E(w i ) to indicate which turn each token belongs to .
Tokens from the same turn will share the same turn embedding .
The input embeddings are then forwarded into L stacked encoders to get the final encoding representations .
Each encoder contains a self-attention layer followed by a feedforward neural network . : E ( 0 ) = I ( w 1 ) , I ( w 2 ) , . . . , I ( w m ) E ( l ) = FNN ( MultiHead ( E ( l?1 ) , E ( l?1 ) , E ( l?1 ) ) ) FNN is the feedforward neural network and MultiHead ( Q , K , V ) is a multi-head attention function taking a query matrix Q , a key matrix K , and a value matrix V as inputs .
Each self-attention and feedforward component comes with a residual connection and layer - normalization step , which we refer to Vaswani et al . ( 2017 ) for more details .
The final encodings are the output from the Lth encoder E ( L ) .
Decoder
The decoder also contains L layers , each layer is composed of three sub-layers .
The first sub-layer is a multi-head self-attention : M l = MultiHead ( D ( l?1 ) , D ( l?1 ) , D ( l?1 ) ) D ( 0 ) = R .
The second sub-layer is encoderdecoder attention that integrates E ( L ) into the decoder .
In our task , as H and U n serve different purposes , we use separate key -value matrix for tokens coming from the dialogue history H and those coming from U n .
The encoded sequence E ( L ) obtained from the last section is split into E ( L ) H ( en- codings of tokens from H ) and E ( L ) Un ( encodings of tokens from U n ) then processed separately .
The encoder-decoder vectors are computed as follows : C( H ) l = MultiHead ( M ( l ) , E ( L ) H , E ( L ) H ) C( U n ) l = MultiHead ( M ( l ) , E ( L ) Un , E ( L ) Un )
The third sub-layer is a position - wise fully connected feed - forward neural network : D ( l ) = FNN ( [ C ( H ) l ? C( U n ) l ] ) where ? denotes vector concatenation .
Output Distribution
In the decoding process , we hope our model could learn whether to copy words from H or U n at different steps .
Therefore , we impose a soft gating weight ? to make the decision .
The decoding probability is computed by combining the atten-tion distribution from the last decoding layer : p( R t =w |H , U n , R <t ) =? i:( w i =w ) ?( w i ?H ) a t , i +( 1 ? ) j:( w j =w ) ? ( w j ?Un ) a t , j a = Attention ( M ( L ) , E ( L ) Un ) a = Attention ( M ( L ) , E ( L ) H ) ? = ? w d D L t + w H C( H ) L t + w U C( U n ) L t a and a are the attention distribution over tokens in H and U n respectively .
w d , w H , and w U are parameters to be learned , ? is the sigmoid function to output a value between 0 and 1 .
The gating weight ? works like a sentinel to inform the decoder whether to extract information from the dialogue history H or directly copy from U n .
If U n contains neither coreference nor information omission .
? would be always 1 to copy the original U n as the output .
Otherwise ? becomes 0 when a coreference or omission is detected .
The attention mechanism is then responsible of finding the proper coreferred or omitted information from the dialogue history .
The whole model is trained endto-end by maximizing p( R|H , U n ) .
Experiments
We train our model to perform the utterance rewriting task on our collected dataset .
In this section , we focus on answering the following two questions : ( 1 ) How accurately our proposed model can perform coreference resolution and information completion respectively and ( 2 ) How good the trained utterance rewriter is at helping off -theshelf dialogue systems provide more appropriate responses .
To answer the first question , we compare our models with several strong baselines and test them by both automatic evaluation and human judgement .
For the second question , we integrate our rewriting model to two online dialogue systems and analyze how it affects the humancomputer interactions .
The following section will first introduce the compared models and basic settings , then report our evaluation results .
Compared Models
When choosing compared models , we are mainly curious to see ( 1 ) whether the self-attention based Transformer architecture is superior to other networks like LSTMs , ( 2 ) whether the pointer - based generator is better than pure generation - based models and ( 3 ) whether it is preferred to split the attention by a coefficient ? as in our model .
With these intentions , we implement the following four types of models for comparison : 1 . ( L/T ) - Gen : Pure generation - based model .
Words are generated from a fixed vocabulary .
2 . ( L/T ) - Ptr-Net : Pure pointer - based model as in .
Words can only be copied from the input .
3 . ( L/T ) - Ptr-Gen : Hybrid pointer + generation model as in See et al . ( 2017 ) .
Words can be either copied from the input or generated from a fixed vocabulary .
4 . ( L/T ) - Ptr-? :
Our proposed model which split the attention by a coefficient ?. ( L/T ) denotes the encoder-decoder structure is the LSTM or Transformer .
For the first three types of models , we unfold all tokens from the dialogue as the input .
No difference is made between the dialogue history and the utterance to be rewritten .
Experiment Settings Transformer - based models
We set the hidden size as 512 . characters and 816 other tokens ) , including the end-of-turn delimiter and a special UNK token for all unknown words .
In the testing stage , all models decode words by beam search with beam size set to 4 .
Quality of Sentence ReWriting Precision Recall F1
Accuracy of Generation
We first evaluate the accuracy of generation leveraging three metrics : BLEU , ROUGE , and the exact match score ( EM ) ( the percentage of decoded sequences that exactly match the human references ) .
For the EM score , we report separately on the positive and negative samples to see the difference .
We report BLEU -1 , 2 , 4 scores and the F1 scores of ROUGE -1 , 2 , L .
The results are listed in Table 4 .
We can have several observations in response to the three questions proposed in the beginning of Section 5.1 : 1 . Transformer - based models lead to signif-icant improvement compare with LSTMbased counterparts .
This implies the selfattention mechanism is helpful in identifying coreferred and omitted information .
More analysis on how it helps coreference resolution can be seen in the next section .
2 . The generation mode does not work well in our setting since all words can be retrieved from either H or U n .
Pointer - based models outperform the more complex generationbased and hybrid ones .
3 . Separately processing H and U n then combine their attention with a learned ?
performs better than treating the whole dialogue tokens as s single input , though the improvement is less significant compared with previous two mentions .
Overall our proposed model achieves remarkably good performance , with 55.84 % of its generations exactly matches the human reference on the positive samples .
For negative samples , our model properly copied the the original utterances in 98.14 % of the cases .
It suggests our model is already able to identify the utterances that do not need rewriting .
Future work should work on improving the rewriting ability on positive samples .
Coreference Resolution
Apart from the standard metrics for text generation , we specifically test the precision , recall and F1 score of coreference resolution on our task .
A pronoun or a noun is considered as properly coreferred if the rewritten utterance contains the correct mention in the corresponding referent .
The result is shown in Table 5 .
To compare with current state - of - the- art models .
We train the model from Lee et al . ( 2017 ) on our task and report the results on the first row .
The result is quite consistent with the findings from the last section .
Our final model outperforms the others by a large margin , reaching a precision score of 93 % and recall score of 90 % .
It implies our model is already quite good at finding the proper coreference .
Future challenges would be more about information completion .
Figure 2 further provides an examples of how the Transformer can help implicitly learn the coreference resolution through the self-attention mechanism .
The same example is also shown in Table 1 . The pronoun " ? " ( he ) in the utterance is properly aligned to the mention " ? " ( Messi ) in the dialogue history , also partially to " ? " ( player ) which is the occupation of him .
Information Completion Similar as coreference resolution , we evaluate the quality of information completeness separately .
One omitted information is considered as properly completed if the rewritten utterance recovers the omitted words .
Since it inserts new words to the original utterance , we further conduct a human evaluation to measure the fluency of rewritten utterances .
We randomly sample 600 samples from our positive test set .
Three participants were asked to judge whether the rewritten utterance is a fluent sentence with the score 1 ( not fluent ) - 5( fluent ) .
The fluency score for each model is averaged over all human evaluated scores .
The results are shown in Table 7 . Basically the condition is similar as in Table 5 . T- Ptr -?
achieves the best performance , with the F1 score of 0.86 .
The performance is slightly worse than coreference resolution since information omission is more implicit .
Retrieving all hidden information is sometimes difficult even for humans .
Moreover , the fluency of our model 's generations is very good , only slightly worse than the human reference ( 4.90 vs 4.97 ) .
Information completeness does not have much effects on the fluency .
Exam - ples of rewritten utterances are shown in Table 6 .
Integration Testing
In this section , we study how the proposed utterance rewriter can be integrated into off - the-shelf online chatbots to improve the quality of generated responses .
We use our best model T- Ptr -? to rewrite each utterance based on the dialogue context .
The rewritten utterance is then forwarded to the system for response generation .
We apply on both a task -oriented and chitchat setting .
The results are compared with the original system having no utterance rewriter .
Task-oriented
Our task - oriented dialogue system contains an intention classifier built on Fast- Text ( Bojanowski et al. , 2017 ) and a set of templates that perform policy decision and slot-value filling sequentially .
Intention detection is a most important component in task - oriented dialogues and its accuracy will affect all the following steps .
We define 30 intention classes like weather , hotel booking and shopping .
The training data contains 35,447 human annotations .
With the combination of our rewriter , the intention classier is able to achieve a precision of 89.91 % , outperforming the original system by over 9 % .
The improved intention classification further lead to better conversations .
An example is shown in Table 8 , a multiturn conversation about the weather .
The user first asks " How is the weather in Beijing " , then follows with a further question about " Then what clothes are suitable to wear " .
The original system wrongly classified the user intention as shopping since this is a common conversational pattern in shopping .
In contrast , our utterance rewriter is able to recover the omitted information " under the weather in Beijing " .
Based on the rewritten utterance , the classifier is able to correctly detect the intention and provide proper responses .
Chitchat
Our social chatbot contains two separate engines for multi-turn and single-turn dialogues .
Each engine is a hybrid retrieval and generation model .
In real- life applications , a user query would be simultaneously distributed to these two engines .
The returned candidate responses are then reranked to provide the final response .
Generally the model is already able to provide rather high-quality responses under the single-turn condition , but under multi-turn conversations , the complex context dependency makes the generation difficult .
We integrate our utterance rewriter into the single-turn engine and compare with the original model by conducting the online A/B test .
Specifically , we randomly split the users into two groups .
One talks with the original system and the other talks with the system integrated with the utterance rewriter .
All users are unconscious of the details about our system .
The whole test lasted one month .
Table 9 shows the Conversation - turns Per Session ( CPS ) , which is the average number of conversation - turns between the chatbot and the user in a session .
The utterance rewriter increases the average CPS from 6.3 to 7.7 , indicating the user is more engaged with the integrated model .
Table 8 shows an example of how the utterance rewriter helps with the generation .
After the rewriting , the model can better understand the dialogue is about the NBA team Warriors , but the original model feels confused and only provides a generic response .
Conclusion
In this paper , we propose improving multi-turn dialogue modelling by imposing a separate utterance rewriter .
The rewriter is trained to recover the coreferred and omitted information of user utterances .
We collect a high-quality manually annotated dataset and designed a Transformer -pointer based architecture to train the utterance rewriter .
The trained utterance rewriter performs remarkably well and , when integrated into two online chatbot applications , significantly improves the intention detection and user engagement .
We hope the collected dataset and proposed model can benefit future related research .
Figure 1 : 1 Figure 1 : Architecture of our proposed model .
Green box is the Transformer encoder and pink box is the decoder .
The decoder computes the probability ?
at each step to decide whether to copy from the context or utterance .
