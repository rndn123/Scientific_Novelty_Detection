title
ShanghaiTech at MRP 2019 : Sequence-to - Graph Transduction with Second-Order Edge Inference for Cross-Framework Meaning Representation Parsing
abstract
This paper presents the system used in our submission to the CoNLL 2019 shared task : Cross -Framework Meaning Representation Parsing .
Our system is a graph- based parser which combines an extended pointergenerator network that generates nodes and a second-order mean field variational inference module that predicts edges .
Our system achieved 1 st and 2 nd place for the DM and PSD frameworks respectively on the inframework ranks and achieved 3 rd place for the DM framework on the cross-framework ranks .
Introduction
The goal of the Cross-Framework Meaning Representation Parsing ( MRP 2019 , Oepen et al. ( 2019 ) is learning to parse text to multiple formats of meaning representation with a uniform parsing system .
The task combines five different frameworks of graph - based meaning representation .
DELPH -IN MRS Bi-Lexical Dependencies ( DM ) ( Ivanova et al. , 2012 ) and Prague Semantic Dependencies ( PSD ) ( Haji ?
et al. , 2012 ; first appeared in SemEval 2014 and 2015 shared task Semantic Dependency Parsing ( SDP ) ( Oepen et al. , , 2015 . Elementary Dependency Structures ( EDS ) ( Oepen and L?nning , 2006 ) is the origin of DM Bi-Lexical Dependencies , which encodes English Resource Semantics ( Flickinger et al. , 2016 ) in a variable - free semantic dependency graph .
Universal Conceptual Cognitive Annotation ( UCCA ) ( Abend and Rappoport , 2013 ) targets a level of semantic granularity that abstracts away from syntactic paraphrases .
Abstract Meaning Representation ( AMR ) ( Banarescu et al. , 2013 ) targets to abstract away from syntactic representations , which means that sentences have similar meaning should be assigned the same AMR graph .
One of the main differences be-tween these frameworks is their level of abstraction from the sentence .
SDP is a bi-lexical dependency graph , where graph nodes correspond to tokens in the sentence .
EDS and UCCA are general forms of anchored semantic graphs , in which the nodes are anchored to arbitrary spans of the sentence and the spans can have overlaps .
AMR is an unanchored graph , which does not consider the correspondence between nodes and the sentence tokens .
The shared task also provides a crossframework metric which evaluates the similarity of graph components in all frameworks .
Previous work mostly focused on developing parsers that support only one or two frameworks while few work has explored cross -framework semantic parsing .
Peng et al. ( 2017 ) , Stanovsky and Dagan ( 2018 ) and Kurita and S?gaard ( 2019 ) proposed methods learning jointly on the three frameworks of SDP and Peng et al . ( 2018 ) further proposed to learn from different corpora .
Hershcovich et al. ( 2018 ) converted UCCA , AMR , DM and UD ( Universal Dependencies ) into a unified DAG format and proposed a transition - based method for UCCA parsing .
In this paper , we present our system for MRP 2019 .
Our system is a graph- based method which combines an extended pointer - generator network introduced by Zhang et al . ( 2019 ) to generate nodes for EDS , UCCA and AMR graphs and a second-order mean field variational inference module introduced by Wang et al . ( 2019 ) to predict edges for all the frameworks .
According to the official results , our system gets 94.88 F1 score in the cross-framework metric for DM , which is the 3 rd place in the ranking .
For in - framework metrics , our system gets 92.98 and 81.61 labeled F1 score for DM and PSD respectively , which are ranked 1 st and 2 nd in the ranking .
Data Processing
In this section , we introduce our data preprocessing and post-processing in our system for all the frameworks .
We use sentence tokenizations , POS tags and lemmas from the official companion data and named entity tags extracted by Illinois Named Entity Tagger ( Ratinov and Roth , 2009 ) in the official ' white - list ' .
We follow Zhang et al. ( 2019 ) to convert each EDS , UCCA , and AMR graph to a tree through duplicating the nodes that have multiple edge entrances , An example is shown in Fig.
1 .
The node sequences for EDS , UCCA and AMR are decided by depth-first search that starts from the root node and sorts neighbouring nodes in alphanumerical order .
AMR Data Processing
Our data processing follows Zhang et al . ( 2019 ) .
In pre-processing , we remove the senses , wiki links and polarity attributes in AMR nodes , and replace the sub-graphs of special named entities , such as names , places , time , with anonymized words .
The corresponding phrases in the sentences are also anonymized .
A mapping from NER tags to these entities is built to process the test data .
In post-processing , we generate the AMR subgraphs from the anonymized words .
Then we assign the senses , wiki links and polarity attributes with the method in Zhang et al . ( 2019 ) .
EDS and UCCA Data Processing
In pre-processing we first clean the companion data to make sure the tokens in the companion data is consistent with those in the MRP input .
We suppose anchors are continuous for each node , so we replace the anchors with the corresponding start and end token indices .
In EDS graphs , there are a lot of nodes without a direct mapping to individual surface tokens , which we call type 1 nodes .
We call nodes with corresponding surface tokens type 2 nodes .
We reduce type 1 nodes in two ways : ?
If a node a of type 1 is connected to only one node b which is of type 2 and has the same anchor as a , we reduce node a into node b as a special attribute for the node . ?
If a node a of type 1 is connected to exactly two nodes b and c which are of type 2 and have a combined anchor range that matches the anchor of a .
We reduce node a as an edge connecting b and c with the same label .
The edge direction is decided by the labels of the edges connecting a to b and c .
For example , if node a has two child nodes b and c , edge ( a , c ) has label ARG2 and edge ( a , b ) has label ARG1 , then node a will be reduced to directed edge ( b , c ) with the label of node a .
An example of the reduction is shown in Fig. 2 .
This method reduces 4 nodes on average for each graph .
We also look at nodes whose node label corresponds to a multi-word in the sentence For example , ' _such + as ' in an EDS graph corresponds to ' such as ' in the sentence .
In such case , if the phrase has a probability over 0.5 that maps to a single node , then all words in this phrase will be combined to a single token in the sentence .
In the post-processing , we recover reduced nodes by reversing the reduction precedure according to the node attributes and edge labels .
For UCCA , we label implicit nodes with special labels n i , where i is the index that the implicit node appears in the node sequence .
System Description
In this section , we describe our model for the task .
We first predict the nodes of the parse graph .
For DM and PSD , there is a one- to - one mapping between sentence tokens and graph nodes .
For EDS , UCCA and AMR , we apply an extended pointergenerator network ( Zhang et al. , 2019 ) for node prediction .
Given predicted nodes , we then adopt the method of second-order mean field variational inference ( Wang et al. , 2019 ) for edge prediction .
Figure 3 illustrates our system architecture .
Word Representation Previous work found that various word representation could help improve parser performance .
Many state - of- the - art parsers use POS tags and pre-trained GloVe ( Pennington et al. , 2014 ) embeddings as a part of the word representation .
Dozat and Manning ( 2018 ) find that characterbased LSTM and lemma embeddings can further improve the performance of semantic dependency parser .
Zhang et al. ( 2019 ) use BERT ( Devlin et al. , 2019 ) embeddings for each token to improve the performance of AMR parsing .
In our system , we find that predicted named entity tags are helpful as well .
The word representation o i in our system is : o i = [
Node Prediction
We use extended pointer - generator network ( Zhang et al. , 2019 ) for nodes prediction .
Given a sentence with n words w = [ w 1 , w 2 , ... , w n ] , we predict a list of nodes u = [ u 1 , u 2 , ... , u m ] sequentially and assign their corresponding indices idx = [ idx 1 , idx 2 , ... , idx m ] .
The indices idx are used to track whether a copy of a previous generated nodes or a newly generated node .
P ( u ) = m i=1 P ( u i | u < i , idx < i , w )
To encode the input sentence , we use a multi-layer BiLSTM fed with embeddings of the words : R = BiLSTM ( O ) ( 1 ) where O represents [ o 1 , . . . , o n ] , o i is the concatenation different types of embeddings for w i , and R = [ r 1 , . . . , r n ] represents the output from the BiLSTM .
For the decoder , at each time step t , we use an l-layer LSTM for generating hidden states z l t sequentially : z l t = f l ( z l?1 t , z l t?1 ) where f l is the l-th layer of LSTM , z l 0 is the last hidden state r n in Eq. 1 . z 0 t is the concatenation of the label embedding of node u t?1 and attentional vector z t?1 . z t is defined by :
Where a t src is the source attention distribution , and c t is contextual vector of encoder hidden layers , W satt , W src , U src , b src , W c , b c are learnable parameters .
The vocabulary distribution is given by : e t src =W ? satt tanh ( W src R + U src z l t + b src ) ( 2 ) a t src =softmax ( e t src ) ( 3 ) c t = n i a t src , i r i z t =tanh ( W c [ c t ; z l t ] + b c ) ( 4 ) Word Embedding Node Prediction Edge Prediction Property / Anchor / Attribute Prediction Graph Output DM / PSD ? 1 , ? , Y Y N 1 , ? , 1 , ? , ~ 1 , ? , P vocab = softmax ( W vocab z t + b vocab ) ( 5 ) where W vocab and b vocab are learnable parameters .
The target attention distribution is defined similarly as Eq. 2 and 3 : e t tgt =W ? tatt tanh ( W tgt z 1:t?1 + U tgt z t + b tgt ) , a t tgt = softmax ( e t tgt ) , where W ? tatt , W tgt , U tgt , b tgt are learnable parameters .
Finally , at each time step , we need to decide which action should be taken .
Possible actions include copying an existing node from previous nodes and generating a new node whose label is either from the vocabulary or a word from the source sentence .
The corresponding probability of these three actions are p tgt , p gen and p src : [ p tgt , p gen , p src ] = softmax ( W action z t + b action ) where p tgt + p gen + p src = 1 .
At time step t , if u t is a copy of an existing nodes , then the probability P ( node ) ( u t ) and the index idx t is defined by : P ( node ) ( u t ) = p tgt i:u i =ut a t tgt [ i ] idx t = idx j where idx j is the copied node index .
If u t is a new node : P ( node ) ( u t ) = p gen P vocab ( u t ) + p src i:w i =ut a t src [ i ] idx t = t
Edge Prediction
We adopt the method presented in Wang et al . ( 2019 ) for edge prediction , which is based on second-order scoring and inference .
Suppose that we have a sequence of vector representations of the predicted nodes [ r ? 1 , . . . , r ? m ] , which can be the BiLSTM output r i in Eq. 1 in the cases of DM and PSD , or the extended pointer - generator network output z i in Eq. 4 in the cases of EDS , UCCA and AMR .
The edge prediction module is shown in Fig. 4 .
To score first-order and second-order parts ( i.e. , edges and edge-pairs ) in both edge-prediction and label - prediction , we apply the Biaffine function Manning , 2017 , 2018 ) and Trilinear function ( Wang et al. , 2019 ) fed with node representations .
Biaff ( v 1 , v 2 ) := v ?
1 Uv 2 + b g i :=
U i v i i ? [ 1 , 2 , 3 ] Trilin( v 1 , v 2 , v 3 ) := d i=1 g 1 i ? g 2 i ? g 3 i ( 6 ) 59 ? Input Feature FNN Biaffine or Trilinear Function MF / LBP Recurrent Layers Edge Prediction Label Prediction Q ( T ) ? ? ? ? Q ( t ) s ( edge ) [ s ( sib ) ; s ( gp ) ; s ( cop ) ] where U i is a ( d ? d ) - dimensional tensor , where d is hidden size and ? represents element-wise product .
We consider three types of second-order parts : siblings ( sib ) , co-parents ( cop ) and grandparents ( gp ) ( Martins and Almeida , 2014 ) .
For a specific first-order and second-order part , we use singlelayer FNNs to compute a head representation and a dependent representation for each word , as well as a head_dep representation which is used for grandparent parts : h i ( edge ?h/d ) h i ( label ?h/d ) h j ( edge ?h/d ) h j ( label ? h/ d ) s ( label ) h i ( sib ) ; h i ( gp ) ; h i ( cop ) ? h j ( sib ) ; h j ( gp ) ; h j ( cop ) h k ( sib ) ; h k ( gp ) ; h k ( cop ) part ?
{edge , label , sib , cop , gp} h ( part-head ) i = FNN ( part-head ) ( r ? i ) h ( part-dep ) i = FNN ( part-dep ) ( r ? i ) h ( gp-head_dep ) i = FNN ( gp-head_dep ) ( r ? i )
We then compute the part scores as follows : s ( edge ) ij = Biaff ( edge ) ( h ( edge-dep ) i , h ( edge-head ) j ) ( 7 ) s ( label ) ij = Biaff ( label ) ( h ( label- dep ) i , h ( label-head ) j ) ( 8 ) s ( sib ) ij , ik ? s ( sib ) ik , ij = Trilin ( sib ) ( h ( head ) i , h ( dep ) j , h ( dep ) k ) ( 9 ) s ( cop ) ij , kj ? s ( cop ) kj , ij = Trilin ( cop ) ( h ( head ) i , h ( dep ) j , h ( head ) k ) ( 10 ) s ( gp ) ij , jk = Trilin ( gp ) ( h ( head ) i , h ( head_dep ) j , h ( dep ) k ) ( 11 ) In Eq. 7,8 , the tensor U in the biaffine function is ( d ? 1 ? d ) - dimensional and ( d ? c ) - dimensional , where c is the number of labels .
We require j < k in Eq. 9 and i < k in Eq. 10 .
In the label- prediction module , s ( label ) i , j is fed into a softmax layer that outputs the probability of each label for edge ( i , j ) .
In the edge-prediction module , we can view computing the edge probabilities as doing posterior inference on a Conditional Random Field ( CRF ) .
Each Boolean variable X ij in the CRF indicates whether the directed edge ( i , j ) exists .
We use Eq. 7 to define our unary potential ?
u representing scores of an edge and Eqs. ( 9 - 11 ) to define our binary potential ? p .
We define a unary potential ?
u ( X ij ) for each variable X ij . ? u ( X ij ) = exp( s ( edge ) ij ) X ij = 1 1 X ij = 0 For each pair of edges ( i , j ) and ( k , l ) that form a second-order part of a specific type , we define a binary potential ?
p ( X ij , X kl ) .
? p ( X ij , X kl ) = exp( s ( type ) ij , kl ) X ij = X kl = 1 1 Otherwise Exact inference on this CRF is intractable .
We use mean field variational inference to approximate a true posterior distribution with a factorized variational distribution and tries to iteratively minimize their KL divergence .
We can derive the following iterative update equations of distribution 60 Q ij ( X ij ) for each edge ( i , j ) .
F ( t?1 ) ij = k =i , j Q ( t?1 ) ik ( 1 ) s ( sib ) ij , ik + Q ( t?1 ) kj ( 1 ) s ( cop ) ij , kj + Q ( t?1 ) jk ( 1 ) s ( gp ) ij , jk + Q ( t?1 ) ki ( 1 ) s ( gp ) ki , ij ( 12 ) Q ( t ) ij ( 0 ) ? 1 Q ( t ) ij ( 1 ) ? exp{s ( edge ) ij + F ( t?1 ) ij }
The initial distribution Q ( 0 ) ij ( X ij ) is set by normalizing the unary potential ?
u ( X ij ) .
We iteratively update the distributions for T steps and then output Q ( T ) ij ( X ij ) , where T is a hyperparameter .
We can then predict the parse graph by including every edge y ( edge ) ij such that Q ( T ) ij ( 1 ) > 0.5 .
The edge labels y ( label ) ij are predicted by maximizing the label probabilities computed by the label - prediction module .
P ( y ( edge ) ij | w ) = softmax ( Q ( T ) ij ( X ij ) ) P ( y ( label ) ij | w ) = softmax ( s ( label ) ij )
Note that the iterative updates in mean-field variational inference can be seen as a recurrent neural network that is parameterized by the potential functions .
Therefore , the whole edge prediction module can be seen as an end-to - end neural network .
Other Predictions
The shared task also requires prediction of component pieces such as top nodes , node properties , node anchoring and edge attributes .
In this section , we present our approaches to predicting these components .
Top Nodes
We add an extra ROOT node for each sentence to determine the top node through edge prediction for DM and PSD .
For the other frameworks , we use the first predicted node as the top node .
Node Properties
Node properties vary among different frameworks .
For DM and PSD , we need to predict the POS and frame for each node .
As DM and PSD are bilexical semantic graphs , we directly use the prediction of XPOS from the official companion data .
We use a single layer MLP fed with word features obtained in Eq. 1 for frame prediction .
For EDS , the properties only contain ' carg ' and the corresponding values are related to the surface string .
For example , the EDS sub-graph in Fig. 2 contains a node with label ' named ' which has property ' carg ' with a corresponding value ' Pierre ' .
The anchor of this node matches the token ' Pierre ' in the sentence .
We found that nodes with properties have limited types of node labels .
Therefore , we exchange node labels and values for EDS nodes containing properties during training .
We combine the node attributes and value predictions described in Section 2.2 together as a multi-label prediction task .
We use a single layer MLP to predict node labels specially for nodes with properties .
For each property value , we regard it as a node label and use the extended pointer - generator network described in Section 3.2 to predict it .
Therefore , the probability of node property prediction is : P prop = softmax ( W prop r ? t + b prop ) ( 13 )
Node Anchoring As DM and PSD contain only token level dependencies , we can decide a node anchor by the corresponding token .
For the other frameworks , we use two biaffine functions to predict the ' start token ' and ' end token ' for each node and the final anchor range is decided by the start position of ' start token ' and the end position of ' end token ' .
The biaffine function is fed by word features from the encoder RNN and node features from decoder RNN .
s ( start / end ) ij = Biaff ( start / end ) ( r i , z j ) P start / end , j = softmax ( [ s 1 j , s 2 j , . . . , s nj ] ) ( 14 ) where i ranges from 1 to n and j ranges from 1 to m .
Edge Attributes
Only UCCA requires prediction of edge attributes , which are the ' remote ' attributes of edges .
We create new edge labels by combining the original edge labels and edge attributes .
In this way , edge attribute prediction is done by edge label prediction .
Learning Given a gold graph y ? , we use the cross entropy loss as learning objective : L ( edge ) ( ? ) = ? i , j log ( P ? ( y ?( edge ) ij | w ) ) L ( label ) ( ? ) = ? i , j ?(y ?( edge ) ij ) log ( P ? (y L ( prop ) ( ? ) = ? i , k log ( P ? ( y ?( prop ) ik | w ) ) L ( anchor ) ( ? ) = ? i j?{start , end } ( log ( P ? ( y ?( j ) i | w ) ) where ? is all the parameters of the model , ?( X ) is an indicator function of whether X exists in the graph , i , j range over all the nodes and k ranges over all possible attributes in the graph .
The total loss is defined by : anchor ) where ? 1 , ... ,4 are hyperparameters .
For DM and PSD , we tuned on ?
1 , ? 2 and ?
3 . For other frameworks , we set all of them to be 1 .
L =? 1 L ( edge ) + ? 2 L ( label ) + ?(y ?( prop ) ) ?
3 L ( prop ) + ?(y ?( anchor ) ) ?
4 L (
Experiments and Results
Training For DM , PSD and EDS , we used the same dataset split as previous approaches ( Martins and Almeida , 2014 ; Du et al. , 2015 ) with 33,964 sentence in the training set and 1,692 sentences in the development set .
For each of the other frameworks , we randomly chose 5 % to 10 % of the training set as the development set .
We additionally removed graphs with more than 60 nodes ( or with input sentences longer than 60 words for DM and PSD ) .
We trained our model for each framework separately and used Adam ( Kingma and Ba , 2015 ) to optimize our system , annealing the learning rate by 0.5 for 10,000 steps .
We trained the model for 100,000 iterations with a batch size of 6,000 tokens and terminated with 10,000 iterations without improvement on the development set .
Main Results
Due to an unexpected bug in UCCA anchor prediction , we failed to submit our UCCA prediction .
Our results are still competitive to those of the other teams and we get the 3 rd place for the DM framework in the official metrics .
The main result is shown in Table 1 .
Our system performs well on the DM framework with an F1 score only 0.4 percent F1 below the best score on DM .
Note that our system does not learn to predict node labels for DM and PSD and simply uses lemmas from the companion data as node labels .
We find that compared to gold lemmas from the original SDP dataset , lemmas from the companion data have only 71.4 % accuracy .
We believe that it is the main reason for the F1 score gap between our system and the best one on DM and PSD .
A detailed comparison between each component will be discussed in Section 4.3 .
For PSD , EDS and AMR graph , our system ranks 6 th , 5 th and 7 th among 13 teams .
Analysis DM and PSD Table 2 and 3 show detailed comparison for each evaluation component for DM and PSD .
For DM , our system outperforms systems of the other teams on tops , properties and edges prediction and is competitive on anchors .
For PSD , our system is also competitive on all the components except labels .
There is a large gap in the performance of node label prediction between our system and the best one on both DM and PSD , we believe adding an MLP layer for label prediction would diminish this gap .
Table 4 shows the performance comparison on in- framework metrics for DM and PSD .
For DM , our system outperforms the best of the other systems by 0.5 and 0.8 F1 scores on all and lpps test sets .
For PSD , our system outperforms the best of the other systems by 0.4 F1 score for lpps and only 0.05 F1 score below the best score for all .
AMR
For AMR graph prediction , our node prediction module is based on Zhang et al . ( 2019 ) , but our edge prediction module is based on the secondorder method of Wang et al . ( 2019 ) .
To verify the effectiveness of second-order edge prediction , we compare the performances on the development set of our model and Zhang et al . ( 2019 ) .
The result is shown in Table 5 .
The result shows that our second-order edge prediction is useful not only on the SDP frameworks but also on the AMR framework .
From the official results on the test sets , we find it surprising that there is a huge gap between the test and development results on both the MRP and the Smatch scores , as shown in Table 6 .
In future work , we will figure out the reason behind this problem .
EDS For EDS , our parser ranks 5 th .
There are multiple details of our parser that can be improved .
For example , our anchor prediction module described in Eq. 14 ( ranking 4 th in the task ) may occasionally predict an end anchor positioned before a start anchor , which would be rejected by the evaluation system .
This can be fixed by adding constraints .
UCCA
For UCCA , we failed to submit the result because of the same reversed start- end anchor predictions , which prevents us from obtaining an MRP score .
Ablation Study
BERT with Other Embeddings
We use BERT ( Devlin et al. , 2019 ) embedding in our model .
We compared the performance of DM in the original SDP dataset with different subtoken pooling methods , and we also explored whether combining other embeddings such as pre-trained word embedding Glove ( Pennington et al. , 2014 ) and contextual embedding ELMo ( Peters et al. , 2018 ) will further improve the performance .
The detailed results are shown in table 7 .
We found that Glove , lemma and character embeddings are helpful for DM and fine-tuning on the training set slightly improves the performance .
ELMo embedding is also helpful but cannot outperform BERT embedding .
However , the performance dropped when ELMo embedding and BERT embedding are combined .
We speculate that the drop is caused by the conflict between the two types of contextual information .
For subtoken pooling , we compared the performance of using first subtoken pooling and average pooling as token embedding .
We found that average pooling is slightly better than first pooling .
For syntactic information , we encode each head word and dependency label as embeddings and concatenate them together with other embeddings .
The result shows that syntactic information as embeddings is not very helpful for the task .
We will try other methods utilizing syntactic information in future work .
Lemma and Named Entity Tags Dozat and Manning ( 2018 ) found that gold lemma embedding is helpful for semantic dependency parsing .
However , in section 4.2 , we note that the lemmas from the official companion data have only 71.4 % accuracy compared to lemmas in gold SDP data , which makes lemma embeddings less helpful for parsing .
We found that one of the difference is about the lemma annotations of entities , for example , lemmas of " Pierre Vinken " are " Pierre " and " Vinken " in the companion data while the lemmas are named - entitylike tags " Pierre " and " _generic_proper_ne " in the original SDP dataset .
Based on this discovery , we experimented on the influence of named entity tags on parsing performance .
We used Illinois Named Entity Tagger ( Ratinov and Roth , 2009 ) in white list to predict named entity tags and compared the performance on the development sets of DM and PSD .
The result is shown in table 8 .
We tuned the hyperparameters for all the embedding conditions in the table , and we found that adding lemma or named entity embeddings results in a slight improvement on DM but does not help on PSD .
With both lemma and named entity embeddings , there is a further improvement on both DM and PSD , which shows the named entity tags are helpful for semantic dependency parsing .
As a result , we apply named entity information in parsing other frameworks .
Conclusion
In this paper , we present our graph - based parsing system for MRP 2019 , which combines two state - of - the - art methods for sequence to graph node generation and second-order edge inference .
The result shows that our system performs well on the DM and PSD frameworks and achieves the best scores on the in-framework metrics .
For future work , we will improve our system to achieve better performance on all these frameworks and explore cross -framework multi-task learning .
Our code for DM and PSD is available at https://github.com/ wangxinyu0922/Second_Order_SDP .
Figure 1 : 1 Figure 1 : An example of converting AMR graphs into tree structures .
This is a sub-graph of sentence # 20003002 .
