title
The DCU-ICTCAS MT system at WMT 2014 on German-English Translation Task
abstract
This paper describes the DCU submission to WMT 2014 on German-English translation task .
Our system uses phrasebased translation model with several popular techniques , including Lexicalized Reordering Model , Operation Sequence Model and Language Model interpolation .
Our final submission is the result of system combination on several systems which have different pre-processing and alignments .
Introduction
On the German-English translation task of WMT 2014 , we submitted a system which is built with Moses phrase - based model .
For system training , we use all provided German - English parallel data , and conducted several pre-processing steps to clean the data .
In addition , in order to improve the translation quality , we adopted some popular techniques , including three Lexicalized Reordering Models ( Axelrod et al. , 2005 ; Galley and Manning , 2008 ) , a 9gram Operation Sequence Model ( Durrani et al. , 2011 ) and Language Model interpolation on several datasets .
And then we use system combination on several systems with different settings to produce the final outputs .
Our phrase - based systems are tuned with k-best MIRA ( Cherry and Foster , 2012 ) on development set .
We set the maximum iteration to be 25 .
The Language Models in our systems are trained with SRILM ( Stolcke , 2002 ) .
We trained
Corpus Filtered Out ( % ) Bilingual 7.17 Monolingual ( English ) 1.05 Table 1 : Results of language detection : percentage of filtered out sentences a 5 - gram model with Kneser - Ney discounting ( Chen and Goodman , 1996 ) .
In the next sections , we will describe our system in detail .
In section 2 , we will explain our preprocessing steps on corpus .
Then in section 3 , we will describe some techniques we have tried for this task and the experiment results .
In section 4 , our final configuration for submitted system will be presented .
And we conclude in the last section .
Pre-processing
We use all the training data for German-English translation , including Europarl , News Commentary and Common Crawl .
The first thing we noticed is that some Non-German and Non-English sentences are included in our training data .
So we apply Language Detection ( Shuyo , 2010 ) for both monolingual and bilingual corpora .
For monolingual data ( only including English sentences in our task ) , we filter out sentences which are detected as other language with probability more than 0.999995 .
And for bilingual data , A sentence pair is filtered out if the language detector detects a different language with probability more than 0.999995 on either the source or the target .
The filtering results are given in Table 1 .
In our experiment , German compound words are splitted based on frequency ( Koehn and Knight , 2003 ) .
In addition , for both monolingual and bilingual data , we apply tokenization , normalizing punctuation and truecasing using Moses scripts .
For parallel training data , we also filter out sentence pairs containing more than 80 tokens on either side and sentence pairs whose length ratio between source and target side is larger than 3 .
Techniques
In our preliminary experiments , we take newstest 2013 as our test data and newstest 2008 - 2012 as our development data .
In total , we have more than 10,000 sentences for tuning .
The tuning step would be very time - consuming if we use them all .
So in this section , we use Feature Decay Algorithm ( FDA ) ( Bic ?ici and Yuret , 2014 ) to select 2000 sentences as our development set .
Table 2 shows that system performance does not increase with larger tuning set and the system using only 2 K sentences selected by FDA is better than the baseline tuned with all the development data .
In this section , alignment model is trained by MGIZA ++ ( Gao and Vogel , 2008 ) with grow-diag-final - and heuristic function .
And other settings are mostly default values in Moses .
Lexicalized Reordering Model German and English have different word order which brings a challenge in German- English machine translation .
In our system , we adopt three Lexicalized Reordering Models ( LRMs ) for addressing this problem .
They are word- based LRM ( wLRM ) , phrase - based LRM ( pLRM ) and hierarchal LRM ( hLRM ) .
These three models have different effect on the translation .
Word - based and phrase - based LRMs are focus on local reordering phenomenon , while hierarchical LRM could be applied into longer reordering problem .
Figure 1 shows the differences ( Galley and Manning , 2008 ) .
And Table 3 shows effectiveness of different LRMs .
In our system based on Moses , we use wbe-msd - bidirectional - fe , phrase-msd - bidirectional -fe and hier-mslr- bidirectional - fe to specify these three LRMs .
From Table 2 , we could see that LRMs significantly improves the translation .
Operation Sequence Model
The Operation Sequence Model ( OSM ) ( Durrani et al. , 2011 ) explains the translation procedure as a linear sequence of operations which generates source and target sentences in parallel .
Durrani et al. ( 2011 ) defined four translation operations : Generate ( X , Y ) , Continue Source Concept , Generate Source Only ( X ) and Generate Identical , as well as three reordering operations : Insert Gap , Jump Back ( W ) and Jump Forward .
These operations are described as follows .
? Generate ( X , Y ) make the words in Y and the first word in X added to target and source string respectively .
? Continue Source Concept adds the word in the queue from Generate ( X , Y ) to the source string .
? Generate Source Only ( X ) puts X in the source string at the current position .
?
Generate Identical generates the same word for both sides .
?
Insert Gap inserts a gap in the source side for future use .
? Jump Back ( W ) makes the position for translation be the Wth closest gap to the current position .
?
Jump Forward moves the position to the index after the right-most source word .
Systems Tuning = ( o 1 o 2 ? ? ? o J ) is : p( O ) = J j=1 p( o j |o j?n+1 ? ? ? o j?1 ) ( 1 ) where n indicates the number of previous operations used .
In this paper we train a 9 - gram OSM on training data and integrate this model directly into loglinear framework ( OSM is now available to use in Moses ) .
Our experiment shows OSM improves our system by about 0.8 BLEU ( see Table 2 ) .
Language Model Interpolation
In our baseline , Language Model ( LM ) is trained on all the monolingual data provided .
In this section , we try to build a large language model by including data from English Gigaword fifth edition ( only taking partial data with size of 1.6G ) , English side of UN corpus and English side of 10 9 French - English corpus .
Instead of training a single model on all data , we interpolate language models trained on each subset ( monolingual data provided is splitted into three parts : News 2007 - 2013 , Europarl and News Commentary ) by tuning weights to minimize perplexity of language model measured on the target side of development set .
In our experiment , after interpolation , the language model does n't get a much lower perplexity , but it slightly improves the system , as shown in Table 2 .
Other Tries
In addition to the techniques mentioned above , we also try some other approaches .
Unfortunately all of these methods described in this section are non-effective in our experiments .
The results are shown in Table 2 . ? Factored Model :
We tried to integrate a target POS factored model into our system with a 9 - gram POS language model to address the problem of word selection and word order .
But experiment does n't show improvement .
The English POS is from Stanford POS Tagger ( Toutanova et al. , 2003 ) . ? Translation Model Combination :
In this experiment , we try to use the method of ( Sennrich , 2012 ) to combine phrase tables or reordering tables from different subsets of data to minimize perplexity measured on development set .
We try to split the training data in two ways .
One is according to data source , resulting in three subsets : Europarl , News Commentary and Common Crawl .
Another one is to use data selection .
We use FDA to select 200K sentence pairs as in-domain data and the rest as out-domain data .
Unfortunately both experiments failed .
In Table 2 , we only report results of phrase table combination on FDA - based data sets .
? OSM Interpolation : Since OSM in our system could be taken as a special language model , we try to use the idea of interpolation similar with language model to make OSM adapted to some data .
Training data are splitted into two subsets with FDA .
We train 9 - gram OSM on each subsets and interpolate them according to OSM trained on the development set .
?
Sparse Features :
For each source phrase , there is usually more than one corresponding translation option .
Each different translation may be optimal in different contexts .
Thus in our systems , similar to ( He et al. , 2008 ) which proposed a Maximum Entropy - based rule selection for the hierarchical phrasebased model , features which describe the context of phrases , are designed to select the right translation .
But different with ( He et al. , 2008 ) , we use sparse features to model the context .
And instead of using syntactic POS , we adopt independent POS - like features : cluster ID of word .
In our experiment mkcls was used to cluster words into 50 groups .
And all features are generalized to cluster ID .
Submission Based on our preliminary experiments in the section above , we use LRMs , OSM and LM interpolation in our final system for newstest 2014 .
But as we find that Language Models trained on UN corpus and 10 9 French - English corpus have a very high perplexity and in order to speed up the translation by reducing the model size , in this section , we interpolate only three language models from monolingual data provided , English Gigaword fifth edition and target side of training data .
In addition , we also try some different methods for final submission .
And the results are shown in Table 4 . ? Development Set Selection : Instead of using FDA which is dependent on test set , we use the method of ( Nadejde et al. , 2013 ) to select tuning set from newstest 2008 - 2013 for the final system .
We only keep 2 K sentences which have more than 30 words and higher BLEU score .
The experiment result is shown in Table 4 ( The system is indicated as Baseline ) .
?
Pre-processing :
In our preliminary experiments , sentences are tokenized without changing hyphen .
Thus we build another system where all the hyphens are tokenized aggressively .
? SyMGIZA ++ : Better alignment could lead to better translation .
So we carry out some experiments on SyMGIZA ++ aligner ( Junczys - Dowmunt and Sza , 2012 ) , which modifies the original IBM / GIZA ++ word alignment models to allow to update the symmetrized models between chosen iterations of the original training algorithms .
Experiment shows this new alignment improves translation quality .
? Multi-alignment Selection :
We also try to use multi-alignment selection ( Tu et al. , 2012 ) to generate a " better " alignment from three alignmens : MGIZA ++ with function growdiag -final - and , SyMGIZA ++ with function grow-diag-final - and and fast alignment ( Dyer et al. , 2013 ) .
Although this method show comparable or better result on development set , it fails on test set .
Since we build a few systems with different setting on Moses phrase - based model , a straightforward thinking is to obtain the better translation from several different translation systems .
So we use system combination ( Heafield and Lavie , 2010 ) on the 1 - best outputs of three systems ( indicated with * in table 4 ) .
And this results in our best system so far , as shown in Table 4 .
In our final submission , this result is taken as primary .
Conclusion
This paper describes our submitted system to WMT 2014 in detail .
Figure 1 : 1 Figure 1 : Occurrence of a swap according to the three orientation models : word - based , phrasebased , and hierarchical .
Black squares represent word alignments , and gray squares represent blocks identified by phrase-extract .
In ( a ) , block b i = ( e i , f a i ) is recognized as a swap according to all three models .
In ( b ) , b i is not recognized as a swap by the word - based model .
In ( c ) , b i is recognized as a swap only by the hierarchical model .
( Galley and Manning , 2008 )
