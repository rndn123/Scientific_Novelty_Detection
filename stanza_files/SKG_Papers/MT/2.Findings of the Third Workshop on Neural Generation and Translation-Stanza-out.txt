title
Findings of the Third Workshop on Neural Generation and Translation
abstract
This document describes the findings of the Third Workshop on Neural Generation and Translation , held in concert with the annual conference of the Empirical Methods in Natural Language Processing ( EMNLP 2019 ) .
First , we summarize the research trends of papers presented in the proceedings .
Second , we describe the results of the two shared tasks 1 ) efficient neural machine translation ( NMT ) where participants were tasked with creating NMT systems that are both accurate and efficient , and 2 ) document generation and translation ( DGT ) where participants were tasked with developing systems that generate summaries from structured data , potentially with assistance from text in another language .
Introduction Neural sequence to sequence models ( Kalchbrenner and Blunsom , 2013 ; Sutskever et al. , 2014 ; Bahdanau et al. , 2015 ) are now a workhorse behind a wide variety of different natural language processing tasks such as machine translation , generation , summarization and simplification .
The 3rd Workshop on Neural Machine Translation and Generation ( WNGT 2019 ) provided a forum for research in applications of neural models to machine translation and other language generation tasks ( including summarization ( Rush et al. , 2015 ) , NLG from structured data ( Wen et al. , 2015 ) , dialog response generation ( Vinyals and Le , 2015 ) , among others ) .
Overall , the workshop was held with two goals .
First , it aimed to synthesize the current state of knowledge in neural machine translation and generation : this year we continued to encourage submissions that not only advance the state of the art through algorithmic advances , but also analyze and understand the current state of the art , pointing to future research directions .
Towards this goal , we received a number of high-quality research contributions on both workshop topics , as summarized in Section 2 .
Second , the workshop aimed to expand the research horizons in NMT : we continued to organize the Efficient NMT task which encouraged participants to develop not only accurate but computationally efficient systems .
In addition , we organized a new shared task on " Document- level Generation and Translation " , which aims to push forward document - level generation technology and contrast the methods for different types of inputs .
The results of the shared task are summarized in Sections 3 and 4 .
Summary of Research Contributions
We published a call for long papers , extended abstracts for preliminary work , and crosssubmissions of papers submitted to other venues .
The goal was to encourage discussion and interaction with researchers from related areas .
We received a total of 68 submissions , from which we accepted 36 .
There were three crosssubmissions , seven long abstracts and 26 full papers .
There were also seven system submission papers .
All research papers were reviewed twice through a double blind review process , and avoiding conflicts of interest .
There were 22 papers with an application to generation of some kind , and 14 for translation which is a switch from previous workshops where the focus was on machine translation .
The caliber of the publications was very high and the number has more than doubled from last year ( 16 accepted papers from 25 submissions ) .
2 3 Shared Task : Document- level
Generation and Translation
The first shared task at the workshop focused on document-level generation and translation .
Many recent attempts at NLG have focused on sentencelevel generation ( Lebret et al. , 2016 ; Gardent et al. , 2017 ) .
However , real world language generation applications tend to involve generation of much larger amount of text such as dialogues or multisentence summaries .
The inputs to NLG systems also vary from structured data such as tables ( Lebret et al. , 2016 ) or graphs ( Wang et al. , 2018 ) , to textual data ( Nallapati et al. , 2016 ) .
Because of such difference in data and domain , comparison between different methods has been nontrivial .
This task aims to ( 1 ) push forward such document - level generation technology by providing a testbed , and ( 2 ) examine the differences between generation based on different types of inputs including both structured data and translations in another language .
In particular , we provided the following 6 tracks which focus on different input / output requirements : ? NLG ( Data ? En , Data ? De ) : Generate document summaries in a target language given only structured data .
? MT ( De ? En ) : Translate documents in the source language to the target language .
? MT+NLG ( Data + En ? De , Data + De ? En ) : Generate document summaries given the structured data and the summaries in another language .
Evaluation Measures
We employ standard evaluation metrics for datato - text NLG and MT along two axes : Textual Accuracy Measures :
We used BLEU ( Papineni et al. , 2002 ) and ROUGE ( Lin , 2004 ) as measures for texutal accuracy compared to reference summaries .
Content Accuracy Measures :
We evaluate the fidelity of the generated content to the input data using relation generation ( RG ) , content selection ( CS ) , and content ordering ( CO ) metrics ( Wiseman et al. , 2017 ) .
The content accuracy measures were calculated using information extraction models trained on respective target languages .
We followed ( Wiseman et al. , 2017 ) and ensembled 6 information extraction models ( 3 CNN - based , 3 LSTM - based ) with different random seeds for each language .
Data
Due to the lack of a document- level parallel corpus which provides structured data for each instance , we took an approach of translating an existing NLG dataset .
Specifically , we used a subset of the RotoWire dataset ( Wiseman et al. , 2017 ) and obtained professional German translations , which are sentence -aligned to the original English articles .
The obtained parallel dataset is called the RotoWire English - German dataset , and consists of box score tables , an English article , and its German translation for each instance .
Table 1 shows the statistics of the obtained dataset .
We used the test split from this dataset to calculate the evaluation measures for all the tracks .
We further allowed the following additional resources for each track : ? NLG : RotoWire , Monolingual ? MT : WMT19 , Monolingual ? MT+NLG : RotoWire , WMT19 , Monolingual RotoWire refers to the RotoWire dataset ( Wiseman et al. , 2017 ) ( train / valid ) , WMT19 refers to the set of parallel corpora allowable by the WMT 2019 English - German task , and Monolingual refers to monolingual data allowable by the same WMT 2019 task , pre-trained embeddings ( e.g. , GloVe ( Pennington et al. , 2014 ) ) , pre-trained contextualized embeddings ( e.g. , BERT ( Devlin et al. , 2019 ) ) , pre-trained language models ( e.g. , GPT - 2 ( Radford et al. , 2019 ) ) .
Systems which follow these resource constraints are marked constrained , otherwise unconstrained .
Results are indicated by the initials ( C/ U ) .
Baseline Systems
Considering the difference in inputs for MT and NLG tracks , we prepared two baselines for respective tracks .
FairSeq -19 FairSeq ( Ng et al. , 2019 ) was used for MT and MT + NLG tracks for both directions of translations .
We used the published WMT '19 single model and did not tune on in- domain data .
NCP +CC : A two -stage model from ( Puduppully et al. , 2019 ) was used for NLG tracks .
We utilized the pretrained English model trained on RotoWire dataset for English article generation , while the German model was trained on RotoWire English - German dataset .
Submitted Systems Four teams , Team EdiNLG , Team FIT -Monash , Team Microsoft , Team Naver Labs Europe , and Team SYSTRAN - AI participated in the shared task .
We note the common trends across many teams and discuss the systems of individual teams below .
On MT tracks , all the teams have adopted a variant of Transformer ( Vaswani et al. , 2017 ) as a sequence transduction model and trained on corpora with different data-augmentation methods .
Trained systems were then fine-tuned on in- domain data including our RotoWire English - German dataset .
The focus of data augmentation was two -fold : 1 ) acquiring in - domain data and 2 ) utilizing document boundaries from existing corpora .
Most teams applied back -translation on various sources including NewsCrawl and the original RotoWire dataset for this purpose .
NLG tracks exhibited a similar trend for the sequence model selection , except for Team EdiNLG who employed LSTM .
Team EdiNLG Team EdiNLG built their NLG system upon ( Puduppully et al. , 2019 ) by extending it to further allow copying from the table in addition to generating from vocabulary and the content plan .
Additionally , they included features indicating the win / loss team records and team rank in terms of points for each player .
They trained the NLG model for both languages together , using a shared BPE vocabulary obtained from target game summaries and by prefixing the target text with the target language indicator .
For MT and MT +NLG tracks , they mined the in-domain data by extracting basketball - related texts from Newscrawl when one of the following conditions are met : 1 ) player names from the RotoWire English - German training set appear , 2 ) two NBA team names appear in the same document , or 3 ) " NBA " appears in titles .
This resulted in 4.3 and 1.1 million monolingual sentences for English and German , respectively .
The obtained sentences were then back - translated and added to the training corpora .
They submitted their system EdiNLG in all six tracks .
Team FIT -Monash Team FIT - Monash built a document- level NMT system ( Maruf et al. , 2019 ) and participated in MT tracks .
The document- level model was initialized with a pre-trained sentence - level NMT model on news domain parallel corpora .
Two strategies for composing document - level context were proposed : flat and hierarchical attention .
Flat attention was applied on all the sentences , while hierarchical attention was computed at sentence and word-level in a hierarchical manner .
Sparse attention was applied at sentence - level in order to identify key sentences that are important for translating the current sentence .
To train a document- level model , the team focused on corpora that have document boundaries , including News Commentary , Rapid , and the Ro-toWire dataset .
Notably , greedy decoding was employed due to computational cost .
The submitted system is an ensemble of three runs indicated as FIT - Monash .
Team Microsoft Team Microsoft ( MS ) developed a Transformerbased NLG system which consists of two sequence - to-sequence models .
The two step method was inspired by the approach from ( Puduppully et al. , 2019 ) , where the first model is a recurrent pointer network that selects encoded records , and the second model takes the selected content representation as input and generates summaries .
The proposed model ( MS - End-to- End ) learned both models at the same time with a combined loss function .
Additionally , they have investigated the use of pre-trained language models for NLG track .
Specifically , they fine- tuned GPT - 2 ( Radford et al. , 2019 ) on concatenated pairs of ( template , target ) summaries , while constructing templates following ( Wiseman et al. , 2017 ) .
The two sequences are concatenated around a special token which indicates " rewrite " .
At decoding time , they adopted nucleus sampling ( Holtzman et al. , 2019 ) to enhance the generation quality .
Different thresholds for nucleus sampling were investigated , and two systems with different thresholds were submitted : MS - GPT - 50 and MS - GPT - 90 , where the numbers refer to Top -p thresholds .
The generated summaries in English using the following systems were then translated with the MT systems which is described below .
Hence , this marks Team Microsoft 's German NLG ( Data ? De ) submission unconstrained , due to the usage of parallel data beyond the RotoWire English - German dataset .
As for the MT model , a pre-trained system from ( Xia et al. , 2019 ) was fine-tuned on the Ro-toWire English - German dataset , as well as backtranslated sentences from the original RotoWire dataset for the English - to - German track .
Backtranslation of sentences obtained from Newscrawl according to the similarity to RotoWire data ( Moore and Lewis , 2010 ) was attempted but did not lead to improvement .
The resulting system is shown as MS on MT track reports .
Team Naver Labs Europe Team Naver Labs Europe ( NLE ) took the approach of transferring the model from MT to NLG .
They first trained a sentence - level MT model by iteratively extend the training set from the WMT19 parallel data and RotoWire English - German dataset to back - translated Newscrawl data .
The best sentence - level model was then fine-tuned at document-level , followed by finetuning on the RotoWire English - German dataset ( constrained NLE ) and additionally on the backtranslated original RotoWire dataset ( unconstrained NLE ) .
To fully leverage the MT model , input record values prefixed with special tokens for record types were sequentially fed in a specific order .
Combined with the target summary , the pair of record representations and the target summaries formed data for a sequence - to-sequence model .
They fine-tuned their document- level MT model on these NLG data which included the original RotoWire and RotoWire English - German dataset .
The team tackled MT + NLG tracks by concatenating source language documents and the sequence of records as inputs .
To encourage the model to use record information more , they randomly masked certain portion of tokens in the source language documents .
3.4.5 Team SYSTRAN -AI Team SYSTRAN -AI developed their NLG system based on the Transformer ( Vaswani et al. , 2017 ) .
The model takes as input each record from the box score featurized into embeddings and decode the summary .
In addition , they introduced a content selection objective where the model learns to predict whether or not each record is used in the summary , comprising a sequence of binary classfication decision .
Furthermore , they performed data augmentation by synthesizing records whose numeric values were randomly changed in a way that does not change the win / loss relation and remains within a sane range .
The synthesized records were used to generate a summary to obtain new ( record , summary ) pairs and were included added the training data .
To bias the model toward generating more records , they further fine- tuned their model on a subset of training examples which contain N ( = 16 ) records in the summary .
The submitted systems are SYSTRAN -AI and SYSTRAN -AI - Detok , which differ in tokenization .
Results
We show the results for each track in Table 2 through 7 .
In the NLG and MT +NLG tasks , we report BLEU , ROUGE ( F1 ) for textual accuracy , RG ( P ) , CS ( P , R ) , and CO ( DLD ) for content accuracy .
While for MT tasks , we only report BLEU .
We summarize the shared task results for each track below .
In NLG ( En ) track , all the participants encouragingly submitted systems outperforming a strong baseline by ( Puduppully et al. , 2019 ) .
We observed an apparent difference between the constrained and unconstrained settings .
Team NLE 's approach showed that pre-training of the document- level generation model on news corpora is effective even if the source input differs ( German text vs linearized records ) .
Among constrained systems , it is worth noting that all the systems but Team EdiNLG used the Transformer , but the result did not show noticeable improvements compared to EdiNLG .
It was also shown that the generation using pre-trained language models is sensitive to how the sampling is performed ; the results of MS - GPT -90 and MS - GPT - 50 differ only in the nucleus sampling hyperparameter , which led to significant differences in every evaluation measure .
The NLG ( De ) track imposed a greater challenge compared to its English counterpart due to the lack of training data .
The scores has generally dropped compared to NLG ( En ) results .
To alleviate the lack of German data , most teams developed systems under unconstrained setting by utilizing MT resources and models .
Notably , Team NLE 's has achieved similar performance to the constrained system results on NLG ( En ) .
However , Team EdiNLG achieved similar performance under the constrained setting by fully leveraging the original RotoWire using the sharing of vocabulary .
In MT tracks , we see the same trend that the system under unconstrained setting ( NLE ) outperformed all the systems under the constrained setting .
The improvement observed in the unconstrained setting came from fine-tuning on the back - translated original RotoWire dataset , which offers purely in -domain parallel documents .
While the results are not directly comparable due to different hyperparameters used in systems , fine -tuning on in- domain parallel sentences was shown effective ( FairSeq - 19 vs others ) .
When incorporating document- level data , it was shown that document- level models ( NLE , FIT - Monash , MS ) perform better than sentence - level models ( EdiNLG , , even if a sentence - level model is trained on document - aware corpora .
For MT +NLG tracks , interestingly , no teams found the input structured data useful , thus applying MT models for MT + NLG tracks .
Compared to the baseline ( FairSeq - 19 ) , fine -tuning on indomain data resulted in better performance overall as seen in the results of Team MS and NLE .
The key difference between Team MS and NLE is the existence of document- level fine-tuning , where Team NLE outperformed in terms of textual accuracy ( BLEU and ROUGE ) overall , in both target languages .
Shared Task : Efficient NMT
The second shared task at the workshop focused on efficient neural machine translation .
Many MT shared tasks , such as the ones run by the Conference on Machine Translation ( Bojar et al. , 2017 ) , aim to improve the state of the art for MT with respect to accuracy : finding the most accurate MT system regardless of computational cost .
However , in production settings , the efficiency of the implementation is also extremely important .
The efficiency shared task for WNGT ( inspired by the " small NMT " task at the Workshop on Asian Translation ( Nakazawa et al. , 2017 ) ) was focused on creating systems for NMT that are not only accurate , but also efficient .
Efficiency can include a number of concepts , including memory efficiency and computational efficiency .
This task concerns itself with both , and we cover the detail of the evaluation below .
Evaluation Measures
We used metrics to measure several different aspects connected to how good the system is .
These were measured for systems that were run on CPU , and also systems that were run on GPU .
Accuracy Measures :
As a measure of translation accuracy , we used BLEU ( Papineni et al. , 2002 ) and NIST ( Doddington , 2002 ) scores .
Computational Efficiency Measures :
We measured the amount of time it takes to translate the entirety of the test set on CPU or GPU .
Time for loading models was measured by having the model translate an empty file , then subtracting this from the total time to translate the test set file .
Memory Efficiency Measures :
We measured : ( 1 ) the size on disk of the model , ( 2 ) the number of parameters in the model , and ( 3 ) the peak consumption of the host memory and GPU memory .
These metrics were measured by having participants submit a container for the virtualization environment Docker 1 , then measuring from outside the container the usage of computation time and memory .
All evaluations were performed on dedicated instances on Amazon Web Services 2 , specifically of type m5. large for CPU evaluation , and p3.2 xlarge ( with a NVIDIA Tesla V100 GPU ) .
System BLEU R-1 R -2 R-L RG CS ( P/
Data
The data used was from the WMT 2014 English - German task ( Bojar et al. , 2014 ) , using the preprocessed corpus provided by the Stanford NLP Group 3 . Use of other data was prohibited .
Baseline Systems
Two baseline systems were prepared : Echo : Just send the input back to the output .
Base : A baseline system using attentional LSTMbased encoder-decoders with attention ( Bahdanau et al. , 2015 ) .
Submitted Systems
Two teams , Team Marian and Team Notre Dame submitted to the shared task , and we will summarize each below .
Team Marian Team Marian 's submission ( Kim et al. , 2019 ) was based on their submission to the shared task the previous year , consisting of Transformer models optimized in a number of ways ( Junczys - Dowmunt et al. , 2018 ) .
This year , they made a number of improvements .
Improvements were made to teacher -student training by ( 1 ) creating more data for teacher -student training using backward , then forward translation , ( 2 ) using multiple teachers to generate better distilled data for training student models .
In addition , there were modeling improvements made by ( 1 ) replacing simple averaging in the attention layer with an efficiently calculable " simple recurrent unit , " ( 2 ) parameter tying between decoder layers , which reduces memory usage and improves cache locality on the CPU .
Finally , a number of CPU - specific optimizations were performed , most notably including 8 - bit matrix multiplication along with a flexible quantization scheme .
System BLEU R-1 R -2 R-L RG CS ( P/
Team Notre Dame Team Notre Dame 's submission ( Murray et al. , 2019 ) focused mainly on memory efficiency .
They did so by performing " Auto-sizing " of the transformer network , applying block -sparse regularization to remove columns and rows from the parameter matrices .
Results
A brief summary of the results of the shared task ( for newstes t 2015 ) can be found in Figure 1 , while full results tables for all of the systems can be found in Appendix A. From this figure we can glean a number of observations .
For the CPU systems , all submissions from the Marian team clearly push the Pareto frontier in terms of both time and memory .
In addition , the Marian systems also demonstrated a good tradeoff between time / memory and accuracy .
For the GPU systems , all systems from the Marian team also outperformed other systems in terms of the speed-accuracy trade- off .
However , the Marian systems had larger memory consumption than both Notre Dame systems , which specifically optimized for memory efficiency , and all previous systems .
Interestingly , each GPU system by the Marian team shares almost the same amount of GPU memory as shown in Table 12 and Figure 2 ( b ) .
This may indicate that the internal framework of the Marian system tries to reserve enough amount of the GPU memory first , then use the acquired memory as needed by the translation processes .
On the other hand , we can see that the Notre Dame systems occupy only a minimal amount of GPU memory , as the systems use much smaller amounts on the empty set ( Figure 2 ( a ) ) .
These different approaches to constant or variable size memory consumption may be based on different underlying perspectives of " memory efficiency , " and it may be difficult to determine which policy is better without knowing the actual environment in which a system will be used .
Conclusion
This paper summarized the results of the Third Workshop on Neural Generation and Translation , where we saw a number of research advances .
Particularly , this year introduced a new document generation and translation task , that tested the efficacy of systems for both the purposes of translation and generation in a single testbed .
Marian.gpu_big ndnlp.all-l21-01-small ndnlp.baseline-small ndnlp.encoder-l21-01-small ndnlp.encoder-l21-1-small ndnlp.fc-l21-01-small ndnlp.fc-l21-1-small ndnlp.fc-l21-10-small ndnlp.fc-linf1-100-small ( b) GPU
Time vs. Marian.gpu_big ndnlp.all-l21-01-small ndnlp.baseline-small ndnlp.encoder-l21-01-small ndnlp.encoder-l21-1-small ndnlp.fc-l21-01-small ndnlp.fc-l21-1-small ndnlp.fc-l21-10-small ndnlp.fc-linf1-100-small ( d) GPU
Memory vs .
Accuracy
