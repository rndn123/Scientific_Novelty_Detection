title
Checkpoint Reranking : An Approach To Select Better Hypothesis For Neural Machine Translation Systems
abstract
In this paper , we propose a method of reranking the outputs of Neural Machine Translation ( NMT ) systems .
After the decoding process , we select a few last iteration outputs in the training process as the N - best list .
After training a Neural Machine Translation ( NMT ) baseline system , it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system .
We come up with a ranking mechanism by solely focusing on the decoder 's ability to generate distinct tokens and without the usage of any language model or data .
With this method , we achieved a translation improvement up to + 0.16 BLEU points over baseline .
We also evaluate our approach by applying the coverage penalty to the training process .
In cases of moderate coverage penalty , the oracle scores are higher than the final iteration up to + 0.99 BLEU points , and our algorithm gives an improvement up to + 0.17 BLEU points .
With excessive penalty , there is a decrease in translation quality compared to the baseline system .
Still , an increase in oracle scores up to + 1.30 is observed with the re-ranking algorithm giving an improvement up to + 0.15 BLEU points is found in case of excessive penalty .
The proposed re-ranking method is a generic one and can be extended to other language pairs as well .
Introduction Neural Machine Translation ( NMT ) has brought excellent results in the field of Machine Transla-tionSutskever et al . ( 2014 ) ; Bahdanau et al . ( 2014 ) ; Cho et al. ( 2014 ) due to generation of high-quality translations for different language pairs .
Yet even higher quality can be achieved by combining multiple models by techniques like ensembles Hansen and Salamon ( 1990 ) and reranking Shen et al . ( 2004 ) .
Our work deals with how Neural Machine Translation ( NMT ) can achieve better results explicitly with reranking methods .
Neural Machine Translation has an encoderdecoder architecture that is jointly trained to maximize the probability of target given source sentences .
It first encodes the source sentence into a single vector , and the decoder predicts it .
With the Attention Mechanism , it tries to apply weights to the input sentence at each time step .
Recent approaches like the transformer model Vaswani et al . ( 2017 ) have achieved the state - of - the - art results for Machine Translation .
Neural Machine Translation ( NMT ) however , leads to over-translation and under-translation as it tends to ignore the past alignment information , and it is effectively tackled by introducing a coverage vector Tu et al . ( 2016 ) .
Other approaches such as Mi et al . ( 2016 a ) and Mi et al . ( 2016 b ) too solve the coverage problem in NMT .
Without the coverage vector , it could result in a decrease in translation quality .
We propose a method that selects a better hypothesis giving high importance to distinct words generated from decoder without the usage of any language model or data .
After applying the proposed reranking method , an overall improvement in translation quality is observed as compared to the baseline system .
The rest of the paper is organized as follows ; Section 2 discusses the work related to re-utilizing existing models for Machine Translation .
Section 3 describes our approach for Checkpoint based Reranking .
In Section 4 , we present our Reranking Algorithm .
In Section 5 , we demonstrate all of our Experiments along with the results obtained , and finally , the paper is concluded in Section 6 with future directions .
Related Work
The work of Imamura and Sumita ( 2017 ) explains the concepts of reranking and ensembling in detail .
It introduces a method of bidirectional reranking in which it combines the hypothesis from l2r and r2l decoding following the works of , which proposes an agreement model to solve unbalanced outputs of recurrent neural networks .
Marie and Fujita ( 2018 ) has introduced a reranking system that uses a smorgasbord of informative features in tasks where PBSMT and NMT produce translations of different quality .
The work by Shen et al . ( 2004 ) shows how to apply perceptron-like reranking algorithms to improve the overall translation quality , and Olteanu et al . ( 2006 ) shows the usage of Language Models ( LMs ) for reranking on hypotheses generated by phrase - based Statistical Machine Translation systems .
Wang et al. ( 2007 ) has shown linguistically motivated and computationally efficient structured language models for reranking in SMT systems .
The concept of Checkpoint ensembles is introduced by Sennrich et al . ( 2016 ) and was later on improvised to independent ensembling Sennrich et al . ( 2017 ) . Vaswani et al. ( 2017 ) included a checkpoint averaging method for their model .
Liu et al. ( 2018 ) has focused on decoding techniques that utilize existing models at parameter , word , and sentence level corresponding to checkpoint averaging , model ensembling , and candidate reranking and found that all of these improve the translation quality without retraining the model .
Checkpoint Based Reranking
In our approach , the iteration outputs are selected as the N - best list .
It implies for the last K iterations ; we have the corresponding K-best list for a sentence .
We take our Oracle scores as the one that is having the largest BLEU Score Papineni et al . ( 2002 ) on the test reference hypothesis from this K-best list .
After obtaining the oracle scores from this K-best list , we observe that this score is larger than the baseline system , and it indicates that there is scope for further improvement of translation quality .
So we propose a reranking method that improves the translation quality over the baseline system without any language model or data .
We try to focus on the nature of translations that the decoder generates with and without coverage penalty .
In the initial step , we keep track of the number of distinct words in the generated hypothe-sis , and the later ones we keep track of words that have repeated more than once .
A higher score is given for sentences having a higher number of Distinct Tokens ( D ) and lower scores for those having more number of repetitive words ( F ) .
For each sentence in the N - best list , these scores are sorted , and the sentence having the highest score is selected .
This process is repeated for the entire test set , and the ones that are having the top most scores are chosen as the reranked output , as shown in Section 4 .
For a sentence , FREQ is the count of each word ; DISTINCT is the total count of unique words .
For each hypothesis in the K-best list we divide DIS-TINCT with FREQ and select the highest scorer .
Reranking
Experiments and Results
DataSet
We used ILCI Jha ( 2010 ) corpus , which has eleven language pairs from which we chose Telugu and Hindi as our parallel data during the training process .
The entire corpus is manually cleaned to remove the misalignments .
Table 1 shows the split ratio of sentences followed in the process .
The hypotheses are collected for the last k=3 , 5 , 7 during decoding .
We evaluate the generated hypotheses with BLEU Papineni et al . ( 2002 ) for our experiments .
The scores obtained after each iteration are shown in Table 2 .
After this , we apply our proposed reranking method to the last few iteration outputs , which are selected as the N - best list .
The proposed reranking method leads to an overall improvement of translation quality by + 0.07 , +0.15 , +0.16 BLEU score compared to the baseline with oracle improvements up to + 0.55 , + 0.90 , + 1.01 on the three systems .
The scores obtained for each of them are shown in Tables 3 , 4 ,
Data
Results
Hypothesis
With Coverage Penalty
We also evaluate our work by adding coverage penalty Wu et al . ( 2016 ) in the training process to ensure that this algorithm works when both the under translations and over translations are addressed adequately .
All the hyperparameters are kept the same as the baseline system except for the coverage penalty .
From Tables 7 , 8 , 9 it can be inferred that there is an improvement of + 0.05 , +0.15 , +0.17 and oracle improvements up to + 0.51 , +0.82 , +0.99 for 0.1 coverage penalty .
With excess coverage penalty , there is a decline in translation quality compared to the baseline system without coverage penalty , as shown in Tables 2 and 10 . Still , the proposed method gives an increase of + 0.12 , +0.15 , +0.15 over baseline with oracle improvements up to + 0.91 , + 1.30 , + 1.30 for the last 3 , 5 and 7 checkpoints respectively as shown in Tables 11 , 12 , 13 .
One can also observe that the improvements and the oracle scores increase correspondingly with the size of the N - best list .
The variation with the baseline can be obtained as shown in Figure 1 In this paper , we introduce a method of selecting an N - best list for NMT systems and propose a way of reranking to the generated hypotheses from the system .
We observe that our approach is giving better results over the baseline model by following the proposed reranking method and is also evaluated with the coverage penalty .
One can investigate our approach with varying beam sizes and analyzing the effect of length penalty Wu et al . ( 2016 ) and comparing it with methods such as .
We also look forward to coming up with better reranking ways that are closer to the oracle scores and investigate the efficacy of the approach in low-resourced data conditions .
Language models are used for getting the likelihood of sentences and is a widely used concept for reranking hypotheses .
Introducing Language Models during reranking could establish a tradeoff between perplexity and the scores to the hypotheses generated .
We also plan to explore the work by C ? aglar G?lc ? ehre et al . ( 2017 ) and C ?aglar G?lc ? ehre et al . ( 2015 ) that introduces language models into the existing neural architecture with methods such as Shallow Fusion and Deep Fusion .
It is another promising area to be looked upon for reranking .
Figure Figure 1 : Comparison with Baseline System
Procedure Algorithm 1 Method Input : Translated Target Language Sentences H = ( h( n ? k ) ... , h( n ) ) at last k epochs for given sentence Output : Sentence having highest number of distinct words and lowest repetitive words for each sentence h j in H do if h score j ?D/ F end if return sentence with highest score j end for=0 j ? ( w 1 , w 2 , w 3 ...w l ) then D ? DIST IN CT ( ( w 1 , w 2 , w 3 ...w l ) ) F ? F REQ ( w 1 ) ?F REQ ( w 2 ) ...
Table 2 : 2 BLEU Scores with Baseline System BLEU Checkpoint - 1 0.62 Checkpoint - 2 3.55 Checkpoint -3 8.83 Checkpoint -4 13.53 Checkpoint -5 17.01 Checkpoint -6 19.20 Checkpoint -7 20.72 Checkpoint -8 21.09 Checkpoint -9 21.38 Checkpoint - 10 21.87 Checkpoint -11 22.39 Checkpoint -12 22.37 Checkpoint -13 22.57 Checkpoint -14 22.71 Checkpoint -15 22.92
5 . System BLEU Baseline 22.92 Reranking 22.99 ( + 0.07 ) Oracle 23.47 ( + 0.55 )
Table 3 : 3 Last 3 Iterations System BLEU Baseline 22.92 Reranking 23.07 ( + 0.15 ) Oracle 23.82 ( + 0.90 )
Table 4 : 4 Last 5 Iterations System BLEU Baseline 22.92 Reranking 23.08 ( + 0.16 ) Oracle 23.93 ( + 1.01 )
Table 5 : 5 Last 7 Iterations
Table 7 : 7 Last 3 Iterations with 0.1 coverage penalty System 0.1 penalty Baseline 23.35 Reranking 23.50 ( + 0.15 ) Oracle 24.17 ( + 0.82 )
Table 8 : 8 Last 5 Iterations with 0.1 coverage penalty System 0.1 penalty Baseline 23.35 Reranking 23.52 ( + 0.17 ) Oracle 24.34 ( + 0.99 )
Table 9 : 9 Last 7 Iterations with 0.1 coverage penalty
Table 10 : 10 . BLEU Scores With 0.2 Coverage Penalty Hypothesis 0.2 penalty Checkpoint -1 1.33 Checkpoint - 2 3.54 Checkpoint -3 10.10 Checkpoint -4 15.36 Checkpoint -5 18.08 Checkpoint -6 19.36 Checkpoint -7 20.35 Checkpoint -8 20.29 Checkpoint -9 20.56 Checkpoint - 10 20.96 Checkpoint - 11 21.43 Checkpoint - 12 21.52 Checkpoint -13 21.66 Checkpoint - 14 21.56 Checkpoint - 15 21.81 System 0.2 penalty Baseline 21.81 Reranking 21.93 ( + 0.12 ) Oracle 22.72 ( + 0.91 )
Table 11 : 11 Last 3 Iterations with 0.2 coverage penalty System 0.2 penalty Baseline 21.81 Reranking 21.96 ( + 0.15 ) Oracle 23.11 ( + 1.30 )
Table 12 : 12 Last 5 Iterations with 0.2 coverage penalty System 0.2 penalty Baseline 21.81 Reranking 21.96 ( + 0.15 ) Oracle 23.11 ( + 1.30 )
Table 13 : 13 Last 7 Iterations with 0.2 coverage penalty 6 Conclusions and Future Work
