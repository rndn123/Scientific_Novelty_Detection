title
Handling Ambiguities of Bilingual Predicate-Argument Structures for Statistical Machine Translation
abstract
Predicate-argument structure ( PAS ) has been demonstrated to be very effective in improving SMT performance .
However , since a sourceside PAS might correspond to multiple different target- side PASs , there usually exist many PAS ambiguities during translation .
In this paper , we group PAS ambiguities into two types : role ambiguity and gap ambiguity .
Then we propose two novel methods to handle the two PAS ambiguities for SMT accordingly : 1 ) inside context integration ; 2 ) a novel maximum entropy PAS disambiguation ( MEPD ) model .
In this way , we incorporate rich context information of PAS for disambiguation .
Then we integrate the two methods into a PASbased translation framework .
Experiments show that our approach helps to achieve significant improvements on translation quality .
Introduction Predicate-argument structure ( PAS ) depicts the relationship between a predicate and its associated arguments , which indicates the skeleton structure of a sentence on semantic level .
Basically , PAS agrees much better between two languages than syntax structure ( Fung et al. , 2006 ; Wu and Fung , 2009 b ) .
Considering that current syntaxbased translation models are always impaired by cross-lingual structure divergence ( Eisner , 2003 ; , PAS is really a better representation of a sentence pair to model the bilingual structure mapping .
However , since a source-side PAS might correspond to multiple different target- side PASs , there usually exist many PAS ambiguities during translation .
For example , in Figure 1 , ( a ) and ( b ) carry the same source- side PAS < [ A0 ] 1 [ Pred ( ? ) ] 2 [ A1 ] 3 > for Chinese predicate " ? " .
However , in Figure 1 ( a ) , the corresponding target- side - like PAS is < [ X 1 ] [ X 2 ] [ X 3 ] > , while in Figure 1 ( b ) , the counterpart target- side - like PAS 1 is < [ X 2 ] [ X 3 ] [ X 1 ] >.
This is because the two PASs play different roles in their corresponding sentences .
Actually , Figure 1 ( a ) is an independent PAS , while Figure 1 ( b ) is a modifier of the noun phrase " ? ? ? " .
We call this kind of PAS ambiguity role ambiguity .
? ? ? ? ? ? [ A0 ] 1 [ A1 ] 3 [ Pred ] 2 ? being , should ? two major countries [ X 3 ] [ X 2 ] China and Russia [ X 1 ] ? ? ? ? ? ? ? [ A0 ] 1 [ A1 ] 3 [ Pred ] 2 flood prevention is the primary mission [ X 1 ] [ X 2 ] [ X 3 ] ? ? ? ? ? ? ? ? ? [ A0 ] 1 [ A1 ] 3 [ Pred ] 2 the location of the olympic village for athletes is the best Meanwhile , Figure 1 also depicts another kind of PAS ambiguity .
From Figure 1 , we can see that ( a ) and ( c ) get the same source - side PAS and target- side - like PAS .
However , they are different because in Figure 1 ( c ) , there is a gap string " ? ? " between [ A0 ] and [ Pred ] .
Generally , the gap strings are due to the low recall of automatic semantic role labeling ( SRL ) or complex sentence structures .
For example , in Figure 1 ( c ) , the gap string " ? ? " is actually an argument " AM - PRP " of the PAS , but the SRL system has ignored it .
We call this kind of PAS ambiguity gap ambiguity .
[ X 3 ] [ X 2 ] [ X 1 ] ( a ) ( c ) During translation , these PAS ambiguities will greatly affect the PAS - based translation models .
Therefore , in order to incorporate the bilingual PAS into machine translation effectively , we need to decide which target - side - like PAS should be chosen for a specific source - side PAS .
We call this task PAS disambiguation .
In this paper , we propose two novel methods to incorporate rich context information to handle PAS ambiguities .
Towards the gap ambiguity , we adopt a method called inside context integration to extend PAS to IC - PAS .
In terms of IC - PAS , the gap strings are combined effectively to deal with the gap ambiguities .
As to the role ambiguity , we design a novel maximum entropy PAS disambiguation ( MEPD ) model to combine various context features , such as context words of PAS .
For each ambiguous source-side PAS , we build a specific MEPD model to select appropriate target- side - like PAS for translation .
We will detail the two methods in Section 3 and 4 respectively .
Finally , we integrate the above two methods into a PAS - based translation framework ( Zhai et al. 2012 ) .
Experiments show that the two PAS disambiguation methods significantly improve the baseline translation system .
The main contribution of this work can be concluded as follows : 1 ) We define two kinds of PAS ambiguities : role ambiguity and gap ambiguity .
To our best knowledge , we are the first to handle these PAS ambiguities for SMT .
2 ) Towards the two different ambiguities , we design two specific methods for PAS disambiguation : inside context integration and the novel MEPD model .
PAS - based Translation Framework PAS - based translation framework is to perform translation based on PAS transformation ( Zhai et al. , 2012 ) .
In the framework , a source- side PAS is first converted into target- side - like PASs by PAS transformation rules , and then perform translation based on the obtained target- side - like PASs .
PAS Transformation Rules PAS transformation rules ( PASTR ) are used to convert a source- side PAS into a target one .
Formally , a PASTR is a triple < Pred , SP , TP > : ?
Pred means the predicate where the rule is extracted .
?
SP denotes the list of source elements in source language order .
? TP refers to the target- side- like PAS , i.e. , a list of general non-terminals in target language order .
For example , Figure 2 shows the PASTR extracted from Figure 1 ( a ) .
In this PASTR , Pred is Chinese verb " ? " , SP is the source element list < [ A0 ] 1 [ Pred ] 2 [ A1 ] 3 > , and TP is the list of non-terminals < X 1 X 2 X 3 >.
The same subscript in SP and TP means a one- to - one mapping between a source element and a target non-terminal .
Here , we utilize the source element to refer to the predicate or argument of the source- side PAS . [ X 3 ] [ X 2 ] [ A0 ] 1 [ Pred ] 2 [ A1 ] 3 [ X 1 ] source-side PAS ( ? ) target-side-like PAS Figure 2 . An example PASTR .
PAS Decoding
The PAS decoding process is divided into 3 steps : ( 1 ) PAS acquisition : perform semantic role labeling ( SRL ) on the input sentences to achieve their PASs , i.e. , source- side PASs ; ( 2 ) Transformation : use the PASTR to match the source- side PAS i.e. , the predicate Pred and the source element list SP .
Then by the matching PASTRs , transform source-side PASs to targetside - like PASs .
( 3 ) Translation : in this step , the decoder first translates each source element respectively , and then a CKY - style decoding algorithm is adopted to combine the translation of each element and get the final translation of the PAS .
Sentence Decoding with the PAS - based translation framework Sometimes , the source sentence cannot be fully covered by the PAS , especially when there are several predicates .
Thus to translate the whole sentence , Zhai et al . ( 2012 ) further designed an algorithm to decode the entire sentence .
In the algorithm , they organized the space of translation candidates into a hypergraph .
For the span covered by PAS ( PAS span ) , a multiplebranch hyperedge is employed to connect it to the PAS 's elements .
For the span not covered by PAS ( non - PAS span ) , the decoder considers all the possible binary segmentations of it and utilizes binary hyperedges to link them .
During translation , the decoder fills the spans with translation candidates in a bottom - up manner .
For the PAS span , the PAS - based translation framework is adopted .
Otherwise , the BTG system ( Xiong et al. , 2006 ) is used .
When the span covers the whole sentence , we get the final translation result .
Obviously , PAS ambiguities are not considered in this framework at all .
The targetside - like PAS is selected only according to the language model and translation probabilities , without considering any context information of PAS .
Consequently , it would be difficult for the decoder to distinguish the source- side PAS from different context .
This harms the translation quality .
Thus to overcome this problem , we design two novel methods to cope with the PAS ambiguities : inside-context integration and a maximum entropy PAS disambiguation ( MEPD ) model .
They will be detailed in the next two sections .
Inside Context Integration
In this section , we integrate the inside context of the PAS into PASTRs to do PAS disambiguation .
Basically , a PAS consists of several elements ( a predicate and several arguments ) , which are actually a series of continuous spans .
For a specific PAS < E 1 , ? , E n > , such as the source- side PAS 2 , its controlled range is defined as : <[ A0 ] [ Pred ] [ A1 ] > in Figure ( ) { ( ) , [ 1 , ] } i range PAS s E i n = ? ? where s( E i ) denotes the span of element E i .
Further , we define the closure range of a PAS .
It refers to the shortest continuous span covered by the entire PAS : 0 ( ) ( ) _ min , max n j s E j s E closure range j j ? ? ? ? = ? ? ? ?
Here , E 0 and E n are the leftmost and rightmost element of the PAS respectively .
The closure range is introduced here because adjacent source elements in a PAS are usually separated by gap strings in the sentence .
We call these gap strings the inside context ( IC ) of the PAS , which satisfy : _ ( ) ( ( ) ( ) ) closure range PAS IC PAS range PAS = ? ?
The operator ?
takes a list of neighboring spans as input 2 , and returns their combined continuous span .
As an example , towards the PAS " < [ A0 ] [ Pred ] [ A1 ] > " ( the one for Chinese predicate " ? ( shi ) " ) in Figure 3 , its controlled range is { [ 3,5 ] , [ 8 , 8 ] , [ 9 , 11 ] } and its closure range is [ 3 , 11 ] .
The IC of the PAS is thus { [ 6,7 ] } .
To consider the PAS 's IC during PAS transformation process , we incorporate its IC into the extracted PASTR .
For each gap string in IC , we abstract it by the sequence of highest node categories ( named as s-tag sequence ) .
The s-tag sequence dominates the corresponding syntactic tree fragments in the parse tree .
For example , in Figure 3 , the s-tag sequence for span [ 6 , 8 ] is " PP VC " .
Thus , the sequence for the IC ( span [ 6,7 ] ) in Figure 3 is " PP " .
We combine the s-tag sequences with elements of the PAS in order .
The resulting PAS is called IC - PAS , just like the left side of Figure 4 ( b ) shows .
Differently , Zhai et al. ( 2012 ) attached the IC to its neighboring elements based on parse trees .
For example , in Figure 3 , they would attach the gap string " ?( dui ) ?( yun-dong-yuan ) " to the PAS 's element " Pred " , and then the span of " Pred " would become [ 6 , 8 ] .
Consequently , the span [ 6,8 ] will be translated as a whole source element in the decoder .
This results in a bad translation because the gap string " ?( dui ) ? ( yun-dong-yuan ) " and predicate " ?( shi ) " should be translated separately , just as Figure 4 ( a ) shows .
Therefore , we can see that the attachment decision in ( Zhai et al. , 2012 ) is sometimes unreasonable and the IC also cannot be used for PAS disambiguation at all .
In contrast , our meth-od of inside context integration is much flexible and beneficial for PAS disambiguation .
Using the IC - PASs , we look for the aligned target span for each element of the IC - PAS .
We demand that every element and its corresponding target span must be consistent with word alignment .
Otherwise , we discard the IC - PAS .
Afterwards , we can easily extract a rule for PAS transformation , which we call IC - PASTR .
As an example , Figure 4 ( b ) is the extracted IC - PASTR from Figure 4 ( a ) . ( a ) ( b ) [ X 1 ] [ X 2 ] [ X 4 ] [ A0 ] 1 [ PP ] 2 [ Pred ] 3 [ A1 ] 4 [ X 3 ] source-side PAS ( ? ) target-side-like PAS ? ? ? ? [ A0 ] 1 [ A1 ] 4 [ Pred ] 3 [ the location of the olympic village ] 1 [ for athletes ] 2 [ is ] 3 [ the best ]
4 [ PP ] 2 de wei-zhi ao-yun-cun ? ? ? dui yun-dong - yuan shi ? ? zui hao de Note that we only apply the source- side PAS and word alignment for IC - PASTR extraction .
By contrast , Zhai et al . ( 2012 ) utilized the result of bilingual SRL ( Zhuang and Zong , 2010 b ) .
Generally , bilingual SRL could give a better alignment between bilingual elements .
However , bilingual SRL usually achieves a really low recall on PASs , about 226,968 entries in our training set while it is 882,702 by using monolingual SRL system .
Thus to get a high recall for PASs , we only utilize word alignment instead of capturing the relation between bilingual elements .
In addition , to guarantee the accuracy of IC - PASTRs , we only retain rules with more than 5 occurrences .
Maximum Entropy PAS Disambiguation ( MEPD ) Model
In order to handle the role ambiguities , in this section , we concentrate on utilizing a maximum entropy model to incorporate the context information for PAS disambiguation .
Actually , the disambiguation problem can be considered as a multi-class classification task .
That is to say , for a source- side PAS , every corresponding targetside - like PAS can be considered as a label .
For example , in Figure 1 , for the source- side PAS " where sp and tp refer to the source - side PAS ( not including the predicate ) and the target- side - like PAS respectively . c( sp ) and c( tp ) denote the surrounding context of sp and tp .
h i is a binary feature function and ?
i is the weight of h i . [ A0 ] 1 [ Pred ] 2 [ A1 ] 3 " , the target- side - like PAS " [ X 1 ] [ X 2 ] [ X 3 ] " in Figure 1 ( a ) is thus a label and " [ X 2 ] [ X 3 ] [ X 1 ] " in We train a maximum entropy classifier for each sp via the off-the-shelf MaxEnt toolkit 3 . Note that to avoid sparseness , sp does not include predicate of the PAS .
Practically , the predicate serves as a feature of the MEPD model .
As an example , for the rule illustrated in Figure 4 ( b ) , we build a MEPD model for its source element list sp < [ A0 ] [ PP ] [ Pred ] [ A1 ] > , and integrate the predicate " ?( shi ) " into the MEPD model as a feature .
In detail , we design a list of features for each pair < sp , tp > as follows : ? Lexical Features .
These features include the words immediately to the left and right of sp , represented as w - 1 and w + 1 .
Moreover , the head word of each argument also serves as a lexical feature , named as hw ( E i ) .
For example , Figure 3 shows the context of the IC - PASTR in Figure 4 ( b ) , and the extracted lexical features of the instance are : w - 1 = ? , w +1 = ? , hw ( [ A0 ] 1 ) = ? ? ( wei-zhi ) , hw ( [ A1 ] 4 ) =?( hao ) .
? POS Features .
These features are defined as the POS tags of the lexical features , p - 1 , p + 1 and phw ( E i ) respectively .
Thus , the corresponding POS features of Figure 4 ( b ) are : p - 1 = PU , p +1 = PU , phw ( [ A0 ] 1 ) =NN , phw ( [ A1 ] 4 ) =VA .
? Predicate Feature .
It is the pair of source predicate and its corresponding target predicate .
For example , in Figure 4 ( b ) , the source and target predicate are " ?( shi ) " and " is " respectively .
The predicate feature is thus " PredF= ? ( shi ) + is " .
The target predicate is determined by : _ ( ) - arg max ( | -) j j t range PAS t pred p t s pred ?
= where s-pred is the source predicate and t-pred is the corresponding target predicate .
t_range ( PAS ) refers to the target range covering all the words that are reachable from the PAS via word alignment .
t j refers to the jth word in t_range ( PAS ) .
The utilized lexical translation probabilities are from the toolkit in Moses ( Koehn et al. , 2007 ) . ? Syntax Features .
These features include st ( Ei ) , i.e. , the highest syntax tag for each argument , and fst ( PAS ) which is the lowest father node of sp in the parse tree .
For example , for the rule shown in Figure 4 ( b ) , syntax features are st ( [ A0 ] 1 ) =NP , st ( [ A1 ] 4 ) =CP , and fst ( PAS ) =IP respectively .
Using these features , we can train the MEPD model .
We set the Gaussian prior to 1.0 and perform 100 iterations of the L-BFGS algorithm for each MEPD model .
At last , we build 160 and 215 different MEPD classifiers , respectively , for the PASTRs and IC - PASTRs .
Note that since the training procedure of maximum entropy classifier is really fast , it does not take much time to train these classifiers .
Integrating into the PAS - based Translation Framework
In this section , we integrate our method of PAS disambiguation into the PAS - based translation framework when translating each test sentence .
For inside context integration , since the format of IC - PASTR is the same to PASTR 4 , we can use the IC - PASTR to substitute PASTR for building a PAS - based translation system directly .
We use " IC - PASTR " to denote this system .
In addition , since our method of rule extraction is different from ( Zhai et al. , 2012 ) , we also use PASTR to construct a translation system as the baseline system , which we call " PASTR " .
On the basis of PASTR and IC - PASTR , we further integrate our MEPD model into translation .
Specifically , we take the score of the MEPD model as another informative feature for the decoder to distinguish good target- side - like PASs from bad ones .
The weights of the MEPD feature can be tuned by MERT ( Och , 2003 ) together with other translation features , such as language model .
Related Work
The method of PAS disambiguation for SMT is relevant to the previous work on context depend-ent translation .
Wu ( 2007a , 2007 b ) and Chan et al . ( 2007 ) have integrated word sense disambiguation ( WSD ) and phrase sense disambiguation ( PSD ) into SMT systems .
They combine rich context information to do disambiguation for words or phrases , and achieve improved translation performance .
Differently , , and Cui et al . ( 2010 ) designed maximum entropy ( ME ) classifiers to do better rule section for hierarchical phrase - based model and tree-to-string model respectively .
By incorporating the rich context information as features , they chose better rules for translation and yielded stable improvements on translation quality .
Our work differs from the above work in the following two aspects : 1 ) in our work , we focus on the problem of disambiguates on PAS ; 2 ) we define two kinds of PAS ambiguities : role ambiguity and gap ambiguity .
3 ) towards the two different ambiguities , we design two specific methods for PAS disambiguation : inside context integration and the novel MEPD model .
In addition , Xiong et al . ( 2012 ) proposed an argument reordering model to predict the relative position between predicates and arguments .
They also combine the context information in the model .
But they only focus on the relation between the predicate and a specific argument , rather than the entire PAS .
Different from their work , we incorporate the context information to do PAS disambiguation based on the entire PAS .
This is very beneficial for global reordering during translation ( Zhai et al. , 2012 ) .
Experiment
Experimental Setup
We perform Chinese-to- English translation to demonstrate the effectiveness of our PAS disambiguation method .
The training data contains about 260K sentence pairs 5 .
To get accurate SRL results , we ensure that the length of each sentence in the training data is among 10 and 30 words .
We run GIZA ++ and then employ the grow-diag-final - and ( gdfa ) strategy to produce symmetric word alignments .
The development set and test set come from the NIST evaluation test data ( from 2003 to 2005 ) .
Similar to the training set , we also only retain the sentences whose lengths are among 10 and 30 words .
Finally , the development set includes 595 sentences from NIST MT03 and the test set contains 1,786 sentences from NIST MT04 and MT05 .
We train a 5 - gram language model with the Xinhua portion of English Gigaword corpus and target part of the training data .
The translation quality is evaluated by case-insensitive BLEU - 4 with shortest length penalty .
The statistical significance test is performed by the re-sampling approach ( Koehn , 2004 ) .
We perform SRL on the source part of the training set , development set and test set by the Chinese SRL system used in ( Zhuang and Zong , 2010 b ) .
To relieve the negative effect of SRL errors , we get the multiple SRL results by providing the SRL system with 3 - best parse trees of Berkeley parser ( Petrov and Klein , 2007 ) , 1best parse tree of Bikel parser ( Bikel , 2004 ) and Stanford parser ( Klein and Manning , 2003 ) .
Therefore , at last , we can get 5 SRL result for each sentence .
For the training set , we use these SRL results to do rule extraction respectively .
We combine the obtained rules together to get a combined rule set .
We discard the rules with fewer than 5 appearances .
Using this set , we can train our MEPD model directly .
As to translation , we match the 5 SRL results with transformation rules respectively , and then apply the resulting target- side - like PASs for decoding .
As we mentioned in section 2.3 , we use the state - of - the - art BTG system to translate the non -PAS spans .
source-side PAS counts number of classes [ A0 ] [ Pred ( ? ) ] [ A1 ] 245 6 [ A0 ] [ Pred ( ? ) ] [ A1 ] 148 6 [ A0 ] [ AM - ADV ] [ Pred ( ? ) ] [ A1 ] 68 20 [ A0 ] [ Pred ( ? ) ] [ A1 ] 66 6 [ A0 ] [ Pred ( ? ) ] [ A1 ] 42 6 [ A0 ] [ Pred ( ? ) ] [ A1 ] 32 4 [ A0 ] [ AM - ADV ] [ Pred ( ? ) ] [ A1 ] 32 19 [ A0 ] [ Pred ( ? ) ] [ A1 ] 29 4 [ AM - ADV ] [ Pred ( ? ) ] [ A1 ] 26 6 [ A2 ] [ Pred ( ? ) ] [ A1 ]
16 5 Table 1 . The top 10 frequent source-side PASs in the dev and test set .
Ambiguities in Source-side PASs
We first give 1 , all the top 10 PASs correspond to several different target- sidelike PASs .
Moreover , according to our statistics , among all PASs appearing in the development set and test set , 56.7 % of them carry gap strings .
These statistics demonstrate the importance of handling the role ambiguity and gap ambiguity in the PAS - based translation framework .
Therefore , we believe that our PAS disambiguation method would be helpful for translation .
Translation Result
We compare the translation result using PASTR , IC - PASTR and our MEPD model in this section .
The final translation results are shown in Table 2 .
As we can see , after employing PAS for translation , all systems outperform the baseline BTG system significantly .
This comparison verifies the conclusion of ( Zhai et al. , 2012 ) and thus also demonstrates the effectiveness of PAS .
2 . Result of baseline system and the MT systems using our PAS - based disambiguation method .
The " * " and " # " denote that the result is significantly better than BTG and PASTR respectively ( p< 0.01 ) .
Specifically , after integrating the inside context information of PAS into transformation , we can see that system IC - PASTR significantly outperforms system PASTR by 0.71 BLEU points .
Moreover , after we import the MEPD model into system PASTR , we get a significant improvement over PASTR ( by 0.54 BLEU points ) .
These comparisons indicate that both the inside context integration and our MEPD model are beneficial for the decoder to choose better target - side - like PAS for translation .
On the basis of IC - PASTR , we further add our MEPD model into translation and get system IC - PASTR + MEPD .
We can see that this system further achieves a remarkable improvement over system PASTR ( 0.95 BLEU points ) .
However , from Table 2 , we find that system IC - PASTR + MEPD only outperforms system IC - PASTR slightly ( 0.24 BLEU points ) .
The result seems to show that our MEPD model is not such useful after using IC - PASTR .
We will explore the reason in section 7.5 .
Effectiveness of Inside Context Integration
The method of inside context integration is used to combine the inside context ( gap strings ) into PAS for translation , i.e. , extend the PASTR to IC - PASTR .
In order to demonstrate the effectiveness of inside context integration , we first give Table 3 , which illustrates statistics on the matching PASs .
The statistics are conducted on the combination of development set and test set .
In Table 3 , for example , the line for PASTR means that if we use PASTR for the combined set , 3241 PASs ( column " Total " ) can match PASTRs in total .
Among these matching PASs , 1539 ones ( column " Gap PAS " ) carry gap strings , while 1702 ones do not ( column " None Gap PAS " ) .
Consequently , since PASTR does not consider the inside context during translation , the Gap PASs , which account for 47 % ( 1539/3241 ) of all matching PASs , might be handled inappropriately in the PAS - based translation framework .
Therefore , integrating the inside context into PASTRs , i.e. , using the proposed IC - PASTRs , would be helpful for translation .
The translation result shown in Table 2 also demonstrates this conclusion .
From Table 3 , we can also find that the number of matching PASs decreases after using IC - PASTR .
This is because IC - PASTR is more spe-cific than PASTR .
Therefore , for a PAS with specific inside context ( gap strings ) , even if the matched PASTR is available , the matched IC - PASTR might not .
This indicates that comparing with PASTR , IC - PASTR is more capable of distinguishing different PASs .
Therefore , based on this advantage , although the number of matching PASs decreases , IC - PASTR still improves the translation system using PASTR significantly .
Of course , we believe that it is also possible to integrate the inside context without decreasing the number of matching PASs and we plan this as our future work .
We further give a translation example in Figure 5 to illustrate the effectiveness of our inside context integration method .
In the example , the automatic SRL system ignores the long preposition phrase " ? ? ? ? ? ? " for the PAS .
Thus , the system using PASTRs can only attach the long phrase to the predicate " ? " according to the parse tree , and meanwhile , make use of a transformation rule as follows : [ X 3 ] [ X 2 ] [ A0 ] 1 [ Pred ] 2 [ A1 ] 3 [ X 1 ] source-side PAS ( ? ) target-side-like PAS
In this way , the translation result is very bad , just as Figure 5 ( b ) shows .
The long preposition phrases are wrongly positioned in the translation .
In contrast , after inside context integration , we match the inside context during PAS transformation .
As Figure 5 ( c ) shows , the inside context helps to selects a right transformation rule as follows and gets a good translation result finally . [ X 1 ] [ X 2 ] [ X 4 ] [ A0 ] 1 [ PP ] 2 [ Pred ] 3 [ A1 ] 4 [ X 3 ] source-side PAS ( ? ) target-side-like PAS
Effectiveness of the MEPD Model
The MEPD model incorporates various context features to select better target- side - like PAS for translation .
On the basis of PASTR and IC - PASTR , we build 160 and 215 different MEPD classifies , respectively , for the frequent sourceside PASs .
In Table 2 , we have found that our MEPD model improves system IC - PASTR slightly .
We conjecture that this phenomenon is due to two possible reasons .
On one hand , sometimes , many PAS ambiguities might be resolved by both inside context and the MEPD model .
Therefore , the improvement would not be such significant when we combine these two methods together .
On the other hand , as Table 3 shows , the number of matching PASs decreases after using IC - PASTR .
Since the MEPD model works on PASs , its effectiveness would also weaken to some extent .
Future work will explore this phenomenon more thoroughly .
This rule wrongly moves the subject " ? ? ( Hague ) " to the end of the translation .
We do not give the translation result of the BTG system here because it makes the same mistake .
Conversely , by considering the context information , the PASTR + MEPD system chooses a correct rule for translation : [ X 3 ] [ X 2 ] [ A0 ] 1 [ Pred ] 2 [ A1 ] 3 [ X 1 ] source-side PAS ( ? ) target-side-like PAS
As we can see , the used rule helps to keep the SVO structure unchanged , and gets the correct translation .
Conclusion and Future Work
In this paper , we focus on the problem of ambiguities for PASs .
We first propose two ambiguities : gap ambiguity and role ambiguity .
Accordingly , we design two novel methods to do efficient PAS disambiguation : inside-context integration and a novel MEPD model .
For inside context integration , we abstract the inside con-text and combine them into the PASTRs for PAS transformation .
Towards the MEPD model , we design a maximum entropy model for each ambitious source- side PASs .
The two methods successfully incorporate the rich context information into the translation process .
Experiments show that our PAS disambiguation methods help to improve the translation performance significantly .
In the next step , we will conduct experiments on other language pairs to demonstrate the effectiveness of our PAS disambiguation method .
In addition , we also will try to explore more useful and representative features for our MEPD model .
Figure 1 . 1 Figure 1 . An example of ambiguous PASs .
