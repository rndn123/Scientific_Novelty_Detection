title
Improving Pivot Translation by Remembering the Pivot
abstract
Pivot translation allows for translation of language pairs with little or no parallel data by introducing a third language for which data exists .
In particular , the triangulation method , which translates by combining source-pivot and pivot-target translation models into a source - target model , is known for its high translation accuracy .
However , in the conventional triangulation method , information of pivot phrases is forgotten and not used in the translation process .
In this paper , we propose a novel approach to remember the pivot phrases in the triangulation stage , and use a pivot language model as an additional information source at translation time .
Experimental results on the Europarl corpus showed gains of 0.4- 1.2 BLEU points in all tested combinations of languages 1 .
Introduction
In statistical machine translation ( SMT ) ( Brown et al. , 1993 ) , it is known that translation with models trained on larger parallel corpora can achieve greater accuracy ( Dyer et al. , 2008 ) .
Unfortunately , large bilingual corpora are not readily available for many language pairs , particularly those that do n't include English .
One effective solution to overcome the scarceness of bilingual data is to introduce a pivot language for which parallel data with the source and target languages exists ( de Gispert and Mari?o , 2006 ) .
Among various methods using pivot languages , the triangulation method ( Cohn and Lapata , 2007 ; Utiyama and Isahara , 2007 ; Zhu et al. , 2014 ) , which translates by combining source-pivot and pivot-target translation models into a source-target 1 Code to replicate the experiments can be found at https://github.com/akivajp/acl2015 model , has been shown to be one of the most effective approaches .
However , word sense ambiguity and interlingual differences of word usage cause difficulty in accurately learning correspondences between source and target phrases .
Figure 1 ( a ) shows an example of three words in German and Italian that each correspond to the English polysemic word " approach . "
In such a case , finding associated source - target phrase pairs and estimating translation probabilities properly becomes a complicated problem .
Furthermore , in the conventional triangulation method , information about pivot phrases that behave as bridges between source and target phrases is lost after learning phrase pairs , as shown in Figure 1 ( b ) .
To overcome these problems , we propose a novel triangulation method that remembers the pivot phrase connecting source and target in the records of phrase / rule table , and estimates a joint translation probability from the source to target and pivot simultaneously .
We show an example in Figure 1 ( c ) .
The advantage of this approach is that generally we can obtain rich monolingual resources in pivot languages such as English , and SMT can utilize this additional information to improve the translation quality .
To utilize information about the pivot language at translation time , we train a Multi-Synchronous Context - free Grammar ( MSCFG ) ( Neubig et al. , 2015 ) , a generalized extension of synchronous CFGs ( SCFGs ) ( Chiang , 2007 ) , that can generate strings in multiple languages at the same time .
To create the MSCFG , we triangulate source-pivot and pivot-target SCFG rule tables not into a single source - target SCFG , but into a source- target - pivot MSCFG rule table that remembers the pivot .
During decoding , we use language models over both the target and the pivot to assess the naturalness of the derivation .
We perform experiments on pivot translation of Europarl proceedings , which show that our method indeed provide significant gains in accuracy ( of up to 1.2 BLEU points ) , in all combinations of 4 languages with English as a pivot language .
2 Translation Formalisms
Synchronous Context-free Grammars First , we cover SCFGs , which are widely used in machine translation , particularly hierarchical phrase - based translation ( Hiero ; Chiang ( 2007 ) ) .
In SCFGs , the elementary structures are rewrite rules with aligned pairs of right - hand sides : X ? s , t ( 1 ) where X is the head of the rewrite rule , and s and t are both strings of terminals and non-terminals in the source and target side respectively .
Each string in the right side tuple has the same number of indexed non-terminals , and identically indexed nonterminals correspond to each-other .
For example , a synchronous rule could take the form of : X ? ?X 0 of the X 1 , X 1 ? X 0 ? . ( 2 ) In the SCFG training method proposed by Chiang ( 2007 ) , SCFG rules are extracted based on parallel sentences and automatically obtained word alignments .
Each extracted rule is scored with phrase translation probabilities in both directions ?( s|t ) and ?( t | s ) , lexical translation probabilities in both directions ? lex ( s|t ) and ? lex ( t | s ) , a word penalty counting the terminals in t , and a constant phrase penalty of 1 .
At translation time , the decoder searches for the target sentence that maximizes the derivation probability , which is defined as the sum of the scores of the rules used in the derivation , and the log of the language model probability over the target strings .
When not considering an LM , it is possible to efficiently find the best translation for an input sentence using the CKY + algorithm ( Chappelier et al. , 1998 ) .
When using an LM , the expanded search space is further reduced based on a limit on expanded edges , or total states per span , through a procedure such as cube pruning ( Chiang , 2007 ) .
Multi-Synchronous CFGs MSCFGs ( Neubig et al. , 2015 ) are a generalization of SCFGs that are be able to generate sentences in multiple target languages simultaneously .
The single target side string t in the SCFG production rule is extended to have strings for N target languages : X ? s , t 1 , ... , t N . ( 3 ) Performing multi-target translation with MSCFGs is quite similar to translating using standard SCFGs , with the exception of the expanded state space caused by having one LM for each target .
Neubig et al. ( 2015 ) propose a sequential search method , that ensures diversity in the primary target search space by first expanding with only primary target LM , then additionally expands the states for other LMs , a strategy we also adopt in this work .
In the standard training method for MSCFGs , the multi-target rewrite rules are extracted from multilingual line - aligned corpora by applying an extended version of the standard SCFG rule extraction method , and scored with features that consider the multiple targets .
It should be noted that this training method requires a large amount of line - aligned training data including the source and all target languages .
This assumption breaks down when we have little parallel data , and thereby we propose a method to generate MSCFG rules by triangulating 2 SCFG rule tables in the following section .
Pivot Translation Methods Several methods have been proposed for SMT using pivot languages .
These include cascade methods that consecutively translate from source to pivot then pivot to target ( de Gispert and Mari?o , 2006 ) , synthetic data methods that machinetranslate the training data to generate a pseudoparallel corpus ( de Gispert and Mari?o , 2006 ) , and triangulation methods that obtain a sourcetarget phrase / rule table by merging source-pivot and pivot-target table entries with identical pivot language phrases ( Cohn and Lapata , 2007 ) .
In particular , the triangulation method is notable for producing higher quality translation results than other pivot methods ( Utiyama and Isahara , 2007 ) , so we use it as a base for our work .
Traditional Triangulation Method
In the triangulation method by Cohn and Lapata ( 2007 ) , we first train source-pivot and pivot-target rule tables , then create rules : X ? s , t ( 4 ) if there exists a pivot phrase p such that the pair ?s , p? is in source - pivot table T SP and the pair p , t is in pivot-target table T P T .
Source- target table T ST is created by calculation of the translation probabilities using phrase translation probabilities ?(? ) and lexical translation probabilities ? lex ( ? ) for all connected phrases according to the following equations ( Cohn and Lapata , 2007 ) : ? t|s = p?T SP ?T P T ? t|p ? ( p|s ) , ( 5 ) ? s|t = p?T SP ?T P T ? ( s|p ) ? p|t , ( 6 ) ? lex t|s = p?T SP ?T P T ? lex t|p ? lex ( p|s ) , ( 7 ) ? lex s|t = p?T SP ?T P T ? lex ( s|p ) ? lex p|t . ( 8 ) The equations ( 5 ) -( 8 ) are based on the memoryless channel model , which assumes ?
t|p , s = ?
t|p and ? s|p , t = ? ( s |p ) .
Unfortunately , these equations are not accurate due to polysemy and disconnects in the grammar of the languages .
As a result , pivot translation is significantly more ambiguous than standard translation .
Proposed Triangulation Method
To help reduce this ambiguity , our proposed triangulation method remembers the corresponding pivot phrase as additional information to be utilized for disambiguation .
Specifically , instead of marginalizing over the pivot phrase p , we create an MSCFG rule for the tuple of the connected sourcetarget - pivot phrases such as : X ? s , t , p . ( 9 )
The advantage of translation with these rules is that they allow for incorporation of additional features over the pivot sentence such as a strong pivot LM .
In addition to the equations ( 5 ) -( 8 ) , we also estimate translation probabilities ?( t , p|s ) , ?( s|p , t ) that consider both target and pivot phrases at the same time according to : ? t , p|s = ? t|p ? ( p|s ) , ( 10 ) ? s|p , t = ? ( s|p ) . ( 11 ) Translation probabilities between source and pivot phrases ?( p|s ) , ?( s|p ) , ? lex ( p|s ) , ? lex ( s|p ) can also be used directly from the source - pivot rule table .
This results in 13 features for each MSCFG rule : 10 translation probabilities , 2 word penalties counting the terminals in t and p , and a constant phrase penalty of 1 .
It should be noted that remembering the pivot results in significantly larger rule tables .
To save computational resources , several pruning methods are conceivable .
Neubig et al. ( 2015 ) show that an effective pruning method in the case of a main target T 1 with the help of target T 2 is the T 1 - pruning method , namely , using L candidates of t 1 with the highest translation probability ?( t 1 |s ) and selecting t 2 with highest ?( t 1 , t 2 | s ) for each t 1 .
We follow this approach , using the L best t , and the corresponding 1 best p .
Experiments
Experimental Setup
We evaluate the proposed triangulation method through pivot translation experiments on the Europarl corpus , which is a multilingual corpus including 21 European languages ( Koehn , 2005 ) widely used in pivot translation work .
In our work , we perform translation among German ( de ) , Spanish ( es ) , French ( fr ) and Italian ( it ) , with English ( en ) as the pivot language .
To prepare the data for these 5 languages , we first use the Gale - Church alignment algorithm ( Gale and Church , 1993 ) to retrieve a multilingual line - aligned corpus of about 900k sentences , then hold out 1,500 sentences each for tuning and test .
In our basic
As a decoder , we use Travatar ( Neubig , 2013 ) , and train SCFG TMs with its Hiero extraction code .
Translation results are evaluated by BLEU ( Papineni et al. , 2002 ) and we tuned to maximize BLEU scores using MERT ( Och , 2003 ) .
For trained and triangulated TMs , we use T 1 rule pruning with a limit of 20 rules per source rule .
For decoding using MSCFG , we adopt the sequential search method .
We evaluate 6 translation methods :
Direct : Translating with a direct SCFG trained on the source-target parallel corpus ( not using a pivot language ) for comparison .
Cascade : Cascading source-pivot and pivottarget translation systems .
Tri. SCFG : Triangulating source-pivot and pivot-target SCFG TMs into a source-target SCFG TM using the traditional method .
Tri. MSCFG : Triangulating source-pivot and pivot-target SCFG TMs into a sourcetarget - pivot MSCFG TM in our approach .
- PivotLM indicates translating without a pivot LM and + PivotLM 100k / 2 M indicates a pivot LM trained using 100k / 2 M sentences respectively .
Experimental Results
The result of experiments using all combinations of pivot translation tasks for 4 languages via English is shown in Table 1 .
From the results , we can see that the proposed triangulation method considering pivot LMs outperforms the traditional triangulation method for all language pairs , and translation with larger pivot LMs improves the BLEU scores .
For all languages , the pivot-remembering triangulation method with the pivot LM trained with 2 M sentences achieves the highest score of the pivot translation methods , with gains of 0.4- 1.2 BLEU points from the baseline method .
This shows that remembering the pivot and using it to disambiguate results is consistently effective in improving translation accuracy .
We can also see that the MSCFG triangulated model without using the pivot LM slightly outperforms the standard SCFG triangulation method for the majority of language pairs .
It is conceivable that the additional scores of translation probabilities with pivot phrases are effective features that allow for more accurate rule selection .
Finally , we show an example of a translated sentence for which pivot-side ambiguity is resolved in the proposed triangulation method : Input ( German ) : ich bedaure , da ?
es keine gemeinsame ann ? herung gegeben hat .
Reference ( Italian ) : sono spiacente del mancato approccio comune .
Tri. SCFG : mi rammarico per il fatto che non si ravvicinamento comune . ( BLEU +1 : 13.84 ) Tri. MSCFG + PivotLM 2M : mi dispiace che non esiste un approccio comune . ( BLEU +1 : 25.10 ) i regret that there is no common approach .
( Generated English Sentence )
The derivation uses an MSCFG rule connecting " approccio " to " approach " in the pivot , and we can consider that appropriate selection of English words according to the context contributes to selecting relevant vocabulary in Italian .
Conclusion
In this paper , we have proposed a method for pivot translation using triangulation of SCFG rule tables into an MSCFG rule table that remembers the pivot , and performing translation with pivot LMs .
In experiments , we found that these models are effective in the case when a strong pivot LM exists .
In the future , we plan to explore more refined methods to devising effective intermediate expressions , and improve estimation of probabilities for triangulated rules .
Figure 1 : 1 Figure 1 : An example of ( a ) triangulation and the resulting phrases in the ( b ) traditional method of forgetting pivots and ( c ) our proposed method of remembering pivots .
