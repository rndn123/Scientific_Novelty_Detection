title
Learning Translational and Knowledge- based Similarities from Relevance Rankings for Cross-Language Retrieval
abstract
We present an approach to cross-language retrieval that combines dense knowledgebased features and sparse word translations .
Both feature types are learned directly from relevance rankings of bilingual documents in a pairwise ranking framework .
In large-scale experiments for patent prior art search and cross-lingual retrieval in Wikipedia , our approach yields considerable improvements over learningto-rank with either only dense or only sparse features , and over very competitive baselines that combine state - of - the - art machine translation and retrieval .
Introduction Cross-Language Information Retrieval ( CLIR ) for the domain of web search successfully leverages state - of- the - art Statistical Machine Translation ( SMT ) to either produce a single most probable translation , or a weighted list of alternatives , that is used as search query to a standard search engine ( Chin et al. , 2008 ; Ture et al. , 2012 ) .
This approach is advantageous if large amounts of indomain sentence - parallel data are available to train SMT systems , but relevance rankings to train retrieval models are not .
The situation is different for CLIR in special domains such as patents or Wikipedia .
Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data ( Utiyama and Isahara , 2007 ; Smith et al. , 2010 ) , however , relevance judgments are often straightforwardly encoded in special domains .
For example , in patent prior art search , patents granted at any patent office worldwide are considered relevant if they constitute prior art with respect to the invention claimed in the query patent .
Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application , patent citations can be used to automatically extract large amounts of relevance judgments across languages ( Graf and Azzopardi , 2008 ) .
In Wikipedia search , one can imagine a Wikipedia author trying to investigate whether a Wikipedia article covering the subject the author intends to write about already exists in another language .
Since authors are encouraged to avoid orphan articles and to cite their sources , Wikipedia has a rich linking structure between related articles , which can be exploited to create relevance links between articles across languages ( Bai et al. , 2010 ) .
Besides a rich citation structure , patent documents and Wikipedia articles contain a number of further cues on relatedness that can be exploited as features in learning - to - rank approaches .
For monolingual patent retrieval , Guo and Gomes ( 2009 ) and Oh et al . ( 2013 ) advocate the use of dense features encoding domain knowledge on inventors , assignees , location and date , together with dense similarity scores based on bag-of - word representations of patents .
Bai et al. ( 2010 ) show that for the domain of Wikipedia , learning a sparse matrix of word associations between the query and document vocabularies from relevance rankings is useful in monolingual and cross-lingual retrieval .
Sokolov et al. ( 2013 ) apply the idea of learning a sparse matrix of bilingual phrase associations from relevance rankings to cross-lingual retrieval in the patent domain .
Both show improvements of learning - to - rank on relevance data over SMTbased approaches on their respective domains .
The main contribution of this paper is a thorough evaluation of dense and sparse features for learning - to - rank that have so far been used only monolingually or only on either patents or Wikipedia .
We show that for both domains , patents and Wikipedia , jointly learning bilingual sparse word associations and dense knowledgebased similarities directly on relevance ranked data improves significantly over approaches that use either only sparse or only dense features , and over approaches that combine query translation by SMT with standard retrieval in the target language .
Furthermore , we show that our approach can be seen as supervised model combination that allows to combine SMT - based and rankingbased approaches for further substantial improvements .
We conjecture that the gains are due to orthogonal information contributed by domainknowledge , ranking - based word associations , and translation - based information .
Related Work CLIR addresses the problem of translating or projecting a query into the language of the document repository across which retrieval is performed .
In a direct translation approach ( DT ) , a state - of- theart SMT system is used to produce a single best translation that is used as search query in the target language .
For example , Google 's CLIR approach combines their state - of- the - art SMT system with their proprietary search engine ( Chin et al. , 2008 ) .
Alternative approaches avoid to solve the hard problem of word reordering , and instead rely on token - to - token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme .
Darwish and Oard ( 2003 ) termed this method the probabilistic structured query approach ( PSQ ) .
The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations ( Xu et al. , 2001 ) .
Ture et al. ( 2012 ) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars .
Ranking approaches have been presented by Guo and Gomes ( 2009 ) and Oh et al . ( 2013 ) .
Their method is a classical learning - to - rank setup where pairwise ranking is applied to a few hundred dense features .
Methods to learn sparse word - based translation correspondences from supervised ranking signals have been presented by Bai et al . ( 2010 ) and Sokolov et al . ( 2013 ) .
Both approaches work in a cross-lingual setting , the former on Wikipedia data , the latter on patents .
Our approach extends the work of Sokolov et al . ( 2013 ) by presenting an alternative learningto- rank approach that can be used for supervised model combination to integrate dense and sparse features , and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia .
This relates our work to supervised model merging approaches ( Sheldon et al. , 2011 ) .
Translation and Ranking for CLIR SMT - based Models .
We will refer to DT and PSQ as SMT - based models that translate a query , and then perform monolingual retrieval using BM25 .
Translation is agnostic of the retrieval task .
Linear Ranking for Word-Based Models .
Let q ? { 0 , 1 } Q be a query and d ? { 0 , 1 } D be a document where the j th vector dimension indicates the occurrence of the j th word for dictionaries of size Q and D .
A linear ranking model is defined as f ( q , d ) = q W d = Q i=1 D j=1 q i W ij d j , where W ? IR Q?D encodes a matrix of rankingspecific word associations ( Bai et al. , 2010 ) .
We optimize this model by pairwise ranking , which assumes labeled data in the form of a set R of tuples ( q , d + , d ? ) , where d + is a relevant ( or higher ranked ) document and d ? an irrelevant ( or lower ranked ) document for query q.
The goal is to find a weight matrix W such that an inequality f ( q , d + ) > f ( q , d ? ) is violated for the fewest number of tuples from R .
We present two methods for optimizing W in the following .
Pairwise Ranking using Boosting ( BM ) .
The Boosting - based Ranking baseline ( Freund et al. , 2003 ) optimizes an exponential loss : L exp = ( q, d + , d ? ) ?R
D( q , d + , d ? ) e f ( q, d ? ) ? f ( q, d + ) , where D(q , d + , d ? ) is a non-negative importance function on tuples .
The algorithm of Sokolov et al . ( 2013 ) combines batch boosting with bagging over a number of independently drawn bootstrap data samples from R .
In each step , the single word pair feature is selected that provides the largest decrease of L exp .
The found corresponding models are averaged .
To reduce memory requirements we used random feature hashing with the size of the hash of 30 bits ( Shi et al. , 2009 ) .
For regularization we rely on early stopping .
Pairwise Ranking with SGD ( VW ) .
The second objective is an 1 - regularized hinge loss : L hng = ( q, d + , d ? ) ?
R f ( q , d + ) ? f ( q , d ? ) + + ?||W || 1 , where ( x ) + = max ( 0 , 1 ? x ) and ? is the regularization parameter .
This newly added model utilizes the standard implementation of online SGD from the Vowpal Wabbit ( VW ) toolkit ( Goel et al. , 2008 ) and was run on a data sample of 5 M to 10 M tuples from R .
On each step , W is updated with a scaled gradient vector ?
W L hng and clipped to account for 1 - regularization .
Memory usage was reduced using the same hashing technique as for boosting .
Domain Knowledge Models .
Domain knowledge features for patents were inspired by Guo and Gomes ( 2009 ) : a feature fires if two patents share similar aspects , e.g. a common inventor .
As we do not have access to address data , we omit geolocation features and instead add features that evaluate similarity w.r.t. patent classes extracted from IPC codes .
Documents within a patent section , i.e. the topmost hierarchy , are too diverse to provide useful information but more detailed classes and the count of matching classes do .
For Wikipedia , we implemented features that compare the relative length of documents , number of links and images , the number of common links and common images , and Wikipedia categories :
Given the categories associated with a foreign query , we use the language links on the Wikipedia category pages to generate a set of " translated " English categories S. The Englishside category graph is used to construct sets of super - and subcategories related to the candidate document 's categories .
This expansion is done in both directions for two levels resulting in 5 category sets .
The intersection between target set T n and the source category set S reflects the category level similarity between query and document , which we calculate as a mutual containment score ( Broder , 1997 ) . s n = 1 2 ( |S ? T n |/|S| + | S ? T n |/|T n | ) for n ? {? 2 , ?1 , 0 , +1 , + 2 } Optimization for these additional models including domain knowledge features was done by overloading the vector representation of queries q and documents d in the VW linear learner :
Instead of sparse word - based features , q and d are represented by real-valued vectors of dense domainknowledge features .
Optimization for the overloaded vectors is done as described above for VW .
Model Combination Combination by Borda Counts .
The baseline consensus-based voting Borda Count procedure endows each voter with a fixed amount of voting points which he is free to distribute among the scored documents ( Aslam and Montague , 2001 ; Sokolov et al. , 2013 ) .
The aggregate score for two rankings f 1 ( q , d ) and f 2 ( q , d ) for all ( q , d ) in the test set is then a simple linear interpolation : f agg ( q , d ) = ? f 1 ( q, d ) d f 1 ( q , d ) +( 1 ? ) f 2 ( q, d ) d f 2 ( q , d ) . Parameter ? was adjusted on the dev set .
Combination by Linear Learning .
In order to acquire the best combination of more than two models , we created vectors of model scores along with domain knowledge features and reused the VW pairwise ranking approach .
This means that the vector representation of queries q and documents d in the VW linear learner is overloaded once more :
In addition to dense domainknowledge features , we incorporate arbitrary ranking models as dense features whose value is the score of the ranking model .
Training data was sampled from the dev set and processed with VW .
Data Patent Prior Art Search ( JP - EN ) .
We use BoostCLIR 1 , a Japanese-English ( JP - EN ) corpus of patent abstracts from the MAREC and NTCIR data ( Sokolov et al. , 2013 ) .
It contains automatically induced relevance judgments for patent abstracts ( Graf and Azzopardi , 2008 ) : EN patents are regarded as relevant with level ( 3 ) to a JP query patent , if they are in a family relationship ( e.g. , same invention ) , cited by the patent examiner ( 2 ) , or cited by the applicant ( 1 ) .
Statistics on the ranking data are given in Table 1 .
On average , queries and documents contain about 5 sentences .
Wikipedia Article Retrieval ( DE -EN ) .
The intuition behind our Wikipedia retrieval setup is as follows :
Consider the situation where the German ( DE ) Wikipedia article on geological sea stacks does not yet exist .
A native speaker of German with profound knowledge in geology intends to write it , naming it " Brandungspfeiler " , while seeking to align its structure with the EN counterpart .
The task of a CLIR engine is to return relevant EN Wikipedia articles that may describe the very same concept ( Stack ( geology ) ) , or relevant instances of it ( Bako National Park , Lange Anna ) .
The information need may be paraphrased as a high- level definition of the topic .
Since typically the first sentence of any Wikipedia article is such
To create this data 4 we downloaded XML and SQL dumps of the DE and EN Wikipedia from , resp. , 22 nd and 4 th of November 2013 .
Wikipedia markup removal and link extraction was carried out using the Cloud9 toolkit 5 . Sentence extraction was done with NLTK 6 . Since Wikipedia articles vary greatly in length , we restricted EN documents to the first 200 words after extracting the link graph to reduce the number of features for BM and VW models .
To avoid rendering the task too easy for literal keyword matching of queries about named entities , we removed title words from the German queries .
Statistics are given in Table 1 . # q # d # d + /q # words Preprocessing Ranking Data .
In addition to lowercasing and punctuation removal , we applied Correlated Feature Hashing ( CFH ) , that makes collisions more likely for words with close meaning ( Bai et al. , 2010 ) .
For patents , vocabularies contained 60 k and 365 k words for JP and EN .
Filtering special symbols and stopwords reduced the JP vocabulary size to 50 k ( small enough not to resort to CFH ) .
To reduce the EN vocabulary 2 de.wikipedia.org/wiki/Brandungspfeiler 3 www.wikidata.org/ 4 www.cl.uni-heidelberg.de/wikiclir 5 lintool.github.io/Cloud9/index.html 6 www.nltk.org/ to a comparable size , we applied similar preprocessing and CFH with F =30k and k=5 .
Since for Wikipedia data , the DE and EN vocabularies were both large ( 6.7 M and 6 M ) , we used the same filtering and preprocessing as for the patent data before applying CFH with F = 40k and k=5 on both sides .
Parallel Data for SMT - based CLIR .
For both tasks , DT and PSQ require an SMT baseline system trained on parallel corpora that are disjunct from the ranking data .
A JP -EN system was trained on data described and preprocessed by Sokolov et al . ( 2013 ) , consisting of 1.8 M parallel sentences from the NTCIR -7 JP -EN PatentMT subtask ( Fujii et al. , 2008 ) and 2 k parallel sentences for parameter development from the NTCIR - 8 test collection .
For Wikipedia , we trained a DE-EN system on 4.1 M parallel sentences from Europarl , Common Crawl , and News - Commentary .
Parameter tuning was done on 3 k parallel sentences from the WMT '11 test set .
6 Experiments Experiment Settings .
The SMT - based models use cdec ( Dyer et al. , 2010 ) .
Word alignments were created with mgiza ( JP - EN ) and fast align ( Dyer et al. , 2013 ) ( DE -EN ) .
Language models were trained with the KenLM toolkit ( Heafield , 2011 ) .
The JP -EN system uses a 5 - gram language model from the EN side of the training data .
For the DE-EN system , a 4 - gram model was built on the EN side of the training data and the EN Wikipedia documents .
Weights for the standard feature set were optimized using cdec's MERT ( JP - EN ) and MIRA ( DE -EN ) implementations ( Och , 2003 ; Chiang et al. , 2008 ) . PSQ on patents reuses settings found by Sokolov et al . ( 2013 ) ; settings for Wikipedia were adjusted on its dev set ( n=1000 , ?=0.4 , L=0 , C=1 ) .
Patent retrieval for DT was done by sentencewise translation and subsequent re-joining to form one query per patent , which was ranked against the documents using BM25 .
For PSQ , BM25 is computed on expected term and document frequencies .
For ranking - based retrieval , we compare several combinations of learners and features ( Table 2 ) .
VW denotes a sparse model using word - based features trained with SGD .
BM denotes a similar model trained using Boosting .
DK denotes VW training of a model that represents queries q and documents d by dense domain-knowledge features instead of by sparse word - based vectors .
In order to simulate pass-through behavior of out -ofvocabulary terms in SMT systems , additional features accounting for source and target term identity were added to DK and BM models .
The parameter ? for VW was found on dev set .
Statistical significance testing was performed using the paired randomization test ( Smucker et al. , 2007 ) .
Borda denotes model combination by Borda Count voting where the linear interpolation parameter is adjusted for MAP on the respective development sets with grid search .
This type of model combination only allows to combine pairs of rankings .
We present a combination of SMTbased CLIR , DT + PSQ , a combination of dense and sparse features , DK + VW , and a combination of both combinations , ( DT + PSQ ) +( DK + VW ) .
LinLearn denotes model combination by overloading the vector representation of queries q and documents d in the VW linear learner by incorporating arbitrary ranking models as dense features .
In difference to grid search for Borda , optimal weights for the linear combination of incorporated ranking models can be learned automatically .
We investigate the same combinations of ranking models as described for Borda above .
We do not report combination results including the sparse BM model since they were consistently lower than the ones with the sparse VW model .
Test Results .
Experimental results on test data are given in Table 2 . Results are reported with respect to MAP ( Manning et al. , 2008 ) , NDCG ( J?rvelin and Kek?l?inen , 2002 ) , and PRES ( Magdy and Jones , 2010 ) .
Scores were computed on the top 1,000 retrieved documents .
As can be seen from inspecting the two blocks of results , one for patents , one for Wikipedia , we find the same system rankings on both datasets .
In both cases , as standalone systems , DT and PSQ are very close and far better than any ranking approach , irrespective of the objective function or the choice of sparse or dense features .
Model combination of similar models , e.g. , DT and PSQ , gives minimal gains , compared to combining orthogonal models , e.g. DK and VW .
The best result is achieved by combining DT and PSQ with DK and VW .
This is due to the already high scores of the combined models , but also to the combination of yet other types of orthogonal information .
Borda voting gives the best result under MAP which is probably due to the adjustment of the interpolation parameter for MAP on the development set .
Under NDCG and PRES , LinLearn achieves the best results , showing the advantage of automatically learning combination weights that leads to stable results across various metrics .
Conclusion Special domains such as patents or Wikipedia offer the possibility to extract cross-lingual relevance data from citation and link graphs .
These data can be used to directly optimizing crosslingual ranking models .
We showed on two different large-scale ranking scenarios that a supervised combination of orthogonal information sources such as domain-knowledge , translation knowledge , and ranking -specific word associations by far outperforms a pipeline of query translation and retrieval .
We conjecture that if these types of information sources are available , a supervised ranking approach will yield superior results in other retrieval scenarios as well .
Table 2 : 2 0.5484 * 0.7736 ( DT + PSQ ) +( DK+ VW ) * 0.4173 * 0.6333 * 0.8031 LinLearn DT +PSQ ? * 0.3718 ? * 0.5751 ? * 0.7251 DK +VW ? * 0.3436 ? * 0.5686 ? * 0.7914 DT + PSQ+DK+VW * 0.4137 ? * 0.6435 ? * 0.8233
Test results for standalone CLIR models using direct translation ( DT ) , probabilistic structured queries ( PSQ ) , sparse model with CFH ( VW ) , sparse boosting model ( BM ) , dense domain knowledge features ( DK ) , and model combinations using Borda Count voting ( Borda ) or linear supervised model combination ( LinLearn ) .
Significant differences ( at p=0.01 ) between aggregated systems and all its components are indicated by * , between LinLearn and the respective Borda system by ?. combination models MAP NDCG PRES Patents ( JP - EN ) standalone Borda LinLearn DT PSQ DK VW BM DT + PSQ DK +VW ( DT + PSQ ) +( DK+ VW ) * 0.3465 0.2554 0.2659 0.2203 0.2205 0.1669 * 0.2747 * 0.3023 DT + PSQ ? * 0.2707 ? * 0.5578 ? * 0.5941 0.5397 0.5680 0.5508 0.5851 0.4874 0.5171 0.4989 0.4911 0.4167 0.4665 * 0.5618 * 0.5988 * 0.5980 * 0.6137 * 0.6420 * 0.6858 DK +VW ? * 0.3283 ? * 0.6366 ? * 0.7104 DT + PSQ+DK+VW ? * 0.3739 ? * 0.6755 ? * 0.7599 Wikipedia ( DE-EN ) standalone Borda DT PSQ DK VW BM DT + PSQ DK+VW 0.3678 0.3642 0.2661 0.1249 0.1386 * 0.3742 * 0.3238 0.5691 0.5671 0.4584 0.3389 0.3418 * 0.5777 * 0.7306 0.7219 0.7165 0.6717 0.6466 0.6145 *
